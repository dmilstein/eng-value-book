* Engineering & The Creation of Value, Part III - Realizing Value In Increments
** Titles
 - The Value of Increments
 - Understanding The Value of Increments
 - Increments & The Creation of Value
 - The Incremental Creation of Value
 - Engineering & The Incremental Creation of Value
 - Engineering & The *Incremental* Creation of Value

** Intro

In today's post we're going to talk about how to design effective *increments* for the development of software.

To do so, we're going to develop a nuanced understanding of how engineering work can steadily create value for an overall business. We'll come to understand how certain increments, despite requiring a great deal of engineering work, can *create no value* whatsoever, while others create a great deal of value.

We'll start by digging into why it's so important to design good increments.

Let's see what happens when a team is laboring under the pain of *bad increment design*.

# I have come to believe it is *the* most important skill of a senior engineer (and of an engineering and product pair).

# This theoretical foundation will give you a powerful way to reason about your work. With practice (and some further tactics, to be explored in subsequent posts), it will allow you to find a path through the shifting chaos of reality to a valuable outcome for your business.

*Our Story*

Sometimes, in the middle of a dark wood, you will find yourself on a team that is "doing Agile", but that doesn't *feel* agile in any way.

The team does all the rituals, and does them faithfully and well. Their sprints are a crisp two weeks long. They start each sprint on a Monday morning with a full team planning session. They gather every day for standup, during which the engineers pull well-groomed tickets from the board. On the final Friday of the sprint, the engineers demo what they've built, and then the team runs a brief retro in the afternoon.

All that is as it should be, right?

In theory, yes.

But, in practice, there's a problem.

Somehow, the overall project has turned into a giant, slow, lumbering effort that is drifting totally out of control.

The team is far, far behind where they are supposed to be. There doesn't seem to be any option whatsoever to catch up. Every lingering problem they finally tackle immediately sprouts three new problems, hydra-like. The PM is losing sleep, and wakes each morning from anxious dreams about their next update to the executive team. The engineers have grown defeatist and bitter. Every day they're asked to pile new expedient hacks on top of yesterday's expedient hacks, resulting in a system that is already profoundly unstable and getting steadily worse. But, because they've already missed all their key delivery dates, there's no time to deal with any of the emerging problems. The team just soldiers on, having long since given up on shipping something that they can be proud of. The engineers and the PM's have a growing suspicion that when they finally *do* ship the unstable, limited, badly compromised system, literally everyone will be angry at them. This is, in fact, exactly what will happen.

# This is a team that is "doing waterfall with agile methods". Somehow, despite successfully applying agile *tactics*, they're still gaining the pretty nasty outcomes of waterfall.

How did this team get here? And how can we avoid getting to a similar place in the future? [fn:: Why didn't "doing agile" save them? Note: I am a huge believer in agile as a way to organize the work of a team. This post is about why agile tactics, as commonly practiced, are not enough. They are, in the terminology of my friends the mathematicians, *necessary but not sufficient*.]

Let's rewind to the start of the project.

At the time, senior non-technical stakeholders grudgingly conceeded to the project being run "via Agile", because otherwise the engineers would have actually quit[fn:: More accurately, because the engineers and product team were so confidently dismissive of the way the stakeholders *wanted* to run the project. The tech team derisively called the stakeholder's desired approach "waterfall". The stakeholders didn't really understand any alternatives to "waterfall", but they've been around software development for long enough to know "waterfall" is Bad, so they didn't force the question]. But those stakeholders extracted a concession of their own from the product team: a commitment to complete the project by Q2 of the following year.

At the time, Q2 was a full nine months away. The engineers didn't love making this kind of long-term commitment, but they believed they had no choice but to give the business *some* kind of promise. They looked over the high-level PRD's from the product team and said "It looks like we should be able to finish by Q2 *if there are no horrible surprises*".

The product team said "Of course, we understand." They even made a good-faith attempt to share that caveat with the senior non-technical stakeholders. But, surprisingly appromixately no one, those stakeholders neither understood nor accepted those caveats. Instead, after meeting with the product team, they immediately turned around and told the Rest Of The Business, "The engineering team has committed to a Q2 launch date." The Rest Of The Business said "Great, thanks," and started basing all their own plans on that date.

What happened next?

The engineers sat down and broke the work down into *increments*. That is to say, they decided what they would build first, what they would build second, etc. The product team wasn't closely involved in the development of the increments---they considered themselves a consumer of this process.

The engineers, led by one of the senior engineers, used a very common approach to develop their increments: they first broke the planned system down into a set of components, then ordered the development of those components in a way that felt natural to them. The choice of order didn't feel particularly high stakes to them---no matter the order, they'd ultimately have to develop all the components. In this particular case, they decided to start with something fairly easy first, to build some momentum.

Once the engineers had the increments, they estimated each, then the product team turned all of that into a schedule with milestones and deadlines. The product team then cut a good bit of scope, to ensure there was a comfortable four weeks of padding at the end of the project, in case anything went wrong.

And the engineers got to work, in their (well-observed!) agile process.

Now.

No one knows it, but, in this moment, the team is already doomed.

Why?

Because they've chosen their overall increments arbitrarily and poorly.

As a result, they will make horrible discoveries very late in the project, when there are no good options to adapt and still deliver something valuable. They have not engaged their stakeholders in any discussion around the increments, instead treating them as internal to engineering and product. As a result, none of those increments deliver something that is at all *useful* to their stakeholders. Thus, there's no point, before the very end of the project that they could decide, with their stakeholders, to take a partial win, and move on.

Fundamentally, they have not chosen their sequence of work to *create incremental value*.

Despite the team working in an agile fashion day-to-day, the company as a whole only seems to see any value at the very end of the project. Which is the opposite of agile.

Now, you might be thinking, "This is why teams should *always* build an end-to-end solution, from day one." Actually, *no*. There are plenty of cases where that is *also* the wrong incremental breakdown. I have seen a great many projects go horribly off the rails because the team started by building a clever-looking end-to-end prototype, and then discovered far too late that they couldn't actually deliver even vaguely what they had promised, due to a profound misunderstanding of some constraint deep in the guts of a key data source.

There isn't one true sequence to building complex software. It requires an act of creative design every time.

Depending on the context, each of the following could be the key first step:

 - Build something crude that satisfies a subset of users with a subset of planned functionality

 - Build an interactive-but-fake protoype of the complete set of planned functionality

 - Build a single backend component in full, rigorous depth

 - Build lightweight versions of all the backend components, and wire them all together

 - Don't build anything, but instead do a deep dive into a key data source

Of course, if each of the above could be the key first step, each of the above can also be the *exactly wrong* first increment, setting your team down the wrong road.

If you want to avoid getting trapped in a situation where, no matter what you do, there is no win for the business, you need to understand how your team can create incremental value. That will allow you to, with careful increment design, offer your business counterparts a steady series of options for when to *stop* and still realize value.

And here is the absolute key.

An engineering team can create incremental *value* for their company, even if they're *not* shipping software that is incrementally *useful* to any users.

...what?

Value is *not* only created by usable software.

...but doesn't the Agile Manifesto say working software is the measure of progress?

Yeah, sigh. The Agile Manifesto is legitimately great, but they got this one wrong.

Let's dig in.

# The engineers had, of course, complained that the product team hadn't sufficiently defined the product for them to give a good estimate. But they always made that complaint.

# The product team complained (to each other, over drinks), that the engineers weren't willing to stand behind their commitments.

** Callback to Previous Post

In our previous posts in this series, (Link, Link), we developed an understanding of how engineers *create value* for their companies.

In order to understand value, we dug deeply into how investors determine what a company is *worth*---also known as the "valuation" they assign a company. Because an investor's valuation of a company is based on a guess about that company's future profits, we came to understand that the work an engineer does *creates value* for their company if that work:

 - Increases a probabilistic estimate of future profits...

 - made by an economically rational investor...

 - who possesses information known both inside and outside the company.

We named a specific, economically rational investor *Bertha*.

Armed with this fuller understanding of how value is created (and our made-up person!), we're ready to explore various kinds of engineering work.

# In particular, we're ready to analyze [explore, dig into] a wide variety of different *demands* that are frequently made of engineering teams, by people across the company who believe that solving problems in their area will certainly absolutely for sure no questions asked create value for the company.

# We will develop the key questions to ask, to determine if those people are correct or misguided in their beliefs about what engineering should work on.

# XXX Make Above Suck Less (MASL)

We'll start by digging into how value is created *incrementally*.

This is absolutely key. Our model of value creation is of no use to us if it can only be applied at the scale of a year-long project. To win at software development, you need to steadily make good decisions on a weekly and daily basis. To support that, we'll need a *fine-grained* understanding of value creation, operating at the scale of months and even weeks. Then, as we go through our planning cycles, we'll be able look at potential increments our team could build, and use our understanding of value to select the best one. That will allow to steadily hone in on *visible wins* for our business.

# [that will create the most value.]

Working on a software project that will hopefully create value is a bit like launching an expedition to cross an unknown sea, and hopefully find a city to trade with on the far side. There might be a single narrow passage to that far shore, savage storms might arise, there might not even be a city in the direction you're initially aiming in.[fn:: Have you ever worked on a months or years-long project which was, ultimately, a total failure? Did that not feel like you'd utterly lost your way? Like you'd been blown so far off course, you couldn't even remember what you'd been trying to do in the first place?]

# What is useful about this metaphor is that it makes it enormously clear that you can't make all your big decisions up front and stick to them.

You can't make all your decisions up front and then just stick to them.

You need to *steer*, every day and every week. You need to constantly update where you're trying to get to next, based on what you've learned so far.

An understanding of value creation will let us *steer* as we build.

So we can ultimately arrive at a form of business success so obvious that no one can deny it. Actual present money flowing in, right now, not just in probablistic estimate form.

# day-to-day. It will, if you'll indulge a lofty metaphors, allow us to cross a choppy sea of uncertainty,

But we need the guidance on what to do, each day, to get to that far shore.

Let's dig in.

** Incremental Value Is Created By Acquiring Evidence

# The Acquisition of Evidence

# Let's start with a classic tension:

# Stop me if you've heard this one before:

Let me sketch in a situation that you've definitely never heard of before or experienced personally.

 - Your company desperately needs a new product, it's all the CEO can talk about

 - Your engineering team desperately needs to stop clawing their eyes out every time they deploy to production

How should an engineering decide what to do with their next increment of work? Should they work on a new product, or on smoothing out deploys? Which will create the most value?

One common way to frame the question is: should the team work on the *business* problem (new product), or the *engineering* problem (deploys)?

Hold it right there, Mr Common Way: these are *both* business problems. They are both opportunities to incrementally create value.

But which of those opportunities should we work on *today*?

It's depressingly common for people to consider the new product opportunity much more urgent because it seems like the only way to create "immediate" value. A reduction in deploy pain feels a lot less urgent, because it will take such a long time for that improvement to impact profits for the business (and we just said profits are value, right?)

That perspective is *profoundly wrong*. Remember, company value is a rational investor's *current* probabilistic estimate of *future* profits. Therefore, crucially, value can accrue *immediately*, even if the actual increase in profits will take a very long time to land.

What?

Let's see how this could happen.

It's a Tuesday morning. Bertha, our economically rational investor, is having her mid-morning tea. As she drinks her tea... something... happens. That... something... causes her to change her beliefs about your company. She suddenly becomes much more optimistic. That something makes her *double* her probabilistic estimate of future profits. Now, Bertha is standing in for all rational investors, so if she changes her mind, so will the mass of other investors. And the value of a company is simply what those investors are willing to pay for it. So, in that moment, whatever the... something... was that made Bertha change her mind has made the company as a whole *immediately* double in value. In the moment she changed her rational mind.

Why on earth would Bertha suddenly change her mind about expected future profits?[fn:: She's *rational*, so you can't answer "There was something in her tea." Even if you're kind of tempted to.]

For exactly one and only one reason: beause she sees a new piece of *evidence*.

Bertha *only* ever changes her estimate of future profits if she sees evidence. That's what it *means* to be rational.

Does this idea of doubling an estimate of profits due to new evidence seem ridiculously far-fetched? In 2024 and 2025, this is *precisely* what happened to a variety of companies in the AI space. Their valuations skyrocketed as evidence accrued about the potential for AI to generate massive future profits. And those valuations went through the roof even though every single one of those companies was, in the present, incredibly *unprofitable*. They were all sinking just incredible amounts of capital into building models and data centers, and losing money just as fast an investors could hand it to them.

Now, for most teams, there's nothing they can do to get Bertha to double her estimate of future profits by way of a single piece of evidence. But there's a great deal they can do that will cause her to slightly increase her estimate.

If a team somehow gets economically rational Bertha to change her mind this way, that team creates some value for their company *immediately*.

A team that creates evidence, today, of a future increase in profits creates incremental value, today.

Let's dig in to our decision between "building a new product" and "improving deploys" to start to see how this model can be used.

# Let's see how that plays out for our two potential investment opportunities.

** Evidence For New Products & Deploy Improvements

For the new product, a form of evidence that would cause Bertha to change her estimate of future profits would simply be customers *purchasing* the new product.

But even best case, that's likely months or years in the future.

What might be some incremental forms of evidence?

Maybe the team has built a rough prototype, and the sales team took that into the field. Every customer who sees the prototype is excited, and starts talking about how, exactly, they'll find budget to purchase.

That would be powerful evidence.

Or, even earlier, maybe the team had conversations with customers and discovered that customers are already spending money to try to solve the problem the product focuses on.

Each of these outcomes would provide Bertha with a different form of evidence that this new product will allow the company to keep growing revenues, and therefore profits, over time. Each of those pieces of evidence would therefore, in the moment they were acquired, immediately increase the value of the company (by different amounts, to be clear)[fn:: Current revenue *is* a powerful predictor of future revenue. Which is why investors short-hand valuation by simply picking revenue multiples. But, inside a company, as we're evaluating fine-grained activities, we need a more nuanced model].

A team that *acquires* that evidence therefore incrementally creates value for the company.

How could incremental value creation work on the deploy side?

First off, we're going to say that, because Bertha is rational, she has read Accelerate [link]. She therefore understands that frequency of deploy is predictive of an increase in future profits. (Yes, your CEO may not be as rational as Bertha, see some ideas in [link] for how to get buy-in to this kind of technical investment).

As above, we can work backwards in time to earlier and earlier forms of evidence.

If the team can demonstrate a significant increase in deploy frequency, Betha would happily increase her estimate of future profits.

But that might take a long time to achieve. What are some incremental steps, that could cause Bertha to increase her estimate?

The team might, after some work, identify a bottleneck in the deploy process. Bertha would see the identification of the bottleneck as evidence that the team will later be able to improve deploy frequency.

It could even simply be the team *measuring* deploy frequency, if it wasn't measured before. Again, a rational investor would see that as improving the odds that the team can later improve the frequency of deploys, and therefore, in the moment the team was able to start measuring, would immediately increase their estimate of future profits (by a small amount, to be clear).

This may sound a bit abstract or hard to believe, but, in extreme cases, almost all engineers already intuitively understand this.

# Name the engineer? Jorja?

Say an engineer joins a B2B SaaS company, and knows that they were hired because the company urgently wants to build a new product over the succeeding year. However, on their first day, that engineer discovers to their horror that the company only ships to production *once per quarter*. In such a situation, just about every engineer I know would tell their leadership that improving deploy processes should be their top priority.

That engineer would not make that case because more frequent deploys "feel good" to them. They'd advocate for that work because they know in their bones that their new company has absolutely zero chance of shipping a new product in a year if they can only deploy to production four times during that period.

If that engineer then managed to get deploys happening *once per week* (aka c. 10 times more often), they would feel like they had created a ton of value for their company.

*And they would be right.*

# Say that, after their first two months of work, the new engineer has cleaned up a variety of issues, and now, when they look at their little deploy frequency graph, they see that, for the most recent three week period, deploys were happening once per week. A fully economically ration investor who understands the impact of deploy frequency on product development would look at that graph as *evidence*, and based on that evidence, would *immediately* ascribe a higher likelihood of the company successfully developing a new product and thus increasing profits.

# The moment that graph exists, and could be shared with a rational investor, the company *immediately* becomes more valuable. Even if the actual revenue comes in much later.

The acquiring of evidence is one of the most powerful ways to understand the incremental creation of value.

Of course, there's every chance that your key stakeholders neither understand nor believe this. That's okay! By having this understanding yourself, you'll be able to advocate for work which, over time, pays off.

You might be thinking: but we can't quantify this! And if we can't quantify it, how can we possible use it to make decisions? This is a fair concern. As we dig into the various ways evidence creates value I think you'll find that there are often continuous tradeoffs happening, so you don't need much in the way of precision. But I'm super curious about exploring quanitification as a means to unlock rapid decision-making. If you've taken a shot at making that work, please let me know what you've learned! Or if you *want* to take a shot at making that work, ooooh, please reach out!

To understand how to apply this model for understanding engineering work, we're going to dig into a variety of situations, and illustrate the key questions you can ask, if you want to maximize the value you and your team can create, with the hours of work you're spending, right now, by asking: "What evidence would Bertha need, to increase her estimate of future profits?"

The evidence/estimate frame will cast a light into many murky areas.

** [Bad Prose] Why The Classic Agile Skateboard To Car Cartoon Is Wrong

# Aka,

You know that classic cartoon that depicts what agile is and isn't?

If not, here it is:

[link]

I want to make a case that this cartoon is both profoundly right, but, in a *very* important sense, also profoundly wrong.

Let's start with the ways it's right (and therefore has seen deserved, widespread popularity).

There are two things that the cartoon captures, about a well-run agile project.

First, by steadily building something that customers can *use*, you can get feedback from customers are you. The customer goes from sad to happy in increments, each of those is a chunk of evidence that you're moving in the right direction.

Part of why waterfall fails is that it doesn't let you check as you go, to see if what you're building actually makes customers happy. Building something simple and then expanding outward is often (thought not always!) the right strategy.

The second thing that the cartoon usefully hints at is more on the engineering side. At each step, there's an end-to-end thing. Another classic failure more of waterfall projects is to build big, complicated things in isolation, and delay the integration of the parts until later. That leaves far too many nasty surprises.

Okay, if that's all right, why is it also profoundly wrong?

Two things.

First off, it's far too linear. No one gets anything wrong or has to learn and adapt. That's so fundamental to value creation, the cartoon damagingly suggests that you're just marching along, making customers happier and happier, with an ever-and-ever better machine for transportation. This is just not at all how it plays out in reality.

Second, increments of value are often created *not* by simply making customers incrementally happier, but by various action which create evidence. In our model of a set of possible product opportunities, *identifying* a good one, or eliminating a bad one, create considerable value. That doesn't show up in this visualization at all.

Let's see how that could look, for a team trying to develop a new product, in cartoon form.

First off, a smart team doesn't start with a product (aka solution) idea, instead, they start with a customer *problem*. See Escaping the Build Trap for more on this.

[Picture of an upset customer]

But, again, remember, we're thinking in terms of pipelines and portfolios. So they start with a *set* of such potential problems, ala:

[Picture of 5 upset customers, maybe numbered, or different kinds of upset? Different strings of sweary characters? Maybe in different boxes]

[Dotted/faint lines emerging from a single box to five other boxes, fanning out, all very faint]

Each of those could lead to a further work:

[Show multiple lines fanning out from each of those.]

For their first increment, they're trying to pick one of the customer problems to work on. They don't currently have a good estimate of the likelihood of success (aka increase in profits) from going along each arc.

They want to create evidence to make a decisin.

In their first increment of effort, they do a mix of a couple of different kinds of work.

For some of the problems (say, "#!" and "@#$"), the team is quite confident they can build something. But they're deeply uncertain if this is, like, a genuinely painful problem for customers, or just something they enjoy complaining about.

To learn more, they dust off their copy of The Mom Test and talk to a bunch of customers.

[Maybe, picture of someone asking someone else questions, wearing a mom t-shirt?]

But, for this other one, they know customers care intensely about it, but are completely unclear on if they can even solve it (maybe it depends on having access to data  they're not sure they can get).

For that one, the engineering team does a spike of research, actually building a bit of their data collection, to see what's possible.

[Picture of either someone typing, or maybe of the team building some weird bits of a machine, in a test lab]

At the end of the increment, they've collected evidence of which path is most likely to lead to future profits.

[Picture of one arrow coming out being much thicker or darker or colored green, maybe label all the arcs with estimates of future profits, all quite low, based on what is currently known]

Someone therefore can *make a decision* about what to do next.

So they move on to the next increment:

[The box darkens]

Again, there are key questions to answer, that will determine what they do next. Having selected a problem to solve, perhaps they're now understanding how a product that they can build actually *will* solve that problem.

[Show the fan out from the current box, make it clear what it is. Save for later the arrow that runs back to the earlier box, but add that before I move on]

What should the team do in this increment? Again, remember that they want to increase the odds of improving future profits. Therefore, ultimately, they need to pick which arrow to follow, which subsequent box to move to.

Remember how someone made a decision? Well, they need to do that again.

You'll notice something, perhaps. Once you understand that value creation means picking your way, in a exploratory fashion, across a graph of options, you can understand that the key thing a team is doing, during each increment, is enabling a good decision about what to do next, aka, what edges to choose out of the current node.

There's a marvelously powerful thing this unlocks: build your milestones explicitly around decisions. I'll write more about that in a subsequent post.

Gotta have a footnote about Maxwell's Demon, who always just picks the right thing to work on, in every moment. Some sprint team should be named Maxwell's Demons. Or maybe Maxwell's Daemons.

Walk through the math on how going into a node, and then coming back out, increases value.

What... is the math? The expectation can be improved by digging in? But shouldn't that fit into the expectation? The expectation can go down, due to bad discoveries. So then something else becomes higher expectation.

Or maybe also show that these expectations, early on, are quite broad.

Based on what is known now. So we *don't* bake in the assumption that the team will do smart things.

So, early on, it's gone from very low odds to, one of them being, like, sliiiightly better odds, but just barely. So then, the returning to the earlier one is an increase, and it's not like you're going from 70% likelihood and dropping back to 20%.

But if you do, that's okay! Kill early.

Can draw out the point that startups mostly don't work this way. VC's do. They just invest in a variety of things, are clever about making sure they can maximize the wins, and then try to convince a bunch of impressionable young people that their best odds of making money is to commit to a single idea.

You are the dice.
** How Do People Make Demands Of Engineering? Let Me Count The Ways

To think about the kinds of work engineers can do, I'm going to speak to the kinds of requests made of engineering. Except, to match up more fully with my lived experience, I'll name them as "Demands", not "Requests".

# We're going to start each one from the perspective of a "problem" that someone might want an engineering team to solve. We'll characterize those as "demands".

I'm going to break the demands made of engineering into a few buckets, based on where, in the organization, I've typically seen such demands come from. Why do this? People rarely come to engineering teams with truly clear thinking about overall company value creation and their place within it. Rather, they're just about always worried about some local problem for their function, which they then try to dress up in impressive and/or moralizing terms (e.g. "This is a huge opportunity!", or "Don't you care about the customer?!")

So, by looking at the different buckets, we can develop means to map from the "local" concerns of those functions to overall company value. Which is what we need to do, if we're going to make good decisions about which problems to solve, aka, how to spend our time.

*** Sales & Marketing

Typical demands:

 - Develop new products

 - Add features to existing products

 - Fix bugs in existing products

*** Internal Operations

E.g. the customer support desk, the data ingestion team, a business intelligence group, the warehousing and fulfillment teams.

Typical demands:

 - Automate repetitive work

 - Handle exceptional/severe problems

 - Add support for a new operation

*** Engineering

Typical demands:

 - Clean up or replace "bad" code

 - Upgrade or retire old infrastructure

 - Make it easier to deploy changes to production

 - Address system performance issues

*** Product

Haha!

The product team is the people of whom demands are made! They have the awesome power of saying no to people (aka prioritization), and with it the attendant awesome power of everyone being kind of mad at them, all the time!

This is the "product function" at its heart---disappointing people by saying no.

If you don't have a product team, or if your product team seems to be kind of a project management team in disguise, you can figure out who is serving the product function by asking: Who gets to/has to disappoint other people? Who decides which problems are important enough to solve? Who continually updates their understanding of reality to adjust the answers to those questions as you go?

There are plenty of situations [cases, times] where the person doing the "product funtion" is actually an engineering leader.

One sign that this might be the case is that various IC engineers on the team are frustrated with that leader for "not allowing them to deal with tech debt".

Engineers are, to a first approximation, *always* frustrated with someone for not letting them deal with tech debt. if the engineers focus that frustration on an engineering lead instead of a nearby product manager, that could be a clue about who is serving the product function.

** Who Evaluates Demands of the Engineering Team?

Company value is created by acquiring *evidence* that will increase Bertha's probablistic *estimate* of future profits.

How can an engineering team create value, when confronted with the kinds of demands we've just sketched in?

What questions should they ask, to orient?

What answers might they hear that could make them push back?

"Wait", you might be saying, "isn't this the product manager's job?"

"In fact," you might further say, "didn't you just tell me, Dan, that the product team is the one of whom demands are made? Shouldn't *they* be digging in, on these questions?"

Look, I'm going to be blurring the line between engineering and product here, and *I make no apologies for this*.

I have *never* seen a high-functioning engineering team where the engineering lead wasn't able to think like a product manager. So, if you're an engineering leader, even if your product peer will ultimately make the prioritization calls, I *highly* recommend that you understand how your team's work could ultimately turn into value for the company. To excel at your job, you need to be an *active partner* in that prioritization decision.

Note: if your product peer doesn't currently seem interested in that kind of partnership, being able to speak to potential value can be a very powerful way to gradually change the dynamic between you. Unsurprisingly, this is a common topic of my coaching practice: helping engineering leaders earn their way into a greater degree of influence and partnership. I wrote about a form of this in <Fixing the Engineering/Stakeholder API>.

On the other hand, if you're a product manager, I think I'm describing a core function of your job? Hopefully that's kind of useful?

"But wait, Dan", you might still be saying, "my team doesn't have a PM."

I have seen... some... high-functioning engineering teams that didn't have a PM.

But, honestly, not that many. There's simply too much to do, across the two functions, to have one person have both the skills and the capacity to handle both. If you get rid of your PM's, your "product-minded" engineering lead can easily find that that they're spending all their time talking with stakeholders and/or trying to triage concerns from the help desk, and/or preparing for meetings with the exec team, and/or trying to quickly learn customer interview or presentation design skills, etc. Aka, they're just being a PM. And, every day, they're feeling like they're doing an increasingly bad job of staying on top of the evolving architecture of their systems, or mentoring promising early-career engineers, or steadily flushing out key risks and opportunities, etc. Aka, they're not being effective as an engineering leader. There's a conversation I find myself in, not infrequently, with young engineering leads who have found themselves in this situation and are thinking about leaving their jobs.

In short: I believe Product Managers can be *extremely* valuable! Don't get rid of them lightly!

Yes, at a somewhat painfully wide variety of places, the PM's may be doing a poor job (though I'm always suspicious of structural reasons as well as weak performance). In my in-no-way humble opinion, the optimal answer is just about *never* to simply get rid of product. I believe this passionately. (again unsurprisingly, this is very much the kind of thing I help my coaching clients wrestle with).

Okay, I'll get off my soapbox now.

** Sales & Marketing Demands

First off: Sales & Marketing-sourced problems are somewhat distressingly often seen as the only economically valuable problems for the engineering team to work on.

Of course, company leaders won't say it in those flowery academic words. They'll instead talk about adding new products or fixing bugs as addressing "actual business problems", or "being customer-centric". By which they're demonstrating that they consider problems identified by other parts of the business as *not* real business problems, or as not serving the morally pure purpose of centering customers[fn:: Look, if you've managed to work at a company where a push to be be "more customer-centric" *didn't* immediately become a means for powerful people to sabotage the prioritization process by elevating their evidence-free opinions about customers into moral imperatives, I'll be thrilled to hear about it. But I am batting negative one thousand on that one.].

We're going to avoid falling into that trap.

*** Develop New Products

This one feels obvious, right? If the engineering team can build a new product that customers will pay for, then Bertha, our economically rational investor, will happily increase her estimate of the future stream of profits, and thus the value of the company will increase.

Great, we can move on---

Waitwaitwait.

Understanding value creation *during* new product development is a total cesspit of confusion. In particular, there are a couple of extremely common anti-patterns to watch out for.

Here is the absolute key to understanding the *incremental* creation of value, as you work on developing a new product:

Bertha, being economically rational, *doesn't think you're going to succeed*.

Most new product development efforts *fail*.

Most new product ideas *fail* (especially as they are initially conceived of).

# Everyone at your company are sort of joining hands and agreeing to pretend this isn't true. Because it would be depressing to go to work every day on something you thought was likely to fail, right? Trick: turn failure into success. How, by adopting a portfolio/pipeline view, and celebrating evidence that lets you winnow bets out of your portfolio. Most sales calls do not turn into conversations. Does the sales team spend an incredibly long time debating about who to call? Or staying on the line with someone who is clearly not going to buy? No, they put in their hours, they "build pipeline", and they spend their time wisely.

An economically rational investor will look *extremely suspiciously* at your CEO's optimistic PowerPoint deck, the one that explains how the new product your team is going to develop will double revenue over the next three years. Bertha has seen *plenty* of such decks. Very few of those companies actually achieved the promised increase in revenue (and, essentially *none* achieved that increase in revenue without significantly changing their original plan).

To understand value creation in new product development, you should think of your company as considering a *set* of product ideas it could potentially invest in. At any moment, your company doesn't actually know which product ideas (if any) in that set will turn out to be both valuable for customers and feasible to build.

A rational investor will therefore assign a weighted average across all of them -- and, unless you have evidence, that weighted average will be *very* low (because so few product ideas work out)

# If, say, on average one out of ten of product ideas turn into a modest increase in profits, then Bertha's *current* estimate of future profits will be one tenth of that modest increase.

Given this context, value is created during new product development by two activities:

 - *Learning* which product idea, if any, are both valuable and feasible

 - Actually *building* those products

The best teams *interleave* these two activities, so that they iteratively hone in on a product customers will pay for, steadily learning and adapting as they go.

There are two classic failure modes companies fall into, here:

 1. They try to do all the learning before they start building

Aka, conduct full market research before a team can start, try to analyize it all up front, and then fully commit to a single bet.

 2. They try to do the building, "as fast as possible", by not slowing down to learn as they go

Just go with what some executive is "certain customers want", and don't do anything to learn from customers and/or reality as you build.

Given that evidence creates value, a team building a new product should be eagerly pursuing evidence. They should bias towards building to learn -- building their product in a smart sequence that lets them test their biggest risks at every moment.

For more on this idea, see my talk Risk, Information, Time & Money

*** Add Features To Existing Products

*** Fix Bugs In Existing Products
* Scraps/Thinking
** Morning Walk Thinking <2025-09-28 Sun>
I've got a tiger by the tail.

I do like that I'm speaking to the "immediacy" of value creation.

Could maybe back up and frame the entire thing around increments, around the incremental creation of value.

Why are increments important?

So you can stay on track -- building a big piece of software in increments is important because it allows you to learn and adapt.

The exact same thing is true of all software work -- you need to see if you're creating value, and if you're not, adapt.

But the increments are tricky.

Maybe, show the classic Agile skateboard picture -- this is profoundly wrong (even though it's usefully right, at the same time). Yes, you should hook your software up all the time, but you shouldn't always have a thing that is useful to a user.

The first picture is asking someone about where they need to go every day

The second one is building 5 different engines and testing them.

The third one is experimenting with different sales models.

Could I show that with arrows going off in different directions, so it's finding a path through decision space? Visually? That's an interesting idea.

And that does maybe give me a way to make clear that each moment, each key milestone, is a *decision*, not a deliverable.

I still want to find a way to give the reader that sort of actionable, useful when/not useful when.

Definitely frame the portfolio/pipeline thing as a way to make the economics manifest, and enable better decisions. And to unlock good bits of human nature, and point stakeholders at useful decisions.

Also, this is clearly exploding into something between a series and a book, embrace that.

Key Q: if I want to touch both on the immediacy of value creation (the incremental creation of value), *and* some specific tactics for new product dev, should I make that one post or two.

It could be two, as long as the first is grounded enough in reality to not be purely abstract.
** Random Thinking
The "this is valuable when/not valuable when" thing worked super well.

I do really like the idea of unifying across product/engineering/operations, showing them all with a common, true view.

What if I make a central point about the unification, so I can show both top-down and bottom-up concerns through a common lens?


** Good/Bad Engineering Activities
*** Rapidly Banging Out Prototypes
*** Building Complex Data Pipelines
*** Cleaning Up Horrible Code
*** Investing in "DevOps" or "Dev Experience"
*** Retiring/Upgrading Old Infrastructure
*** Developing New Products to Expand TAM or $/Customer
*** Adding Features for Big Customers
*** Making It Possible to Sell to Smaller Customers
*** Making Internal Operations Easier
*** Making Onboarding Easier
*** Writing Lots and Lots and Lots of New Code, Super Fast

** Contextual Situations
Can I run that through. What are my four forms of value so far?

Existing Forms of Value:

 - "This Code Is a Nightmare From The Black Depths of Hell"

 - "Deploying To Production Saps My Will To Live"

 - "I Can't Find a Moment to Think"

 - "The Database Is On the Verge of Death And No One Cares"


** Possible Titles
Turn "Engineering Concerns" Into Potential Value, I

The Landscape of Potential Value

The Unifying Force of Potential Value

Seeing Engineering Work Through the Lens of Value

Engineering & The Creation of Value, Part III


** Scrap
It covers both "simple" situations, like closing new customers who add to this year's top-line revenue, but also more nuanced ones, like, a team that rapidly chews through three different product hypotheses, invalidates two of them and makes a critical discovery about a third. That key discovery creates *evidence* that the company is on the verge of building a valuable new product. Bertha, in reviewing that, may even consider that action as having created a greater probabilistic increase in future profits than closing a few new customers (though, note, closing those new customers can create evidence that the company can keep growing, which, in some situations, might be the most important evidence of all).

* Mini Todos
** TODO Rewrite opening to focus on value of increments
Possibly use the "waterfall in disguise" there
** TODO Throw in link / quote to Rewrites post
** TODO For New Product + Deploy pain, show bad alternatives (first?)
** TODO Maybe: separate New Product + Deploy Pain
So that I'm not asking to compare them, I'm saying, how do you see value here.

Maybe, start with Deploy Pain, since it's less obvious.

And then, I can do my "New Product" is obvious, right? Not, really
** TODO End with teaser of "How do you select the most valuable increment?"
Or is that "which evidence is most valuable?"

So I'm setting it up for "The one that steers into the biggest risk" = gathers
** TODO Further tease for "how do you set goals for teams"

* Old Turn "Engineering Concerns" Into Potential Value, I
** Intro
# Getting a Handle on Interruptions

# Hmm, When You Put It That Way, That Does Sound Pretty Important

# Can Bertha Help Tame Interruptions?

Now, armed with a fuller understanding of value [link], we're ready to look at issues engineers tend to be concerned about.

We'll look for ways to turn those from vague worries into potentially valuable *investment opportunities*.

We'll ask: What Would Bertha (our economically rational investor) Say?

Then, we'll share ideas on how you to make the potential value *visible* to stakeholders.

Today, we'll dig into one such challenge, which engineers might experience as:

** "I Can't Find a Moment to Think"

Wouldn't it be great if your engineers had time to, say, *do software engineering*?

But instead, every day they face a relentless stream of *interruptions* from people across your company:

 - *People who work directly with customers pinging them about bugs and feature requests (and bugs that are actually feature requests)*

   Every one naturally at the highest priority!

 - *Follow ups and status checks and nudges about those bugs and feature requests (and bugs that are actualy feature requests)*

   And I have some bad news.

   People who work in sales are often very good at advocating for issues that affect "their" customers.

   I mean, look, they didn't get into sales because they're *bad* at persuading people to do things![fn:: I once asked my friend Marion, who was running sales at Ellevation, what it's like to interview sales people, who are, by their very nature, skilled at presenting themselves optimally, and she rolled her eyes and said "Oh my god it's the worst".]

 - *Weird bits of operational work only engineering can do*

   The still-largely-manual work to set up data integrations for new customers, or the monthly data pull for the BI reports.

Worse yet, the interruptive requests often fall most heavily on your most experienced engineers (because they're the ones who know how to solve all the wonkiest problems)

And that's *especially* true if those engineers suffer from the misfortune of *being nice*.

(I have vivid memories of standing by Tom Hare's desk at Wayfair, watching just a parade of people from the operations teams "wander by", each asking for Tom's help to fix some weird edge case. Tom was such a good engineer! And so nice!).

# That said, he did end up marrying one of those ops stakeholders -- hi Lauren! -- so I guess that worked out okay in the end?

*** Potential Value: Reduce Opportunity Cost *And/Or* Improve Operational Outcomes

This situation isn't just *unpleasant* for the engineers.

It may represent a serious *opportunity cost* for the company as a whole.

As in, there might be something else, that the engineers *could* be doing, which would create *more* overall company value than their current work.

But, and this is important, just because the current work is interruptive and not much fun, *doesn't mean it's not creating value*.

So we're going to dig in, with Bertha at our side, to understand the situation in more detail -- and then be ready to advocate.

Let's imagine the engineers on the team spend, among them, a few dozen hours each month doing the following two "distracting" things:

 1) Fixing edge case bugs for a small set of extremely vocal customers

 2) Setting up data integrations for the customers who onboard in that month

What is the value being created by each of these activities?

aka, what is the effect on Bertha's probabilistic estimate of future profits?

That is what we'll have to understand if we want to make a case for the engineers doing *something else*.

Let's take them each in turn.

*** 1) Fixing Edge Case Bugs

Aka, Sometimes We Should Just Let the Wheel Squeak

Let's imagine that the engineers and/or their PM's do some investigation and discover the following things are true:

 - These customers represent a tiny fraction of the company's revenue

 - They're not particularly *representative* customers

   A common case for this is that they were acquired *early* in the company's history, but they're not actually in the key segment. But they have high expectations of responsiveness.

 - They are very unlikely to cancel -- although they're *always* complaining about bugs, but none of the customers have left in a long time.

In this case, it ;

# Likely nearly purely opp cost, key is how to make this visible, answer = a) lightweight tracking of time, then use that to b) set up triage to bring it out in the open, and c) force a one-time budget or cost.


*** 2) Setting Up Data Integrations for New Customers

aka, Enabling Customers To Use The Product They Paid For

Let's imagine that the investigation led to finding that there genuinely is no other way.

If they *didn't* do this, there would be some likelihood

Say that decreases the likelihood of those customers churning by some amount. Then we can look at the value of the

If, instead, theywhen they could have been developing a product that opens up a new segment for the whole business... that might represent a loss of overall company value (where, again, value is a probabilistic estimate of future profits).

But, of course, that tends to be completely invisible to stakeholder and decision-makers.

There are two distinct ways that Bertha understands the potential for value here, and thus two distinct forms of visibility.

First, Bertha suspects there might well be value for the company if the engineers could spend *less time* on all this interruptive work.

In this belief, she is likely heartily joined by both the engineers *and* their immediate stakeholders.

Spending less time on reactive work could free the engineers up to work on things that would be more valuable (hopefully) and more fun (definitely).

# more fun for them and more in keeping with the product team's immediate goals.

If that "other" work were likely to lead to greater profits in the future, Bertha will happily ascribe real value to replacing the reactive work with that "something else".

Visibility on this "engineering capacity" front is fairly straightforward: you want to simply make it clear *how much time* the engineers are spending on operational work (with some multiplier for interruptions, since they blow up focus).

Just viewing the capacity consumed by reactive work can sometimes motivate a real investment to speed up or fully eliminate interruptive tasks the engineers are currently responsible for.

You can build visibility into the "capacity spent on reactive work" by some combo of:

 - Surveying engineers on a regular basis as to how much time they're spending on the reactive work

 - Tagging and tracking tickets

 - Shadowing an engineer for a day or two

 - Setting up a formal triage process to bring reactive work out into the open

All of that can help create enough visibility to make a case for investment, in particular if there's a way to *reduce* the reactive work.

However, that's not the whole story.

The reactive work, thankless though it may be, is very likely creating *some* form of value for the business.

Bad news: *Bertha cares about that value, too.*

If fixing bugs, or restoring the site from outages, or correcting data issues in production keep customers renewing, then Bertha will not be happy if your team simply stops doing that work.

The trick here is to spend a bit of time understanding the *positive* value of what your team perceives as reactive work.

If you can really dig in on that side, you might be able to find creative ways to restructure how much work gets to your team, or make a real investment to eliminate a whole class of issues at a deeper level, or even, propose moving the work *off your team* altogether and finding a home for it somewhere else in the organization.

Those kind of major investments or shifts can be economically rational, but those aren't easy pitches to make, unless you can show the *positive* value to the business, *beyond* just saving time for the engineers.

E.g. say your engineers spend time every sprint helping set up data import configurations for new customers.

Even if they were to invest in better tooling, they can't automate it all away, because setting up each new customer requires carefully reviewing sample data files, testing out imports and diagnosing failures, helping the customers fix subtle issues on *their* end, etc.

Imagine you were go to an Important Person at your company and say, "We'd like create a dedicated Data Operations team"

And the Important Person looks august, and says, "Okay, why?"

And you say, "So my engineers can spend less time on new customer onboarding."

Here's a problem: there is a risk that Important People will hear that as a form of *complaining*.

Everyone's job has certain unpleasant and/or boring parts. Most Important People have developed the skill of ignoring complaints that they hear as: "Part of my job isn't fun, can I stop doing that part?"

You really don't want them to hear this suggestion in that light.

You might be able to make a more effective case by saying something like:

/"It currently takes three weeks to onboard new customers. Delays in the back and forth to setup data imports are the main driver./

/That work is currently being handled by the engineers, but:/
  /a) Engineers are expensive, and/
  /b) it often takes a few days for an engineer to find time to review a question from customers, which adds a lot of delays and frustrates customers./

/We'd like to talk about finding a better home for that work, so we can both improve onboarding times and reduce costs./

/Our early estimate is that 70% of the work can be done by the more technical members of the help desk, if we can carve out time for them, and the engineers can build some basic tooling."/

That's speaking to potential benefits -- both a better customer experience, but also lower costs and better outcomes *for the operation itself*.

There's a decent chance you can (and should) loop in your product team to help build this kind of case. It's usually not too hard to get their help, because they would love to have more of "their" engineers time devoted to "their" work.

There are other variations on this game plan you can run, be it setting up a regular collaborative triage process, or breaking off a separate platform team that owns a particularly troublesome bit of functionality (e.g. authentication and authorization is a classic), etc. We'll touch on a couple in the Case Book of Tech Investments later.
