* The Art of Increment Design, Part I: Help Us, Good Increments, You're Our Only Hope
# Only Good Increments Can Save Us Now
** Intro

Today's post is the first in a series about how to design effective *increments* when developing software.

By "increments" I simply mean: how to break up a large body of engineering work into a series of smaller steps.

I have come to believe that effective increment design is perhaps *the* most important skill of an experienced engineer[fn:: Breaking up a large system into distinct components (another fundamental skill), is sort of like decomposing across *space*. Increment design is decomposing across *time*, and, since time is unidirectional, that challenge is sort of interestingly trickier.]. I further believe that the design of increments should be a centerpiece of the conversations between engineering and product, and even stretch out to include the rest of the business.

To understand why, over the course of this series, I'll develop a nuanced understanding of how engineering work does (or does *not*) create value for an overall business (building on previous posts [link], [link]). We'll discover how some increments can, despite requiring a great deal of engineering effort, somehow create *no value whatsoever*. We'll also find how other increments, including ones where the engineers write very little code, can somehow create a great deal of value.

This understanding of value will ultimately give us tools to break large efforts into small pieces, and will *also* offer creative ways to mix in increments of value-generating work to address a wide variety of concerns, e.g. being able to deploy more frequently; ensuring a system can handle increases in load; meeting security expectations; etc.

Why is good increment design so valuable?

A teacher of mine once said, "The beauty of something is made clear by its absence."

Thus: what is life like, on a team that suffers from poor increment design?

My guess is that you, dear reader, may have actually experienced this first hand.

Let's see what that feels like.

# This theoretical foundation will give you a powerful way to reason about your work. With practice (and some further tactics, to be explored in subsequent posts), it will allow you to find a path through the shifting chaos of reality to a valuable outcome for your business.

# When I talk with engineers or product managers at tech companies, just about universally, their teams are using some form of agile to organize their day-to-day work. They have sprint teams, those teams do daily stand ups, they work in iterations of a few weeks, with some form of planning at the start of each.

# In a sense, the alternative to agile (Waterfall, natch), has "lost"

** The Perils of Bad Increment Design

Sometimes, in the middle of a dark wood, an engineer or a PM will find themselves on a team that is *doing* Agile, but that somehow doesn't *feel* agile in any way.

# Switch all to "you" in the below?

The team observes all the agile rituals, and observes them faithfully and well. Their sprints are a crisp two weeks long. They start each sprint on a Monday morning with a full team planning session. They gather every day for a stand up. As they work, the engineers steadily pull well-groomed tickets from the board. On the final Friday of each sprint, the engineers demo what they've built, and then the team runs a brief retro in the afternoon.

All that is as it should be, right?

In theory, yes.

But, in practice, there's a problem.

Somehow, the overall project is drifting totally out of control.

The team is far, far behind where they are supposed to be. Every lingering problem they finally tackle immediately sprouts three new problems, hydra-like. The PM is losing sleep, and wakes each morning from anxious dreams about their next update to the executive team. The engineers are growing defeatist and bitter. Every day they're asked to pile new expedient hacks on top of yesterday's expedient hacks, resulting in a system that is ever-more unstable. They've already missed all their key delivery dates, so there's no time to deal with any of the emerging problems. The engineers and the PM's have a growing suspicion that when they finally *do* ship the unstable, limited, badly compromised system, literally everyone will be angry at them.

This is, in fact, exactly what will happen.

# This is a team that is "doing waterfall with agile methods". Somehow, despite successfully applying agile *tactics*, they're still gaining the pretty nasty outcomes of waterfall.

How did this team get here?

How can we avoid getting to a similar place in the future?

Why didn't "doing agile" save them? I am a huge believer in agile as a way to organize the work of a team. But, unfortunately, agile tactics, as commonly practiced, are not enough. They are, in the precise terminology of mathematics, *necessary but not sufficient*.

Let's rewind to the start of the project.

At the time, the team was working closely with a senior non-technical stakeholder. That stakeholder, after a good bit of back and forth, grudgingly conceded to the project being run "via Agile", instead of the way, well, every other project they'd ever supervised had been run: with a task breakdown, and a schedule, and a PMO to ensure everyone stays on track.[fn:: Why did the stakeholder agree to this? Because the engineers and product team were so *confidently dismissive* of the way the stakeholder *wanted* to run the project. The tech team derisively called the stakeholder's desired approach "waterfall". The stakeholder didn't really understand any alternatives to "waterfall", but within their first five minutes of being even *near* software development, they had learned that "waterfall" is Very Bad. They didn't want to look stupid, so they agreed to try this vague thing that everyone assured them was their only option.]

# because otherwise the engineers would have actually quit.

But, that stakeholder extracted a concession of their own from the product team: a commitment to complete the project by Q2 of the following year.

At the time, Q2 was a full nine months away. The engineers didn't love making this kind of long-term commitment, but they believed they had no choice but to give the business *some* kind of promise. They looked over the high-level PRD's from the product team and said "It looks like we should be able to finish by Q2 *if there are no horrible surprises*".

The product team said "Of course, we understand." They made a good-faith attempt to share that caveat with the senior non-technical stakeholder. But, surprisingly approximately no one, that stakeholder neither understood nor accepted the caveat. Instead, after meeting with the product team, they immediately turned around and told the Rest Of The Business, "The engineering team has committed to a Q2 launch date." The Rest Of The Business said "Great, thanks," and started basing all their own plans on that date.

What happened next?

The engineers sat down and broke the work down into increments.

That is to say, they decided what they would build first, what they would build second, etc. The product team wasn't closely involved in the development of the increments---they considered themselves a consumer of, rather than a direct participant in, this "engineering process".

The eng team, led by one of the senior IC's, developed their increments as follows: first, they broke the planned system down into a set of components; then they ordered the development of those components in a way that felt natural to them. The choice of order didn't feel particularly high stakes to them---no matter the order, they'd ultimately have to develop all the components.

Once the engineers had the increments, they estimated each, then the product team turned all of that into a schedule with milestones and deadlines. Everyone then worked together to cut scope, to ensure there was a comfortable four weeks of padding at the end of the project, in case anything went wrong.

And then the engineers got to work, in their (well-observed!) agile process.

Unfortunately, in this moment, the team is already doomed.

# Clean up tenses in the below

They have chosen their overall increments arbitrarily and poorly. Even if they run their agile processes well, sprint-to-sprint, they are going to find themselves trapped, with no options as the work unfolds.

Why is this so?

One of the components will turn out to be impossible to build as they had planned. The absence of that component will trigger a ripple effect through the rest of the system, requiring enormous amount of rework and ultimately forcing a rethinking of what the product is able to do. Unfortunately, the team chose to work on that component *late* in their sequence. By the time they make this unfortunate discovery, their original launch date is only four weeks away. There are no good options to adapt and still deliver something valuable anywhere close to the plan.

Of course, missing plan isn't an uncommon occurrence. Why does this leave the team in such bad shape?

The engineers and the PM have not engaged their stakeholders in any discussion around the increments. Instead, they treated the increments as an internal concern of engineering and product. Therefore, none of the intermediate increments deliver anything that their stakeholders would find at all *useful* or valuable. There's no point, before the very end of the project that the team can decide, *with* their stakeholders, to take some form of a partial win, and move on.

One way to understand all of the above is that the team has not chosen their sequence of work to *create incremental value*.

Despite the team working in an agile fashion day-to-day, the company as a whole only seems to see *any* value at the very end of the project.

If a team creates incremental value, then, well, they can *never really lose*. There's no panicked anxiety looming over them, because they can always stop, and the Rest Of The Business will be some degree of happy---because they will have gotten *some* value. The Rest of the Business may not get everything they *expected*, but if the team can create some genuine value, a smart PM and engineering lead can find a way to help the rest of the business understand the win.[fn:: Effectively drawing stakeholders into collaboration around valuable increments is a profoundly interesting challenge. We'll return to that challenge, once we have an understanding of which increments are even valuable in the first place.]

** Sadly, Blind Adherence To One Approach Will Not Save You
*** Intro
Someone might read the above parable and think: "Ugh, Dan, that team made an /obvious/ mistake. Teams should /always/ build an end-to-end solution first, and then gradually expand outward from that. That's the True Agile approach. If they had done that, they would never have gotten stuck in such a pit."

Unfortunately, that approach, though sometimes effective... can *still fail spectacularly*.

I have seen projects go horribly off the rails even though the team started by building an end-to-end prototype and immediately sharing it with users. Those teams discovered, very late in their work, that they couldn't actually deliver even vaguely what that prototype had promised (because, say, they had badly misunderstood what data was available to them, or delayed facing some profound technical challenge or risk).

# a constraint deep in the guts of a key data source).

There isn't one true sequence for building complex software.

Designing good increments requires an understanding of how teams create value, and a good deal of creative effort to apply that understanding to a specific situation.

# Designing good increments requires creative effort---and then, continual effort to redesign, as the work unfolds.

Consider the following approaches. Teams are, possibly implicitly, considering something like this list when selecting their next incremental chunk of work. Individual engineers or PM's might advocate for something on this list as the One True Way to decompose a software project into smaller pieces:

 - Build something limited-but-real that satisfies a subset of customers with a subset of planned functionality

 - Build an interactive-but-fake prototype of the complete set of planned functionality

 - Build a single back-end component in full, rigorous depth

 - Build lightweight versions of all the back-end components, and wire them all together

 - Don't build anything, but instead do a deep dive into a key data source

Here's the thing: in different situations, each of those could be the exactly right next increment, *or* the exactly wrong one.

Because each can either *create incremental value* for the overall business, or can completely *fail to create value* for the overall business.

And, remember, increments that don't create incremental value are super dangerous. A succession of such increments will leave a team in a very bad place. Every increment of work must create an increment of value.

Let's dig into how each of the above could or could not be valuable.

*** Build something limited-but-real that satisfies a subset of customers with a subset of planned functionality

Creates Value If:

 - That subset of customers is representative of the full set of customers

 - The subset of functionality is compelling enough for those initial customers to actually use it to solve problems they care about

 - The team can build the useful subset significantly faster than they can build the full product

Does Not Create Value If:

 - The subset of customers has completely different needs than the rest of the customer base, so a product that satisfies them can not be expanded to serve all customers.

 - The limitations in functionality mean customers can't use it to actually solve their problems.

   Massive risk in this case: customers tell you how great the limited product /looks/, and they'll /absolutely/ use it once you've added just a few more features. You feel like you're making tremendous progress, but, once you address the remaining "blockers", it turns out the customers just wanted you to not feel bad and were lying to you, and none of them are willing to use or pay for what you've built (see The Mom Test for how to handle customers cheerfully lying to you in this exact way).

 - The limited subset rests atop an iceberg of technical complexity below the surface, so getting it working requires 90% of the time and effort of the full project.

   Massive risk in this case: the product team names that limited subset the "MVP", but it's more than a few months to build it... so the engineering team drifts into the "build the technical components in some random order" plan described above, with all its attendant dangers.[fn:: The term "MVP" has, sadly, lost just about all ability to function as a useful piece of product development discourse. Far too often it becomes "What bundle of features does a stakeholder insist a customer will want." Rather than fight over a better definition of MVP (e.g. "The next hypothesis to test"), I've had better luck just leaving the term MVP fully on the side of the road, and focusing on building a shared understanding of other terms.]

*** Build an interactive-but-fake prototype of the complete set of planned functionality

Creates Value If:

 - The engineering team is confident in their ability to build the complete set of functionality

 - It's hard or impossible for customers to imagine how the product even could solve their problems

   Customers are near-universally terrible at imagining software that they can't interact with. If the team can allow them to interact with something where they can successfully imagine using it to solve their problems, the team can achieve one of two outcomes, *each of which* is valuable:

   a) Customers not only get excited about the product, they start talking in detail about *how* they would use it to solve their problems, they talk about what they are currently doing to try to solve those problems, they beg to show it to other people they work with, etc.

   Value = Great, you've gotten validation + a partner for incrementally testing out your solution as you go.

   Or,

   b) Customers demonstrate *none* of the above evidence of commitment.

   Value = Great, you've learned that you shouldn't waste time building that full set of planned functionality.

   This latter result is *super valuable*! It creates the opportunity for the team to build *something else* that customers will pay for, when there's still plenty of time to do so. (We'll dig into this form of value creation throughout this series)

Does Not Create Value If:

 - The product has the nature where interacting with a fake prototype isn't enough for customers to imagine using it to solve their problems

   A classic example of this is when the product involves aggregating some complex set of the customer's own data. Showing such customers a slick-looking visualization tool on top of /fake/ data often fails to engage the part of their brain that is worrying about their problems. Which means you fall back into the risk of them trying to make you feel good by "being nice".[fn:: Fun fact: the best early increment in this case is often a *spreadsheet*, into which you've painstakingly hand-collected that customer's *own data*, and can then see what they do with it.]

 - The engineering team isn't certain they can build all the functionality

   If, by building a cool looking prototype, you learned that customers would happily pay for some Magic Solution, but your engineering team knew all along that they can't build the Magic Solution (because, y'know, *magic*), you've wasted a bunch of time, and have to start over, no with less time. This kind of "learning" does not create value.

*** Build a single back-end component in full, rigorous depth

Creates Value If:

 - The engineering team has real fears about whether or not they even *can* build that back-end component

 - The absence (or shape) of that back-end component has a major impact on the design of the overall product

Does Not Create Value If:

 - It might take a while to build that back-end component, but there's no question about whether or not it's *possible* (aka, It's "hard but not risky")

 - The absence of that back-end component would only change the ultimate product design in a fairly minor way

*** Build lightweight versions of all the back-end components, and wire them all together

Creates Value If:

 - There a lot of engineers working on this effort, and the company wants subsets of them to work in parallel on different parts of the overall system

 - The engineering team, at project start, has broad-based concerns about if/how they can tie all the pieces together

   E.g. maybe the system depends on threading some key pieces of data through the various components, but the team isn't certain where that data is available. Or some are system decomposition questions will have a major impact on the design of the product (e.g. maybe the team fears that some key step in the user workflow will have be completed asynchronously).

   One way to say the above is: there isn't something that can be shown to users that the team is confident they can build.

Does Not Create Value If:

 - It's going to take a while to build all those components, and it's not clear if customers care about the *problem* the product tries to solve.

 - All the risks and questions are concentrated in one component

   E.g. if your team is trying to build some form of domain-specific AI assistant, there's a good chance all you should be focused on is "Can we get that assistant to usefully answer questions about that domain?", and not string together all the other bits of a full solution (e.g. automatic ingestion of relevant customer context, a smooth UI to offer answers, etc).

*** Don't build anything, but instead do a deep dive into a key data source

Creates Value If:

 - The presence, absence or shape of the available data will have a major impact on what product you can build

Does Not Create Value If:

 - The team knows the data inside and out already

** Outro

# For many experienced engineers and product managers, various situations above will, hopefully, feel familiar, and the "good" options may even feel kind of "obvious".

What is the pattern behind all of above?

How can you reason about your exact situation, and be certain you're picking a good increment?

My answer is: be sure your team is creating incremental value as you go.

To do this, you will be very well-served by having a first principles understanding of how value creation works during the development of software.

That understanding will allow you to design the increments for even very large software efforts such that you can offer your business counterparts both steadily visible *progress*, and more importantly, a steady series of options for when to *stop* and still realize value.

Now that we've established *why* good increment design is so important, in the next post we're going to dig into *how* engineering teams can create incremental value.

In closing, I'll offer a teaser for what's to come:

An engineering team can create incremental *value* for their company, even if they're *not* shipping software that is incrementally more *useful* to any users.

"...what?" I hear you thinking.

Shipping useful software is *not* the only way engineers create value for a business.

"...but doesn't the Agile Manifesto say working software is the measure of progress?" I hear you continue to think.

# "Working software is the primary measure of progress.", and it's Principles Behind the Manifesto

The Agile Manifesto is legitimately and enduringly great.

But they got this one wrong.


# The engineers had, of course, complained that the product team hadn't sufficiently defined the product for them to give a good estimate. But they always made that complaint.

# The product team complained (to each other, over drinks), that the engineers weren't willing to stand behind their commitments.

* The Next Post
** Defining Overall Company Value

We're talking about overall company value. Not just "what makes stakeholders happy", or "what users can use", but what makes the overall business *worth more*. Specifically worth more to *investors*.

We need to answer: what would make an investor *pay more* for (a fraction of) a company? That is directly driven by the investor's "valuation" of the company, aka, how much they think the company as a whole is worth. That is the kind of value we're talking about.

In our previous posts in this series, (Link, Link), we dug deeply into this question.

What we arrived at, in brief, is that an investor's *valuation* of a company is based on a *guess* about that company's future profits, aka a "probabilistic estimate of future profits". Thus, an increment of engineering work *creates incremental value* for their company if that work:

# In order to understand value, we dug deeply into how investors determine what a company is *worth*---also known as the "valuation" they assign a company.

 - Increases a probabilistic estimate of future profits...

 - made by an economically rational investor...

 - who possesses information known both inside and outside the company.

For ease of discourse[fn:: and because it's fun?] we named one specific, economically rational investor *Bertha*.

Armed with this fuller understanding of how value is created (and our made-up person!), we're ready to explore how various kinds of engineering work can create *incremental* value.

# In particular, we're ready to analyze [explore, dig into] a wide variety of different *demands* that are frequently made of engineering teams, by people across the company who believe that solving problems in their area will certainly absolutely for sure no questions asked create value for the company.

# We will develop the key questions to ask, to determine if those people are correct or misguided in their beliefs about what engineering should work on.

# XXX Make Above Suck Less (MASL)

# We'll start by digging into how value is created *incrementally*.

# This is absolutely key. Our model of value creation is of no use to us if it can only be applied at the scale of a year-long project. To win at software development, you need to steadily make good decisions on a weekly and daily basis. To support that, we'll need a *fine-grained* understanding of value creation, operating at the scale of months and even weeks. Then, as we go through our planning cycles, we'll be able look at potential increments our team could build, and use our understanding of value to select the best one. That will allow to steadily hone in on *visible wins* for our business.

# [that will create the most value.]

Working on a software project that will hopefully create value is a bit like launching an expedition to cross an unknown sea, and in hopes of finding a city to trade with on the far side. There might be a single narrow passage to that far shore, savage storms might arise, there might not even be a city in the direction you're initially aiming in.[fn:: Have you ever worked on a months or years-long project which was, ultimately, a total failure? Did that not feel like you'd utterly lost your way? Like you'd been blown so far off course, you couldn't even remember what you'd been trying to do in the first place?]

# What is useful about this metaphor is that it makes it enormously clear that you can't make all your big decisions up front and stick to them.

You can't make all your decisions up front and then just stick to them.

You need to *steer*, every day and every week. You need to constantly update where you're trying to get to next, based on what you've learned so far.

An understanding of value creation will let us *steer* as we build.

So we can ultimately arrive at a form of business success so obvious that no one can deny it. Actual present money flowing in, right now, not just in probablistic estimate form.

# day-to-day. It will, if you'll indulge a lofty metaphors, allow us to cross a choppy sea of uncertainty,

But we need the guidance on what to do, each day, to get to that far shore.

Let's dig in.

** Incremental Value Is Created By Acquiring Evidence

# The Acquisition of Evidence

# Let's start with a classic tension:

# Stop me if you've heard this one before:
It's a Tuesday morning. Bertha, our economically rational investor, is having her mid-morning tea. When she woke up that morning, her economically rational, probabilistic estimate for your comnpany is that it will make, say, $10 million in profits over the next five years.

But then, as she drinks her tea... something... happens. That... something... causes her to change her beliefs about your company. She suddenly becomes much more optimistic. That something makes her *double* her probabilistic estimate of future profits---she now believes you'll make $20 million in profits over the next five years. Bertha is, remember, standing in for *all* rational investors. So if Bertha changes her mind, so will the mass of other investors. And the value of a company is simply what those investors are willing to pay for it, which they base on their probabilistic estimate of future profits.

So, in that moment, whatever the... something... was that made Bertha change her mind has made the company as a whole *immediately* double in value. In the moment she changed her rational mind.

Why on earth would Bertha suddenly change her mind about expected future profits?[fn:: She's *rational*, so you can't answer "There was something in her tea." Even if you're kind of tempted to.]

For exactly one and only one reason: beause she sees a new piece of *evidence*.

Bertha *only* ever changes her estimate of future profits if she sees evidence. That's what it *means* to be rational.

If, while drinking her tea, she seems evidence that your company will make vastly more profits in the next five years, she'll quickly double her estimate.

Does this idea of doubling an estimate of profits due to new evidence seem ridiculously far-fetched? In 2024 and 2025, this is *precisely* what happened to a variety of companies in the AI space. Their valuations skyrocketed as evidence accrued about the potential for AI to generate massive future profits. And those valuations went through the roof even though every single one of those companies was, in the present, incredibly *unprofitable*. They were all sinking just incredible amounts of capital into building models and data centers, and losing money just as fast an investors could hand it to them.

Now, for most teams, there's nothing they can do to get Bertha to double her estimate of future profits by way of a single piece of evidence. But there's a great deal they can do that will cause her to incrementally increase her estimate.

If a team somehow gets economically rational Bertha to change her mind this way, that team creates value for their company *immediately*.

A team that creates evidence of a future increase in profits creates incremental value, right now.

# Let's see how that plays out for our two potential investment opportunities.

** Incremental Value & Improving Deploys

Say your team is agitating for work to improve the process of getting code into production.

# What are things that *won't* increase a rational investor's estimate of future profits?

How could incremental value creation work on the deploy side?

First off, we're going to say that, because Bertha is rational, she has read Accelerate [link]. She therefore understands that frequency of deploy is predictive of an increase in future profits. (Yes, your CEO may not be as rational as Bertha, see some ideas in [link] for how to get buy-in to this kind of technical investment).

As above, we can work backwards in time to earlier and earlier forms of evidence.

If the team can demonstrate a significant increase in deploy frequency, Betha would happily increase her estimate of future profits.

But that might take a long time to achieve. What are some incremental steps, that could cause Bertha to increase her estimate?

The team might, after some work, identify a bottleneck in the deploy process. Bertha would see the identification of the bottleneck as evidence that the team will later be able to improve deploy frequency.

It could even simply be the team *measuring* deploy frequency, if it wasn't measured before. Again, a rational investor would see that as improving the odds that the team can later improve the frequency of deploys, and therefore, in the moment the team was able to start measuring, would immediately increase their estimate of future profits (by a small amount, to be clear).

This may sound a bit abstract or hard to believe, but, in extreme cases, almost all engineers already intuitively understand this.

# Name the engineer? Jorja?

Say an engineer joins a B2B SaaS company, and knows that they were hired because the company urgently wants to build a new product over the succeeding year. However, on their first day, that engineer discovers to their horror that the company only ships to production *once per quarter*. In such a situation, just about every engineer I know would tell their leadership that improving deploy processes should be their top priority.

That engineer would not make that case because more frequent deploys "feel good" to them. They'd advocate for that work because they know in their bones that their new company has absolutely zero chance of shipping a new product in a year if they can only deploy to production four times during that period.

If that engineer then managed to get deploys happening *once per week* (aka c. 10 times more often), they would feel like they had created a ton of value for their company.

*And they would be right.*

# Say that, after their first two months of work, the new engineer has cleaned up a variety of issues, and now, when they look at their little deploy frequency graph, they see that, for the most recent three week period, deploys were happening once per week. A fully economically ration investor who understands the impact of deploy frequency on product development would look at that graph as *evidence*, and based on that evidence, would *immediately* ascribe a higher likelihood of the company successfully developing a new product and thus increasing profits.

# The moment that graph exists, and could be shared with a rational investor, the company *immediately* becomes more valuable. Even if the actual revenue comes in much later.

** Evidence For New Products & Deploy Improvements

Let me sketch in a situation that you've definitely never heard of before or experienced personally.

 - Your company desperately needs a new product, it's all the CEO can talk about

 - Your engineering team desperately needs to stop clawing their eyes out every time they deploy to production

How should an engineering decide what to do with their next increment of work? Should they work on a new product, or on smoothing out deploys? Which will create the most value?

One common way to frame the question is: should the team work on the *business* problem (new product), or the *engineering* problem (deploys)?

Hold it right there, Mr Common Way: these are *both* business problems. They are both opportunities to incrementally create value.

But which of those opportunities should we work on *today*?

It's depressingly common for people to consider the new product opportunity much more urgent because it seems like the only way to create "immediate" value. A reduction in deploy pain feels a lot less urgent, because it will take such a long time for that improvement to impact profits for the business (and we just said profits are value, right?)

That perspective is *profoundly wrong*. Remember, company value is a rational investor's *current* probabilistic estimate of *future* profits. Therefore, crucially, value can accrue *immediately*, even if the actual increase in profits will take a very long time to land.

What?

Let's see how this could happen.


For the new product, a form of evidence that would cause Bertha to change her estimate of future profits would simply be customers *purchasing* the new product.

But even best case, that's likely months or years in the future.

What might be some incremental forms of evidence?

Maybe the team has built a rough prototype, and the sales team took that into the field. Every customer who sees the prototype is excited, and starts talking about how, exactly, they'll find budget to purchase.

That would be powerful evidence.

Or, even earlier, maybe the team had conversations with customers and discovered that customers are already spending money to try to solve the problem the product focuses on.

Each of these outcomes would provide Bertha with a different form of evidence that this new product will allow the company to keep growing revenues, and therefore profits, over time. Each of those pieces of evidence would therefore, in the moment they were acquired, immediately increase the value of the company (by different amounts, to be clear)[fn:: Current revenue *is* a powerful predictor of future revenue. Which is why investors short-hand valuation by simply picking revenue multiples. But, inside a company, as we're evaluating fine-grained activities, we need a more nuanced model].

A team that *acquires* that evidence therefore incrementally creates value for the company.

The acquiring of evidence is one of the most powerful ways to understand the incremental creation of value.

Of course, there's every chance that your key stakeholders neither understand nor believe this. That's okay! By having this understanding yourself, you'll be able to advocate for work which, over time, pays off.

You might be thinking: but we can't quantify this! And if we can't quantify it, how can we possible use it to make decisions? This is a fair concern. As we dig into the various ways evidence creates value I think you'll find that there are often continuous tradeoffs happening, so you don't need much in the way of precision. But I'm super curious about exploring quanitification as a means to unlock rapid decision-making. If you've taken a shot at making that work, please let me know what you've learned! Or if you *want* to take a shot at making that work, ooooh, please reach out!

To understand how to apply this model for understanding engineering work, we're going to dig into a variety of situations, and illustrate the key questions you can ask, if you want to maximize the value you and your team can create, with the hours of work you're spending, right now, by asking: "What evidence would Bertha need, to increase her estimate of future profits?"

The evidence/estimate frame will cast a light into many murky areas.

** [Bad Prose] Why The Classic Agile Skateboard To Car Cartoon Is Wrong

# Aka,

You know that classic cartoon that depicts what agile is and isn't?

If not, here it is:

[link]

I want to make a case that this cartoon is both profoundly right, but, in a *very* important sense, also profoundly wrong.

Let's start with the ways it's right (and therefore has seen deserved, widespread popularity).

There are two things that the cartoon captures, about a well-run agile project.

First, by steadily building something that customers can *use*, you can get feedback from customers are you. The customer goes from sad to happy in increments, each of those is a chunk of evidence that you're moving in the right direction.

Part of why waterfall fails is that it doesn't let you check as you go, to see if what you're building actually makes customers happy. Building something simple and then expanding outward is often (thought not always!) the right strategy.

The second thing that the cartoon usefully hints at is more on the engineering side. At each step, there's an end-to-end thing. Another classic failure more of waterfall projects is to build big, complicated things in isolation, and delay the integration of the parts until later. That leaves far too many nasty surprises.

Okay, if that's all right, why is it also profoundly wrong?

Two things.

First off, it's far too linear. No one gets anything wrong or has to learn and adapt. That's so fundamental to value creation, the cartoon damagingly suggests that you're just marching along, making customers happier and happier, with an ever-and-ever better machine for transportation. This is just not at all how it plays out in reality.

Second, increments of value are often created *not* by simply making customers incrementally happier, but by various action which create evidence. In our model of a set of possible product opportunities, *identifying* a good one, or eliminating a bad one, create considerable value. That doesn't show up in this visualization at all.

Let's see how that could look, for a team trying to develop a new product, in cartoon form.

First off, a smart team doesn't start with a product (aka solution) idea, instead, they start with a customer *problem*. See Escaping the Build Trap for more on this.

[Picture of an upset customer]

But, again, remember, we're thinking in terms of pipelines and portfolios. So they start with a *set* of such potential problems, ala:

[Picture of 5 upset customers, maybe numbered, or different kinds of upset? Different strings of sweary characters? Maybe in different boxes]

[Dotted/faint lines emerging from a single box to five other boxes, fanning out, all very faint]

Each of those could lead to a further work:

[Show multiple lines fanning out from each of those.]

For their first increment, they're trying to pick one of the customer problems to work on. They don't currently have a good estimate of the likelihood of success (aka increase in profits) from going along each arc.

They want to create evidence to make a decisin.

In their first increment of effort, they do a mix of a couple of different kinds of work.

For some of the problems (say, "#!" and "@#$"), the team is quite confident they can build something. But they're deeply uncertain if this is, like, a genuinely painful problem for customers, or just something they enjoy complaining about.

To learn more, they dust off their copy of The Mom Test and talk to a bunch of customers.

[Maybe, picture of someone asking someone else questions, wearing a mom t-shirt?]

But, for this other one, they know customers care intensely about it, but are completely unclear on if they can even solve it (maybe it depends on having access to data  they're not sure they can get).

For that one, the engineering team does a spike of research, actually building a bit of their data collection, to see what's possible.

[Picture of either someone typing, or maybe of the team building some weird bits of a machine, in a test lab]

At the end of the increment, they've collected evidence of which path is most likely to lead to future profits.

[Picture of one arrow coming out being much thicker or darker or colored green, maybe label all the arcs with estimates of future profits, all quite low, based on what is currently known]

Someone therefore can *make a decision* about what to do next.

So they move on to the next increment:

[The box darkens]

Again, there are key questions to answer, that will determine what they do next. Having selected a problem to solve, perhaps they're now understanding how a product that they can build actually *will* solve that problem.

[Show the fan out from the current box, make it clear what it is. Save for later the arrow that runs back to the earlier box, but add that before I move on]

What should the team do in this increment? Again, remember that they want to increase the odds of improving future profits. Therefore, ultimately, they need to pick which arrow to follow, which subsequent box to move to.

Remember how someone made a decision? Well, they need to do that again.

You'll notice something, perhaps. Once you understand that value creation means picking your way, in a exploratory fashion, across a graph of options, you can understand that the key thing a team is doing, during each increment, is enabling a good decision about what to do next, aka, what edges to choose out of the current node.

There's a marvelously powerful thing this unlocks: build your milestones explicitly around decisions. I'll write more about that in a subsequent post.

Gotta have a footnote about Maxwell's Demon, who always just picks the right thing to work on, in every moment. Some sprint team should be named Maxwell's Demons. Or maybe Maxwell's Daemons.

Walk through the math on how going into a node, and then coming back out, increases value.

What... is the math? The expectation can be improved by digging in? But shouldn't that fit into the expectation? The expectation can go down, due to bad discoveries. So then something else becomes higher expectation.

Or maybe also show that these expectations, early on, are quite broad.

Based on what is known now. So we *don't* bake in the assumption that the team will do smart things.

So, early on, it's gone from very low odds to, one of them being, like, sliiiightly better odds, but just barely. So then, the returning to the earlier one is an increase, and it's not like you're going from 70% likelihood and dropping back to 20%.

But if you do, that's okay! Kill early.

Can draw out the point that startups mostly don't work this way. VC's do. They just invest in a variety of things, are clever about making sure they can maximize the wins, and then try to convince a bunch of impressionable young people that their best odds of making money is to commit to a single idea.

You are the dice.
** How Do People Make Demands Of Engineering? Let Me Count The Ways

To think about the kinds of work engineers can do, I'm going to speak to the kinds of requests made of engineering. Except, to match up more fully with my lived experience, I'll name them as "Demands", not "Requests".

# We're going to start each one from the perspective of a "problem" that someone might want an engineering team to solve. We'll characterize those as "demands".

I'm going to break the demands made of engineering into a few buckets, based on where, in the organization, I've typically seen such demands come from. Why do this? People rarely come to engineering teams with truly clear thinking about overall company value creation and their place within it. Rather, they're just about always worried about some local problem for their function, which they then try to dress up in impressive and/or moralizing terms (e.g. "This is a huge opportunity!", or "Don't you care about the customer?!")

So, by looking at the different buckets, we can develop means to map from the "local" concerns of those functions to overall company value. Which is what we need to do, if we're going to make good decisions about which problems to solve, aka, how to spend our time.

*** Sales & Marketing

Typical demands:

 - Develop new products

 - Add features to existing products

 - Fix bugs in existing products

*** Internal Operations

E.g. the customer support desk, the data ingestion team, a business intelligence group, the warehousing and fulfillment teams.

Typical demands:

 - Automate repetitive work

 - Handle exceptional/severe problems

 - Add support for a new operation

*** Engineering

Typical demands:

 - Clean up or replace "bad" code

 - Upgrade or retire old infrastructure

 - Make it easier to deploy changes to production

 - Address system performance issues

*** Product

Haha!

The product team is the people of whom demands are made! They have the awesome power of saying no to people (aka prioritization), and with it the attendant awesome power of everyone being kind of mad at them, all the time!

This is the "product function" at its heart---disappointing people by saying no.

If you don't have a product team, or if your product team seems to be kind of a project management team in disguise, you can figure out who is serving the product function by asking: Who gets to/has to disappoint other people? Who decides which problems are important enough to solve? Who continually updates their understanding of reality to adjust the answers to those questions as you go?

There are plenty of situations [cases, times] where the person doing the "product funtion" is actually an engineering leader.

One sign that this might be the case is that various IC engineers on the team are frustrated with that leader for "not allowing them to deal with tech debt".

Engineers are, to a first approximation, *always* frustrated with someone for not letting them deal with tech debt. if the engineers focus that frustration on an engineering lead instead of a nearby product manager, that could be a clue about who is serving the product function.

** Who Evaluates Demands of the Engineering Team?

Company value is created by acquiring *evidence* that will increase Bertha's probablistic *estimate* of future profits.

How can an engineering team create value, when confronted with the kinds of demands we've just sketched in?

What questions should they ask, to orient?

What answers might they hear that could make them push back?

"Wait", you might be saying, "isn't this the product manager's job?"

"In fact," you might further say, "didn't you just tell me, Dan, that the product team is the one of whom demands are made? Shouldn't *they* be digging in, on these questions?"

Look, I'm going to be blurring the line between engineering and product here, and *I make no apologies for this*.

I have *never* seen a high-functioning engineering team where the engineering lead wasn't able to think like a product manager. So, if you're an engineering leader, even if your product peer will ultimately make the prioritization calls, I *highly* recommend that you understand how your team's work could ultimately turn into value for the company. To excel at your job, you need to be an *active partner* in that prioritization decision.

Note: if your product peer doesn't currently seem interested in that kind of partnership, being able to speak to potential value can be a very powerful way to gradually change the dynamic between you. Unsurprisingly, this is a common topic of my coaching practice: helping engineering leaders earn their way into a greater degree of influence and partnership. I wrote about a form of this in <Fixing the Engineering/Stakeholder API>.

On the other hand, if you're a product manager, I think I'm describing a core function of your job? Hopefully that's kind of useful?

"But wait, Dan", you might still be saying, "my team doesn't have a PM."

I have seen... some... high-functioning engineering teams that didn't have a PM.

But, honestly, not that many. There's simply too much to do, across the two functions, to have one person have both the skills and the capacity to handle both. If you get rid of your PM's, your "product-minded" engineering lead can easily find that that they're spending all their time talking with stakeholders and/or trying to triage concerns from the help desk, and/or preparing for meetings with the exec team, and/or trying to quickly learn customer interview or presentation design skills, etc. Aka, they're just being a PM. And, every day, they're feeling like they're doing an increasingly bad job of staying on top of the evolving architecture of their systems, or mentoring promising early-career engineers, or steadily flushing out key risks and opportunities, etc. Aka, they're not being effective as an engineering leader. There's a conversation I find myself in, not infrequently, with young engineering leads who have found themselves in this situation and are thinking about leaving their jobs.

In short: I believe Product Managers can be *extremely* valuable! Don't get rid of them lightly!

Yes, at a somewhat painfully wide variety of places, the PM's may be doing a poor job (though I'm always suspicious of structural reasons as well as weak performance). In my in-no-way humble opinion, the optimal answer is just about *never* to simply get rid of product. I believe this passionately. (again unsurprisingly, this is very much the kind of thing I help my coaching clients wrestle with).

Okay, I'll get off my soapbox now.

** Sales & Marketing Demands

First off: Sales & Marketing-sourced problems are somewhat distressingly often seen as the only economically valuable problems for the engineering team to work on.

Of course, company leaders won't say it in those flowery academic words. They'll instead talk about adding new products or fixing bugs as addressing "actual business problems", or "being customer-centric". By which they're demonstrating that they consider problems identified by other parts of the business as *not* real business problems, or as not serving the morally pure purpose of centering customers[fn:: Look, if you've managed to work at a company where a push to be be "more customer-centric" *didn't* immediately become a means for powerful people to sabotage the prioritization process by elevating their evidence-free opinions about customers into moral imperatives, I'll be thrilled to hear about it. But I am batting negative one thousand on that one.].

We're going to avoid falling into that trap.

*** Develop New Products

This one feels obvious, right? If the engineering team can build a new product that customers will pay for, then Bertha, our economically rational investor, will happily increase her estimate of the future stream of profits, and thus the value of the company will increase.

Great, we can move on---

Waitwaitwait.

Understanding value creation *during* new product development is a total cesspit of confusion. In particular, there are a couple of extremely common anti-patterns to watch out for.

Here is the absolute key to understanding the *incremental* creation of value, as you work on developing a new product:

Bertha, being economically rational, *doesn't think you're going to succeed*.

Most new product development efforts *fail*.

Most new product ideas *fail* (especially as they are initially conceived of).

# Everyone at your company are sort of joining hands and agreeing to pretend this isn't true. Because it would be depressing to go to work every day on something you thought was likely to fail, right? Trick: turn failure into success. How, by adopting a portfolio/pipeline view, and celebrating evidence that lets you winnow bets out of your portfolio. Most sales calls do not turn into conversations. Does the sales team spend an incredibly long time debating about who to call? Or staying on the line with someone who is clearly not going to buy? No, they put in their hours, they "build pipeline", and they spend their time wisely.

An economically rational investor will look *extremely suspiciously* at your CEO's optimistic PowerPoint deck, the one that explains how the new product your team is going to develop will double revenue over the next three years. Bertha has seen *plenty* of such decks. Very few of those companies actually achieved the promised increase in revenue (and, essentially *none* achieved that increase in revenue without significantly changing their original plan).

To understand value creation in new product development, you should think of your company as considering a *set* of product ideas it could potentially invest in. At any moment, your company doesn't actually know which product ideas (if any) in that set will turn out to be both valuable for customers and feasible to build.

A rational investor will therefore assign a weighted average across all of them -- and, unless you have evidence, that weighted average will be *very* low (because so few product ideas work out)

# If, say, on average one out of ten of product ideas turn into a modest increase in profits, then Bertha's *current* estimate of future profits will be one tenth of that modest increase.

Given this context, value is created during new product development by two activities:

 - *Learning* which product idea, if any, are both valuable and feasible

 - Actually *building* those products

The best teams *interleave* these two activities, so that they iteratively hone in on a product customers will pay for, steadily learning and adapting as they go.

There are two classic failure modes companies fall into, here:

 1. They try to do all the learning before they start building

Aka, conduct full market research before a team can start, try to analyize it all up front, and then fully commit to a single bet.

 2. They try to do the building, "as fast as possible", by not slowing down to learn as they go

Just go with what some executive is "certain customers want", and don't do anything to learn from customers and/or reality as you build.

Given that evidence creates value, a team building a new product should be eagerly pursuing evidence. They should bias towards building to learn -- building their product in a smart sequence that lets them test their biggest risks at every moment.

For more on this idea, see my talk Risk, Information, Time & Money

*** Add Features To Existing Products

*** Fix Bugs In Existing Products
* Mini Todos
** DONE Rewrite opening to focus on value of increments
CLOSED: [2025-09-30 Tue 10:20]
Possibly use the "waterfall in disguise" there
** TODO Throw in link / quote to Rewrites post
I've come to place a really high value. Or, quoting Kent Beck.
** TODO Maybe, for stuck team, show in more detail how the "prototype-first" team also gets stuck
** TODO For New Product + Deploy pain, show bad alternatives (first?)
** TODO Maybe: separate New Product + Deploy Pain
So that I'm not asking to compare them, I'm saying, how do you see value here.

Maybe, start with Deploy Pain, since it's less obvious.

And then, I can do my "New Product" is obvious, right? Not, really
** TODO End with teaser of "How do you select the most valuable increment?"
Or is that "which evidence is most valuable?"

So I'm setting it up for "The one that steers into the biggest risk" = gathers
** TODO Further tease for "how do you set goals for teams"

* Scraps/Thinking
** Morning Walk Thinking <2025-09-28 Sun>
I've got a tiger by the tail.

I do like that I'm speaking to the "immediacy" of value creation.

Could maybe back up and frame the entire thing around increments, around the incremental creation of value.

Why are increments important?

So you can stay on track -- building a big piece of software in increments is important because it allows you to learn and adapt.

The exact same thing is true of all software work -- you need to see if you're creating value, and if you're not, adapt.

But the increments are tricky.

Maybe, show the classic Agile skateboard picture -- this is profoundly wrong (even though it's usefully right, at the same time). Yes, you should hook your software up all the time, but you shouldn't always have a thing that is useful to a user.

The first picture is asking someone about where they need to go every day

The second one is building 5 different engines and testing them.

The third one is experimenting with different sales models.

Could I show that with arrows going off in different directions, so it's finding a path through decision space? Visually? That's an interesting idea.

And that does maybe give me a way to make clear that each moment, each key milestone, is a *decision*, not a deliverable.

I still want to find a way to give the reader that sort of actionable, useful when/not useful when.

Definitely frame the portfolio/pipeline thing as a way to make the economics manifest, and enable better decisions. And to unlock good bits of human nature, and point stakeholders at useful decisions.

Also, this is clearly exploding into something between a series and a book, embrace that.

Key Q: if I want to touch both on the immediacy of value creation (the incremental creation of value), *and* some specific tactics for new product dev, should I make that one post or two.

It could be two, as long as the first is grounded enough in reality to not be purely abstract.
** Random Thinking
The "this is valuable when/not valuable when" thing worked super well.

I do really like the idea of unifying across product/engineering/operations, showing them all with a common, true view.

What if I make a central point about the unification, so I can show both top-down and bottom-up concerns through a common lens?
** Tell Stakeholders To Wait
Or, you might be saying "Look, stakeholders just have to understand that engineering teams can't make commitments for work that is estimated to take nine months or more."

Okay, but then what are you going to offer them as an alternative? There are real deadlines in the real world, that matter for businesses. Just telling the Rest of the Business "Hey man, be cool, it'll be ready when it's ready", is actually not a good option for the business as a whole. You need to find some incremental sequence where you're creating options and information as you go, so the Rest of the Business can, well, play along.


** Good/Bad Engineering Activities
*** Rapidly Banging Out Prototypes
*** Building Complex Data Pipelines
*** Cleaning Up Horrible Code
*** Investing in "DevOps" or "Dev Experience"
*** Retiring/Upgrading Old Infrastructure
*** Developing New Products to Expand TAM or $/Customer
*** Adding Features for Big Customers
*** Making It Possible to Sell to Smaller Customers
*** Making Internal Operations Easier
*** Making Onboarding Easier
*** Writing Lots and Lots and Lots of New Code, Super Fast

** Contextual Situations
Can I run that through. What are my four forms of value so far?

Existing Forms of Value:

 - "This Code Is a Nightmare From The Black Depths of Hell"

 - "Deploying To Production Saps My Will To Live"

 - "I Can't Find a Moment to Think"

 - "The Database Is On the Verge of Death And No One Cares"


** Possible Titles
Turn "Engineering Concerns" Into Potential Value, I

The Landscape of Potential Value

The Unifying Force of Potential Value

Seeing Engineering Work Through the Lens of Value

Engineering & The Creation of Value, Part III


** Scrap
It covers both "simple" situations, like closing new customers who add to this year's top-line revenue, but also more nuanced ones, like, a team that rapidly chews through three different product hypotheses, invalidates two of them and makes a critical discovery about a third. That key discovery creates *evidence* that the company is on the verge of building a valuable new product. Bertha, in reviewing that, may even consider that action as having created a greater probabilistic increase in future profits than closing a few new customers (though, note, closing those new customers can create evidence that the company can keep growing, which, in some situations, might be the most important evidence of all).

* Possible Titles
 - The Value of Increments
 - Understanding The Value of Increments
 - Increments & The Creation of Value
 - The Incremental Creation of Value
 - Engineering & The Incremental Creation of Value
 - Engineering & The *Incremental* Creation of Value
 - The Art of Increment Design, Part I - Why Bad Increments Are So Very, Very Bad

* Old Turn "Engineering Concerns" Into Potential Value, I
** Intro
# Getting a Handle on Interruptions

# Hmm, When You Put It That Way, That Does Sound Pretty Important

# Can Bertha Help Tame Interruptions?

Now, armed with a fuller understanding of value [link], we're ready to look at issues engineers tend to be concerned about.

We'll look for ways to turn those from vague worries into potentially valuable *investment opportunities*.

We'll ask: What Would Bertha (our economically rational investor) Say?

Then, we'll share ideas on how you to make the potential value *visible* to stakeholders.

Today, we'll dig into one such challenge, which engineers might experience as:

** "I Can't Find a Moment to Think"

Wouldn't it be great if your engineers had time to, say, *do software engineering*?

But instead, every day they face a relentless stream of *interruptions* from people across your company:

 - *People who work directly with customers pinging them about bugs and feature requests (and bugs that are actually feature requests)*

   Every one naturally at the highest priority!

 - *Follow ups and status checks and nudges about those bugs and feature requests (and bugs that are actualy feature requests)*

   And I have some bad news.

   People who work in sales are often very good at advocating for issues that affect "their" customers.

   I mean, look, they didn't get into sales because they're *bad* at persuading people to do things![fn:: I once asked my friend Marion, who was running sales at Ellevation, what it's like to interview sales people, who are, by their very nature, skilled at presenting themselves optimally, and she rolled her eyes and said "Oh my god it's the worst".]

 - *Weird bits of operational work only engineering can do*

   The still-largely-manual work to set up data integrations for new customers, or the monthly data pull for the BI reports.

Worse yet, the interruptive requests often fall most heavily on your most experienced engineers (because they're the ones who know how to solve all the wonkiest problems)

And that's *especially* true if those engineers suffer from the misfortune of *being nice*.

(I have vivid memories of standing by Tom Hare's desk at Wayfair, watching just a parade of people from the operations teams "wander by", each asking for Tom's help to fix some weird edge case. Tom was such a good engineer! And so nice!).

# That said, he did end up marrying one of those ops stakeholders -- hi Lauren! -- so I guess that worked out okay in the end?

*** Potential Value: Reduce Opportunity Cost *And/Or* Improve Operational Outcomes

This situation isn't just *unpleasant* for the engineers.

It may represent a serious *opportunity cost* for the company as a whole.

As in, there might be something else, that the engineers *could* be doing, which would create *more* overall company value than their current work.

But, and this is important, just because the current work is interruptive and not much fun, *doesn't mean it's not creating value*.

So we're going to dig in, with Bertha at our side, to understand the situation in more detail -- and then be ready to advocate.

Let's imagine the engineers on the team spend, among them, a few dozen hours each month doing the following two "distracting" things:

 1) Fixing edge case bugs for a small set of extremely vocal customers

 2) Setting up data integrations for the customers who onboard in that month

What is the value being created by each of these activities?

aka, what is the effect on Bertha's probabilistic estimate of future profits?

That is what we'll have to understand if we want to make a case for the engineers doing *something else*.

Let's take them each in turn.

*** 1) Fixing Edge Case Bugs

Aka, Sometimes We Should Just Let the Wheel Squeak

Let's imagine that the engineers and/or their PM's do some investigation and discover the following things are true:

 - These customers represent a tiny fraction of the company's revenue

 - They're not particularly *representative* customers

   A common case for this is that they were acquired *early* in the company's history, but they're not actually in the key segment. But they have high expectations of responsiveness.

 - They are very unlikely to cancel -- although they're *always* complaining about bugs, but none of the customers have left in a long time.

In this case, it ;

# Likely nearly purely opp cost, key is how to make this visible, answer = a) lightweight tracking of time, then use that to b) set up triage to bring it out in the open, and c) force a one-time budget or cost.


*** 2) Setting Up Data Integrations for New Customers

aka, Enabling Customers To Use The Product They Paid For

Let's imagine that the investigation led to finding that there genuinely is no other way.

If they *didn't* do this, there would be some likelihood

Say that decreases the likelihood of those customers churning by some amount. Then we can look at the value of the

If, instead, theywhen they could have been developing a product that opens up a new segment for the whole business... that might represent a loss of overall company value (where, again, value is a probabilistic estimate of future profits).

But, of course, that tends to be completely invisible to stakeholder and decision-makers.

There are two distinct ways that Bertha understands the potential for value here, and thus two distinct forms of visibility.

First, Bertha suspects there might well be value for the company if the engineers could spend *less time* on all this interruptive work.

In this belief, she is likely heartily joined by both the engineers *and* their immediate stakeholders.

Spending less time on reactive work could free the engineers up to work on things that would be more valuable (hopefully) and more fun (definitely).

# more fun for them and more in keeping with the product team's immediate goals.

If that "other" work were likely to lead to greater profits in the future, Bertha will happily ascribe real value to replacing the reactive work with that "something else".

Visibility on this "engineering capacity" front is fairly straightforward: you want to simply make it clear *how much time* the engineers are spending on operational work (with some multiplier for interruptions, since they blow up focus).

Just viewing the capacity consumed by reactive work can sometimes motivate a real investment to speed up or fully eliminate interruptive tasks the engineers are currently responsible for.

You can build visibility into the "capacity spent on reactive work" by some combo of:

 - Surveying engineers on a regular basis as to how much time they're spending on the reactive work

 - Tagging and tracking tickets

 - Shadowing an engineer for a day or two

 - Setting up a formal triage process to bring reactive work out into the open

All of that can help create enough visibility to make a case for investment, in particular if there's a way to *reduce* the reactive work.

However, that's not the whole story.

The reactive work, thankless though it may be, is very likely creating *some* form of value for the business.

Bad news: *Bertha cares about that value, too.*

If fixing bugs, or restoring the site from outages, or correcting data issues in production keep customers renewing, then Bertha will not be happy if your team simply stops doing that work.

The trick here is to spend a bit of time understanding the *positive* value of what your team perceives as reactive work.

If you can really dig in on that side, you might be able to find creative ways to restructure how much work gets to your team, or make a real investment to eliminate a whole class of issues at a deeper level, or even, propose moving the work *off your team* altogether and finding a home for it somewhere else in the organization.

Those kind of major investments or shifts can be economically rational, but those aren't easy pitches to make, unless you can show the *positive* value to the business, *beyond* just saving time for the engineers.

E.g. say your engineers spend time every sprint helping set up data import configurations for new customers.

Even if they were to invest in better tooling, they can't automate it all away, because setting up each new customer requires carefully reviewing sample data files, testing out imports and diagnosing failures, helping the customers fix subtle issues on *their* end, etc.

Imagine you were go to an Important Person at your company and say, "We'd like create a dedicated Data Operations team"

And the Important Person looks august, and says, "Okay, why?"

And you say, "So my engineers can spend less time on new customer onboarding."

Here's a problem: there is a risk that Important People will hear that as a form of *complaining*.

Everyone's job has certain unpleasant and/or boring parts. Most Important People have developed the skill of ignoring complaints that they hear as: "Part of my job isn't fun, can I stop doing that part?"

You really don't want them to hear this suggestion in that light.

You might be able to make a more effective case by saying something like:

/"It currently takes three weeks to onboard new customers. Delays in the back and forth to setup data imports are the main driver./

/That work is currently being handled by the engineers, but:/
  /a) Engineers are expensive, and/
  /b) it often takes a few days for an engineer to find time to review a question from customers, which adds a lot of delays and frustrates customers./

/We'd like to talk about finding a better home for that work, so we can both improve onboarding times and reduce costs./

/Our early estimate is that 70% of the work can be done by the more technical members of the help desk, if we can carve out time for them, and the engineers can build some basic tooling."/

That's speaking to potential benefits -- both a better customer experience, but also lower costs and better outcomes *for the operation itself*.

There's a decent chance you can (and should) loop in your product team to help build this kind of case. It's usually not too hard to get their help, because they would love to have more of "their" engineers time devoted to "their" work.

There are other variations on this game plan you can run, be it setting up a regular collaborative triage process, or breaking off a separate platform team that owns a particularly troublesome bit of functionality (e.g. authentication and authorization is a classic), etc. We'll touch on a couple in the Case Book of Tech Investments later.
