:PROPERTIES:
:ID:       71B164B6-0AB2-4FDE-B51E-71870F553C67
:END:
#+title: The Tech Investment Cycle
#+filetags: :Chapter:
* The Tech Investment Cycle
** Favor Repeated Cycles Over One-Off Projects

There are two fundamental facets to working with technical investments.

First, you have to *identify* potentially valuable work.

Second, you have to *advocate* with your stakeholders for time to execute on that work.

# XXX Add third, which is actually executing on the work?

If you're stuck in an oppositional relationship with stakeholders who don't seem to care about anything except their feature list, it may feel like your best bet is to carve off a big block of time so the team can just go and definitively fix their problems, without interruptions.

I have tried the "Bargain for one giant chunk of time" approach, and, unfortunately, it has been something of a consistent disaster.

# XXX Maybe, tell story of early Wayfair, I had earned some trust with the Chief Operating Officer, by leading the resolution of a massive problem in rolling out new software and processes to the Final Mile delivery agents (see Solve a Problem to Earn Trust). I made a case for carving out time -- but I wasn't actually 100% certain where the greatest value was, and that COO absolutely thought of this as a "one-time cost" and then he'd just see rapid progress. We made some real improvements, but didn't magically fix everything, and within a few months, were back in the usual treading water in sewage feeling, and not in a better conversation. Much later, my friend Edmund managed took over a Durable Team and made a transformative change. Abrar Chaudry, in contrast, took over the horrifying legacy warehousing management system and gradually completely transformed it, with his stakeholders.

Both the identification and the advocacy are *far* more effective done as a series of repeated small steps, instead of a single giant one-off project.

There are at least two reasons for this.

First, in the big bang mode, the stakeholders don't tend to see the work as "valuable". Instead they see it as a "painful delay", and as such, feel "owed" immediately faster progress on their features. Which is not always the immediate payoff for a technical investment, even an extremely valuable one.

# XXX Add: especially if the big bang investment has no associated visibility?
# XXX Tease apart: don't start here vs it's okay to build to this
# As in the real problem is if you use the one-time nature to avoid fully educating the stakeholder and ensuring they can see the results of the investment.

But the big bang approach is not actually good for the engineers, either.

Real value is often created at the intersection of the technical and human/social systems (see Allspaw on Socio-Technical) -- and those are essentially impossible to adjust in big, fixed steps.

E.g. two significant forms of value are:

 1) reducing the time to get code to production

 2) reducing the time to restore from outages

# XXX increasing the load a system can handle? Increasing capacity to match current demand?

Both are *extremely* valuable for a business (more on both in [[id:E7DB3CD4-9B7B-425B-BF07-E2607DDD6670][Forms of Value/Visibility]]).

But neither is effectively addressed as a single big bang investment -- you have to steadily improve things, see where new bottlenecks or problems occur, and then pick the next thing to focus on. That kind of effort take real calendar time -- you have to see a set of "improved" deploys, or see how the team is able to handle the next set of stresses to the system, before you can understand your next step.

# Footnote?
(if an engineer tries to convince you that all the stability problems in the site will be addressed by rewriting the entire thing in Rust, you should +fire+ firmly persuade that engineer to think otherwise, if you wish to maintain your sanity and/or job).

# Maybe: do a single one in detail, then list a slew of others which also need steady digging and learning

Thus, what you want is to get into a *cycle of technical investments* -- where you are repeatedly identifying small potential improvements, advocating for those, and then executing on them.

Going through this cycle *with* your stakeholders will gradually build trust and rapport over time.

# (and a shared understanding)

That increased trust, rapport and understanding will allow you to "lever up" to larger and larger investments.

You should, of course, still *execute* the work in incremental steps (because that is how all software should be built) but you can use these repeated cycles to gradually climb the [[id:722C702D-A6C2-4A51-AB62-515CE8144AA2][Ladder of Commitment]] for technical investments:

 - On the Side

 - A Single Ticket

 - A Within-Team Project

 - A Cross-Team Initiative

 - A Durable Team

** Use Cycles To Climb a Ladder of Visibility and Value

When I joined Ellevation Education, a thriving EdTech company serving public school educators who work with English Learner students, I found that the engineers had grown incredibly frustrated by deploying the legacy app.

The deploy process was a hodgepodge of different jobs, some of which ran automatically, many of which had to be manually started after a previous job completed.

It had everyone's favorite feature of a deploy pipeline:

 - Lengthy rebuilds of massive artifacts from scratch, every time

 - A sprawling suite of poorly-maintained Selenium tests that enjoyed the properties of being both slow *and* flaky

 - Intermediate jobs that liked to fail with cryptic error messages that only the most senior engineer could resolve

 - Jobs hosted on multiple competing automation platforms (Jenkins, Octopus, some GitHub bits)

The #deploy-sucks Slack channel was just a firestorm of angry gifs and emojis.

But... what was the product team's experience?

And please note: this was a pretty technical savvy product team -- Nathan Papazian, Ellevation's VP of Product, held his PM's accountable for listening carefully to the engineers, and really understanding the systems in some depth.

What could that product team *observe*?

Well, any development that touched the legacy app felt slow.

But, legacy app development *always* felt slow.

And there were plenty of other contributing factors -- understanding of the legacy app was poorly distributed throughout the team (which of course was made worse because deploying it was such a nightmare, everyone avoided it like the plague).

Also, the engineers were complaining about legacy app deploys.

But, to a first approximation, engineers are *always* complaining about deploys. So this didn't really stand out.

Furthermore, when the product team asked the engineers for any concrete improvement options, the engineers weren't able to offer much in the way of specifics -- the whole thing was such a mess, it wasn't clear where to start.

One engineer kept saying "We need to rewrite all our Selenium tests", but that was clearly an apocalyptic amount of work.

And so they all felt stuck.

Then, one afternoon, while waiting for a deploy to finish, Alla Hoffman, a *very* bright and *very* frustrated engineer threw together a spreadsheet and asked all the engineers on the team to just *manually* log their deploy times in it (the legacy app was called Flagship internally, Alla titled the spreadsheet "Flagship Pains").

She asked engineers to fill in their name, one column when they started the first in the series of jobs, then another when the final job finished up. There was also a column for free text notes on anything that happened.

Setting up that spreadsheet took her about 15 minutes (counting the, ahem, vigorous email she sent to all of engineering encouraging them to keep it up to date).

This was a technical investment!

All *created visibility* -- which is an *excellent* form of value (which we'll talk about at some length in [[id:D901A4C9-885B-4F42-8B8D-3595616857E8][Visibility Creates Value]]).

She did so as an "on-the-side" project -- one where the engineers *don't* ask the product team for permission/capacity, but just quietly scrape together a bit of time.

Overall, it's well worth your time to develop a collaborative partnership around technical investments -- but some work *is* best done without a formal negotation. That's an especially good pattern for cheap initial steps to build visibility.

We'll talk in the [[id:722C702D-A6C2-4A51-AB62-515CE8144AA2][Ladder of Commitment]] about different scopes for technical investments, and where the on-the-side approach works, and were it falls down.

Once Alla had set up that spreadsheet, what happened next?

The engineers on the team were plenty motivated to track their deploys (and had plenty of time to do so, thanks to the various forms of failure). They didn't experience this as annoying manual overhead, they experienced it as validation for their pains, and a chance to contributing to improving things for the future.

After a few short weeks, Lisa McCusker, Ellevation's engineering manager who had responsibility for the legacy app (and other things), brought the spreadsheet to Nathan and the product team.

Together, they all looked at how long it was taking to get legacy app changes out to production -- and discovered that, on occasion, there were so many repeated failures, it took *more than a full day* to get a single deploy out. The comments were filled with complaints about flaky tests and mysteriously stuck jobs.

At this point, it wasn't hard for Lisa to convince Nathan to carve out a week for one engineer to instrument the key stages of the deploy process, so they could better understand what the hell was going on (this is what I call "Ticket" scope).

Thus, a few weeks later, they were looking together at a clearer picture of overall deploy trends and, for various internal stages, both times and failure rates.

The flaky Selenium tests proved to be the worst culprit -- often needing to be re-run multiple times until they passed.

But, unfortunately, there was no simple fix -- it was tempting to just rm -rf the whole set, but everyone agreed that, on occasion, the tests caught a potentially very bad problem in some part of the legacy product that customers still depended on.

Lisa made a case for a carefully time-boxed, three week-long effort by a couple of engineers, to inventory all the tests, come up with options, share those back and then execute on one (this is "Project" scope -- and has a built-in partway-through decision).

Lisa and Nathan worked together to find a time for this project -- they weren't working much in the legacy app at the moment, but both knew a big chunk of work on it was coming, and they were *both* motivated to get deploy improvements in before it landed.

With some careful co-planning, they found a chunk capacity.

When the engineers dug in, the product team worked closely with them. Together, the two sides decided which features they most wanted to retain test coverage for, and which areas were okay to leave with less coverage.

Thanks to having built shared understanding, the product team were ready to pitch in themselves. This is a super common need -- for many tech investments, business context is needed to make decisions as you go.

The engineers ended up deleting a big set of tests (deleting code is Lisa's absolute favorite thing to do, she was very happy on that day).

They moved most of the remaining flaky-but-sometimes-valuable tests off the main deploy path -- they only ran that full suite for a small subset of deploys that touched certain parts of the legacy app.

That immediately made the vast majority of legacy deploys much faster.

The engineers, the engineering manager and the product team could all *see* that improvement on the graphs of average deploy time (as a small, ticket-sized follow up, the engineers had piped the deploy times into Grafana so they and the PM's could visualize them over time).

For a few more months the team kept steadily improving the deploy process, in parallel with a great deal of feature work.

Sometimes it was just a ticket here or there, sometimes an engineer would drop off the main sprint for a week or even a month and just focus on some specific challenge.

Eventually, the legacy app deploys became reliable enough that, by common agreement between Lisa and Nathan, the pace of investment in this specific area slowed.

Then, one day, the legacy app suffered a major outage.

In the course of resolving the incident, the team rapidly deploy one change after another, first to diagnose and then to fix the underlying issue (which, this will shock you, turned out to be in the cache, which was Couchbase).

When Lisa wrote up the post-mortem notes, she took time to carefully document how those fast, reliable deploys had saved Ellevation somewhere between one and three *full days* of downtime.

She made a point of sharing those post-mortem notes with both the product team and the CEO (see [[id:3DE23585-34F0-4C88-A16B-4558ACC45C99][Make Your Post-Mortems an Act of Visibility]]).

All of which eventually led to Ellevation's (highly non-technical!) CEO, Jordan Meranus, beaming with pride at a company All Hands as Lisa told *the entire company* the story of how the team had gradually improved deploys (see: [[id:4D62F0DE-2862-45F3-97EE-6AFED5382F2C][Use Storytelling To Celebrate Your Wins]]).

During her presentation, Lisa had one of the engineers walk the company through some very impressive-looking graphs of improved deploy times.

I don't know if you know this, but CEO's really like impressive-looking graphs. We'll talk more about this in [[id:0A54C1F2-B531-4CF9-9337-8FC336B0AB15][Leverage the Dark Art of "Metrics" In Your Favor]].

# Ideally, you want your stakeolders to experience these as "their" wins -- which is what the engineering manager above did.

In the course of climbing the ladder, there was a constant interplay between building visibility and then improving systems.

That's so central to working effectively with technical investments, we'll spend the entire next chapter on building visibility.

** A Framework for Tech Investments
Having seen those examples, we can sketch in the skeleton for the overall cycle -- which we'll dig into in detail, through the rest of the book [Part I].

Not every single cycle goes precisely through every step in precisely this order -- but it's good to understand this as an overall *arc* you want to go through, *with your team and your stakeholders*.

If you find yourself stuck, you can return to this and see if you've tried to skip past something important. E.g. "Oh, our conversations with the stakeholder feel broken because we have no visibility to offer", or "We need to come up with some incremental options".

*** Find things engineers are *worried about*
*** Map those concerns to *potential value*
*** *Build visibility* into the potential value
*** Develop *options* for small increments of investment
*** Share visibility & options with *stakeholders*
*** Select an option, *together*
*** (Do The Thing)
*** Celebrate visible improvements via *story-telling*
*** Return to Step 1, with more *visibility and trust*

* Random Notes/Thoughts/Scraps

** The Cycle from My ToC
# Basically just name each of these, will go deeper in later chapter.

# Emphasize that you do this over and over, deliberately starting with small scale, and gradually "levering up" to larger investments.

*** Find things engineers are *worried about*
*** Convert each into a statement of *potential value*
*** Select the highest value option, based on what is *currently known*
*** *Build visibility* into current state

# In a way which will show the improvement, if/when you make it

*** Identify a *small increment* that will improve things and/or create more visibility
*** Share visibility with stakeholders to *motivate investment*
*** Offer an *incremental option* to stakeholder, get buy-in
*** Do The Thing
*** Celebrate improvements via *story-telling*
*** Return to Step 1, with more *capital and trust*
