:PROPERTIES:
:ID:       D901A4C9-885B-4F42-8B8D-3595616857E8
:END:
#+title: Visibility Creates Value
#+filetags: :Chapter:
* The Extraordinary Value of Knowing What To Do Next
** Welcome To Wayfair, Here Is Your Pile of Legacy Code
Late in 2017, I was starting my second year as an Engineering Director at Wayfair.

# ..the home goods ecommerce leader

Wayfair's greatest strength *and* greatest weakness was a simply incredible tolerance for doing things in fast and scrappy ways -- both in engineering and in operations[fn:: Over a beer or seventeen, I could tell you some stories].

I really enjoyed that challenge -- and I had learned from repeated startup experience, that almost all companies that achieve product/market fit do so on top of a bunch of seriously crazy code[fn:: Edmund is the one who first said this out loud to me, and boy has experience proved him right].

# Fix this, so that it's *after* peak -- early 2018? Or December 2017, after peak season.
Partway through 2017, I had been promoted to lead "Supply Chain Engineering", a sprawling set of engineering teams that supported transportation, warehousing, ocean shipping, and other operational concerns.

# as part of ultimately delivering furniture and home goods to people.

At every company All Hands in 2017, Niraj Shah, Wayfair's CEO, was just *constantly* talking about Wayfair's ambitions in supply chain.[fn:: I could probably write another book about the um, fun, of being the focus of the CEO's dreams and desires.]

# -- he believed that developing tech-enabled operations was a long-term competitive advantage.

Wayfair was thus hiring just a slew of VP's and charging each with spinning up some new operation absolutely as fast as possible.

It was a rare month that went by that Doran Robinson (who led Operational Product) and I didn't meet some new operations VP who informed us that we needed to immediately provide engineering support for their own Very Special Operation.

# Those VP's promptly turned around and demanded engineering support from Supply Chain Eng.

# Because of the ever-increasing scope of Wayfair's supply chain, my teams had an ever-growing mob of stakeholders.

# And, every single one of those stakeholders was urgently demanding engineering support for whatever new operation they had been personally charged with spinning up, as fast as possible.

Now, this will shock you, but there wasn't a real excitement from those new VP's about slowing down to deal with tech debt -- of which we had simply incredible amounts, by literally any definition of tech debt (see strength/weakness).

This was my life (and I enjoyed it very much, thank you).

Then, one day, a senior engineer from the customer-facing "Storefront" teams approached me.

He told me that he had been tasked with leading a major, across-all-engineering project called "Order Sharding".

He told me that I was going to have to commit significant engineering capacity over the next several quarters to adapt *all* the SCE systems to work with a new sharded order database structure they were putting in place.

# (he gave me a long document filled with technical details on the sharding scheme)

My heart sank.

I well understood why someone had prioritized an effort to shard the order database.

Wayfair had just gotten through the 2017 peak season (the "Cyber 5", post-Thanksgiving), and our main order database had barely survived.

There was no way we'd be able to get through another peak season without significant downtime, unless we did *something*.

There was just one tiny problem with the Order Sharding plan.

There was no way on earth we could make it work in SCE, unless we dropped everything and spent the next several years rewriting all of our systems essentialy from scratch.[fn:: For those curious about the technical details, the Storefront team had assumed we could shared by *customer*, because in their world, the vast majority of queries started with one specific customer. However, in the SCE world, customer orders were constantly mixed and remixed across warehouses, shipping legs and final delivery routes. Essentially all our queries needed to look across abitrary sets of customers, completely defeating that simple sharding approach]

"Um, let me think about this," I told that senior engineer, who went off to tell some other team about this new exciting mandate.

** What Would Bertha Say?
Let's pause and ask what our Economically Rational Investor, Bertha, would say about Wayfair's overall company value in this moment.

Bertha knows that sometimes, companies find themselves stuck with an architecture that badly impedes their ability to grow. Those companies usually find *some* way to address it, but it can be a very real drag on creating happy, repeat customers.

She would raise her eyebrows when we told her that, at the time, the Wayfair engineering team didn't even have a *plan* for how we could adapt our systems to handle a greater load of orders, without spending multiple years on a hyper-complex rewrite[fn:: Bertha stops listening when you tell her you're solving your problems with a multiyear rewrite].

Wayfair's market cap at the time was [$4 billion dollars] -- but of course the price of a share of stock was determined by investors in the public market... who didn't know much in the way of specifics of our internal technical set up.

Bertha, with her added information from inside the company, would discount that some.

Let's say that Bertha estimates that given the risks of scale, and the lack of any specific current plan, she's going to revise downward her estimate of profits over the next 5 years by a modest 5% (which represents lost orders but also factors in a lower rate of people recommending Wayfair to friends, etc).

That 5% shift down represents a difference of *$200 million dollars* in company value ($4B * 5%).

If we could somehow come up with a half-decent plan, that a rational investor would think has even a 50/50 chance of working, we could increase company value by *$100 million dollars.*

I have not worked on many projects that have a greater return than that.

Again, this isn't some weird fantasy -- this is how actual company value *works*.

If we just ignored these problems, it was going to have very real impacts on the business, and those impacts would eventually show up in quarterly filings, and investors would punish the stock.

Asking what Bertha would think allows us to make fine-grained decisions, *today*, that gets ahead of those quarterly filings.

** Wait, Is This Actually a Technical Investment?

I've framed it in a way that makes the business value clear.

But that's not how it presented in the moment.

This was very much something engineering believed was very valuable to the business, but that stakeholders weren't asking for.

Why weren't stakeholders "asking for" engineering to address the limits with the orders database?

First off, stakeholders essentially *never* ask for feature of "The site doesn't explode in fiery wreck", because *they don't think they have to*.

(Unless you can show them a very clear picture of where the current limits are, which we could not do)

Second, the flow of orders sat *between* every domain in supply chain. So any one stakeholder thought it was "someone else's" problem, why would they prioritize "their" engineering team working on it?

These are very common features of technical investment opportunities.

** Your Mission, Should You Choose To Accept It

In the next section, I'll walk through how we utimately resolved this, but I want to give you a chance to try your hand at it, if you're curious.

Here are some of the details of the technical set up.

One of the key interfaces between Storefront (where customers browsed the site, collected items in their carts and then eventually hit "Buy") and Supply Chain (which dealt with fulfillment), was the moment when a customer *committed* to an order.

In the Storefront systems, it went from being a "basket" (Storefront-speak for items in a cart), to becoming an actual order, with a relevant row in the database table creatively named ~tblOrder~.

On a normal day, baskets turned into orders a hundred times per minute or so. During the most intense times during peak that went up to tens of 1000's of times/minute -- vastly greater load.

Now ~tblOrder~, among *many* others things, functioned as an implicit queue: dozens of different fulfillment operations were constantly querying that table for various slices of new or recent data.

Some of them later updated those rows, and there was all sort of downstream work that came looping back into that central database in some form, driving up load further.

The SQLServer experts on the team had optimized a bunch of queries as best they could, but, as is so often the case with the centrally shared DB, it wasn't fully clear where load was coming from, or what to do about it -- certainly not during the quiet, non-peak days.

What would you do?

** What We Did

To deal with my growing panic, I did what I often do to soothe myself.

I read a book.

In this case, The Art of Capacity Planning, by John Allspaw.

In talking about how they had handled some specific load challenge at Etsy, he mentioned how they were able to determine a certain kind of load limit by focusing larger amounts of load to one of a bank of (stateless) servers, and seeing when it fell over.

I felt jealous -- in supply chain, we had a *stateful* system, with data flowing through it, not a bank of horizontally scaled stateless front-end servers.

But, man, how much I wished we could somehow determine our limits *in production*.



# Within the next day, two important things happened.

# That afternoon, in a meeting with the product leadership within supply chain, I attempted to explain to *why* Wayfair eng had committed to this project.

# I explained how we were currently running all orders through a single giant table in a single giant database.

# I explained how the overall "post-order" systems had hit some scary moments in the recent peak season.

# And further that breaking that database up into separate shards would allow for horizontal scaling--.

# I caught myself, and said, "We shouldn't be calling it Order Sharding, we should be calling it Order *Scaling*".

# It's *extremely* useful to push for the discipline of naming projects after the desired *value* or outcome, instead of the details of the implementation. Among other things, that ensures you talk at least once about the outcome the engineers are trying to unlock.

# One of the PM's asked: what are the current limits on scaling?

# And I said "Huh. I don't really know." (see, this is why it's so useful to push for this discipline). We did know that the overall system had gotten sluggish and stuck at a bunch of points in the most recent season -- which could lead to delays in order fulfillment (breaking the promise of two-day delivery), or even causing the overall orders database to slow down, which could back up into problems for people shopping on the site.



* Scraps

** It's a real problem -- the previous seasons peak had suffered outages, and it was growing fast
Bertha, the rational investor would knock something off the stock price based on her rational concerns that we'd piss off a bunch of customers next year. And that could represent (many) millions of dollars in overall market cap.

** I was explaining it to stakeholders (always explain), when I realized, as I spoke, that the name was wrong.
We had named it after the technical approach, not the underlying business value.

Order Scaling

** I then went on a brief warpath in the CTO staff meeting to rebrand it as Order Scaling.

** Literally the first time I got my head clear to talk about the technical implications, we all realized this was insane
The were modeling it on having sharded customers, but orders were, by design, completely mixed as they entered SCE.

Dozens of different operations depended on the implicit queue in the database (later things move to explicit queues, but at the time, there was a job that took completed "baskets" from customers and dropped them into the single giant orders table, and then everything sprung into action.

** but, zomg, it was a very very real problem

** Stakeholders weren't asking for "Please don't have the site crash"... because they didn't think they had to. And we didn't have any way to tell them what the current limits were -- it was an incredibly complex web of systems.

** What would you do? Stop and think about it.

** Wayfair had a real problem but didn't know what to do next.

** Then, I was reading Allspaw, was jealous

** Had inspiration

** Told Ben Clark (who managed the senior engineer who was leading Order Sharing), who immediately got it

** He wrangled stakeholders, t
* Scraps/Notes
From my notebook <2025-06-01 Sun>

Call out that Revenue != Value -- mabe start with this, and name "value" as "what is your company worth". What is it's stock price? What would an investor value it at?

Illustrated with:

 - Customer survey or gathering of feedback (esp if it makes extremely clear what to do, maybe with either stalled deals or high churn rates)

 - Profiling a big distributed systems (esp if customer complaints are driven by slowness, in the face of key deadlines, and they're giving up and just using spreadsheets)

 - Acquiring a data set (or, if I turn this into a story, maybe it's having researched an alternative data store or way to implement indexing for the database that will remove the bottleneck)

Each step creates value because it allows you to understand the *next* valuable step. This is how technical investments often work.

Note: don't lead with economic theory with stakeholders up front (again, note my failures). Get them addicted to decision making and gradually educate them on the key parts of the system

Some kind of metaphor about how it's not a planned drive across the country with a good map, where you hit some minor snags, and have to, like, go to a different hotel or go through Minneapolis instead of Milwaukee.

Rather, it's like trying to find a route across a massive jungle to a set of mountains, just visible in the distance, in an undiscovered country (sigh, colonialism, sigh) (or is it to the far side of the mountains)

There will be valleys hidden from sight right now, that might contain deep canyons you can't across, there might be rivers that run precisely where you want to go, and can save days and days of time.

Every day, the leader might send someone up to the highest nearby tree or hill, and survey, to see what they have learned.

They might fundamentally change their course as they go -- they might end up going a fundamentally different route than initially planned, they might even give up and find another way to get to the far side.

Every day is interwoven progress and learning, one drives the other. The take some actions to fill in the map, and others to make progress (which allows them to fill in more of the map).

Software projects are much better understand as explorations with a flexible long-term goal than as a planned itinerary through a mostly-known landscape.

This is why the PMO approach to building software has become a one-word shorthand for disaster, among most engineers: "Waterfall".

Fun fact: human nature has this extremely reliable widget, called Hindsight Bias.

Which means that, after massive exertions, having found the one clean path through, the human mind will, in essence, look backwards and say "Welp, that was actually kind of obvious".

That tends to discount the value of the learning. So beware!

Again, use Storytelling in your favor.
** Wayfair Details
Tom Hare, who maintained the horrifying "shipping loader" downstream of the orders table explained it as "Transportation's job is to semi-randomly *shuffle* orders from all sort of different customers to different shipping companies and warehouses. There is no way to shard that ahead of time -- every single query would have to summarize data across multiple shards, it'll be unbelievably complicated and it won't actually make performance any better."

The Storefront team had done an ambitious sharding of customers. But didn't really understand that Orders were a different beast.

Wayfair's peak season was the Cyber 5, immediately after Thanksgiving -- and, in the one that had just taken place, the Storefront and SCE systems had... survived... the intense stress, but, just barely.
