:PROPERTIES:
:ID:       E7DB3CD4-9B7B-425B-BF07-E2607DDD6670
:END:
#+title: Forms of Value & Visibility
#+filetags: :Chapter:
#+SELECT_TAGS
#+OPTIONS: tags:nil

* Forms of Value & Visibility             :export:
# BAD PROSE GO

** Intro
In the below, we're going to go through a list of ways that engineering teams can create value for an overall business.

Feel free to pick and choose the ones that you think might be useful to you, in your current situation.

For each, we'll first touch on why Bertha, our economically rational investor, would consider an investment to be potentially valuable.

We'll then sketch in options for creating visibility, at different investment sizes:

 - Small: an on-the-side bit of work or a modestly-scoped ticket

 - Medium: a project that might take a few engineers a few weeks

 - Large: a multi-month cross-team initiative or the mandate for a durable team.

For the "Small" options I'm deliberately aiming for *very* small.

I want them to be things you could do, even if you're in the middle of some intense crunch (because the median software team is kind of always in some form of intense crunch).

See if you can get that small one out there, go back to crunching, and then check back in a week later -- maybe then you'll have enough visibility to motivate just a bit more investment.

A few notes, before we dive in.

First, Bertha's perspective is *not* intended to be a model for how your stakeholders think (unless you happen to have some, like, *extremely* rational stakeholders? Which would be awesome? But also surprising?).

The discussions of what Bertha would think are for *you* to understand how to map engineer concerns to potential value for the business.

In later chapters, we'll show how to bring your stakeholders along on this journey (and visibility will play a central role in that).

Second, I do not develop precise, dollar-figure estimates of potential increases in company value.

I have always been interested in doing so, but instead, I've focused on creating good enough visibility to make good enough tradeoff and prioritization decisions, frequently enough.

My hunch is that getting into *repeated* decision-making loops is more valuable than making a single decision incredibly well.[fn:: the best of both worlds is running a one-time heavyweight process to determine decison-rules that bake in an overall economic framework. See Don Reinertsen's story about aircraft weight/cost tradeoffs.]

Okay, let's go.

** Ship Smaller Changes More Often
*** The Economic Value

Our economically rational investor Bertha understands that your company's future profits are, ultimately, strongly influenced by by how quickly your engineering and product team can go through repeated cycles where they build, then ship, and then *learn* (and then start over again with build).

Being, frankly, *more* rational than the median software company CEO, she understands that it is only through such learning loops that teams can hone in on software that is both *valuable to customers* and *feasible to build* (the intersection set of those two is essentially impossible to predict in advance).

The faster teams can go through such loops, the more quickly they'll be able to develop new products or services that customers are willing to pay for (and be able to address issues that are causing customers to churn, and be able to reduce the cost to serve customers, etc).

For a company where technology plays some central role in the business, those discovery loops are at the very heart of how engineering and product teams increase company value.

Thus, the speed of learning and discovery has a huge, multiplicative long-term impact.

A team that goes from shipping once a quarter to shipping once a month can make *3 times* as many decisions-based-on-learning in a year.

(For those curious to learn more, please enjoy [[id:D901A4C9-885B-4F42-8B8D-3595616857E8][The Extraordinary Value of Knowing What To Do Next]], which I have crammed into an appendix because, frankly, I could not help myself)

But, wait, if Bertha is *more* rational than the median company CEO, because the median company CEO doesn't fully understand the value of being able to safely and quickly ship small changes, how can you motivate investment in this area?

Luckily, you and Bertha have strong support for your shared belief in the economic value of improving deploys, thanks to the truly marvelous book Accelerate.

<XXX and XXX> conducted *actually valid research* (in software engineering! it's nearly unique!) and demonstrate a clear link between long-term company value and the speed, frequency and safety which which teams are able to ship code.[fn:: shipping code isn't the same as releasing it. Value is created if small changes are frequently *deployed* to production, even if customers can't *see* those changes -- e.g. because they are hidden behind feature flags.]

Accelerate names 4 Golden Metrics:

 - Deploy Lead Time: the time to get a single change out to production

 - Change Frequency: how often each engineer ships changes to production

 - Revert Frequency: how often changes have to be reverted after deploy

 - Mean Time to Recover: the average duration of outages

That said, I (no longer!) ask my stakeholders to read Accelerate. Instead, my current game plan is:

 - Name "smaller, more frequent deploys" as a known industry best practice

 - Cite Accelerate as research-based evidence

 - Ensure the Accelerate metrics are both visible to and understood by stakeholders

 - Ensure stakeholders hear about the wins enabled by small, frequent deploys

*** Forms of Visibility
**** Small

Ask engineers to manually log their deploys in a spreadsheet.

Write some quick and dirty scripts to scrape log files.

Run a weekly survey or Slack workflow to ask people about how long the worst deploy they did in the last week took.

**** Medium
Capture versions of 1-2 Accelerate metrics.

Instrument your deploy pipeline to measure how long various stages within it are taking.

**** Large

Set up a durable team that is responsible for release tooling, and hold them accountable to reporting on the core Accelerate metrics.

Bootstrap an engineering-team wide practice of high-quality post-mortems, with widely visible summaries (see below).

*** Some Notes On Working With Accelerate Metrics

A few tactical points if you are going to spend real time with the Accelerate metrics.

The second two -- Revert Frequency and Mean Time to Restore -- are a bit tricky.

Each represents a genuinely important piece of the puzzle of enabling small, safe, frequent deploys... but I've never found a way to stick a *number* on them that didn't immediately get stuck in a definitional morass:

 - When is an urgent redeploy actually a "revert"?

 - When is a revert just a planned test?

   Say, by some engineer exploring an issue in that one horrible part of your system that requires deploys to work on at all? (You know, the part where the git commits all say things like "Maybe fix this time?", "Goddamn it", "Work plz")

 - When do we say an outage is fully "over"?

Your log files don't tend to have good proxies for these.

Thus, instead of aiming for *numbers* to build visibility into these proxies for resilience, I recommend developing a practice of running thorough post-mortems with clear, widely shared summaries of the findings (see [[id:3DE23585-34F0-4C88-A16B-4558ACC45C99][Make Your Post-Mortems an Act of Visibility]]).

That said, I *do* recommend measuring Deploy Lead Time and Change Frequency.

Those are super powerful and tend to be more amenable to measurement from your technical systems.

As you dig in, be ready to spend real time to wrestling with questions such as:

 - Do we break out measurements for different "kinds" of deploys (front end vs back end, legacy code vs new system, one repo vs another, one team vs another)?

 - How do we determine when an engineer "intended" to ship a change to production?

 - How do we measure / report on engineers batching up sets of changes and shipping all of them at once?

 - How do we measure / report on single "conceptual" changes that require multiple deploys to get fully live?

 - Do we distinguish the hot fix/urgent path from normal deploys?

** Enable (Specific) Product Improvements

Your product team has an ambitious plan to build something cool.

Good news: customers are genuinely eager to use this cool thing!

Bad news: building it will require your team to dig into that horrible part of the legacy codebase that was initially written by contractors ten years ago, has no tests that you can trust worth a damn, and is based on a data model that is a malevolent joke against your current reality.

*** The Economic Value

The core trick here is to convert this from a technical investment to a *product* investment.

In other words, the product team *already thinks* there's value here -- they just don't realize there's more of a *cost* than usual.

Let your product team talk to Bertha about how great it will be once this new features ships.

Bertha is ready to hear from you that she should be careful about how strongly she believes in this promise of future profits, given the risks larded throughout this part of your codebase.

Making those risks visible and gradually wearing them down will therefore create value.

*** Forms of Visibility

Fundamentally, these are intertwined with the tactics for a significant rewrite -- e.g. see my How to Survive a Ground Up Rewrite. But I'll call out a couple with specific tactics with regard to visibility.

**** Small

If your team is *totally unfamiliar* with the terrifying code, create a spreadsheet of "engineers who are able to develop, test and safely deploy a change to System X".

If your team can, like, check out and build the code, but don't know how to make any meaningful changes, create a spreadsheet of "engineers who know how to work in System X".

Those may sound a bit silly, but *showing* your product team a list of the exactly one engineer who can currently even check out the legacy app is a genuine form of visibility.

You can base your decisions and goals for an upcoming sprint on that shared visibility, you can later update it and show progress over time, etc.

If the team understands the code, but the data model imposes a painful set of restrictions, you can write a set of User Stories reflecting this[fn:: I adore user stories,- especially in the formulation from User Stories Applied.]. E.g. explain that the current data model means you're currently *unable to support*: "As a teacher, I can batch assign to all students in my class in one step". That user-story form of visibility is generally much more effective than something more abstract-sounding, like, "We don't have reliable mappings from students to classes to teachers in the database".

If working in this system has the potential to irreversibly corrupt key customer data, and there are no guardrails to prevent you from doing so, you can share that fact with your product team. Try to find and share a few measurable guardrails (e.g. frequency of backups and/or speed of restore).

**** Medium

Hidden dependencies are often at the core of why it's so difficult to safely change legacy code. Various medium-sized projects can make the dependencies in production visible. I'll sketch in a few ideas in a section below.

You could run a tightly timeboxed effort to build a deliberately crude but functional prototype. This can both create visibility into current limitations (stakeholders will be able to *feel* the limitations), while also creating visibility into the specific challenges of working in this particular codebase (which can then identify and motivate further investments).

**** Large

You want to find something that matters to your customers *and* your business.

It will be project-specific, because it should reflect the specific business challenges you're solving by adjusting the code.

Again, the potential *value* here is already clear to the rest of the business -- you just need to show that you've enabled some of it.

As an example, at Ellevation, Justin Hildebrandt led a major effort to restructure a student-facing product, in order to better support the various workflows that teachers needed to assig and reassign work to students.

Justin spent real time ensuring his stakeholders understood the limitations of the old, rigid assignment system. Once the team had stitched a more flexible one through the code (which involved touching almost every part of it, because assignment was so fundamental to how the product modeled the world), they were able to demo some basic new features that were simply impossible to build before.

Such demos were a very powerful form of visible progress -- and they were perceived as valuable in no small part because Justin took the time to ensure everyone understood what *wasn't* possible before.

*** Tactics For Making Dependencies Visible

Code dependencies are bad enough, but the really nasty problems tend to come from *data* dependencies -- things your compiler and unit tests have no idea are happening behind their backs.

One useful approach to finding data dependencies is to push "fake data" through your production systems on a regular basis. You can then make sure that every system that consumes the data knows to log and discard that fake data.

E.g. you can add a series of known transactions from "Robert ;Drop All", every day, as a sort of tracer bullet, fired into your systems.

# XXX add link to the tracer bullet pattern, which totally exists?

Initially, that will create a flurry of exciting production bugs as people start finding Bobby in systems you had no idea consumed your data.

Those bugs are a small price to pay for gradually mapping out the hidden data dependencies.[fn:: As a bonus, you can then start monitoring for the *presence* of Bobby transactions, which will totally save you some day, when a trivial config adjustment silently kills the flow of data to your most important consumer]

Brief soapbox rant: engineers or stakeholders might say "Oh, that's going to take too much time, we don't know enough about how the code works to safely add fake transactions."

Um, if you don't know how to add fake transactions, you don't know how to add *real transactions*.

It is usually much faster to learn by attempting to add something deliberately fake and *looking for it* than by shoving through a real change and then spending the next several months getting absolutely nothing done because you silently broke half of production (and now enjoy a parade of people showing up at your desk, furious and/or distraught).

Okay, off soapbox now.

Anand Mukhandan did a brilliant version of this at Wayfair, when he took a terrifying giant PHP file with hundreds of distinct if statements and figured out a way to log the *combinations* of ifs that were most often getting triggered in production, which he could then factor out into coherent functions.

*** The Golden Cesspool

I will make a bold prediction: this specific flavor of technical invstment opportunity is never going to go out of style.

As Edmund says in his blog post, The Golden Cesspool[fn:: https://www.tomheon.com/2017/03/24/the-golden-cesspool/], almost all companies seem to have some genuinely hideous mass of code sitting at the heart of their business.

Over the years tons of complex business logic has been shoved into that cesspool. Lots of other critical processes are tied to data updates in the cesspool. All sorts of state gets updated in all sorts of deeply non-obvious ways.

Your engineering team likely already thinks about this morass as a prime example of tech debt, and are itching to rewrite it.

They may, in fact, resist an attempt to methodically build visibility and then incrementally improve things (with each increment unlocking some narrow set of product capabilities).

Instead, they'll make the faux-economic argument that it'd be better to just commit to a ground-up rewrite of that core system.

They'll claim that it will be both faster and cheaper to do so "from scratch" rather than through a slow, incremental shift.

Once that rewrite is fully finished, the things the product team are asking for will be super easy to build!

What could go wrong?

Please see our later chapter: "The Giant Rewrite: Only Undertake If You Wish To Later Be Fired Midway Through a Long & Painful Death March", which has some tips on how one *can* gradually rewrite such systems.

** Reduce Steady-State Operational Work
Most engineering teams I've seen have, in addition to their "main" work, at least three buckets of things that take their time.

 - Steady "operational" work

 - Production bugs

 - Outages and incidents

There's no bright line dividing those three, but I have found different tactics to be useful for each.

We'll start with the steady operational work.

This is anything which the engineering team does for the business on a regular basis, but which is not directly related to the main new value they're trying to create.

Some typical examples include:

 - Executing manual account setup tasks for new customers or new users

 - Managing a queue of data issues that need hand-massaging to fix

 - Working with BI to maintain views into data the team owns

The key characteristic is that these kinds of work are (relatively) "steady" -- unlike production bugs or outages, which arrive without warning and often have to be resolved quickly to prevent damage to value.

*** The Economic Value

There are two distinct ways that Bertha understands the potential for value here.

First, Bertha suspects there might be value for the company if the engineers could just spend *less time* on operational work.

Note: in this belief, she is likely heartily joined by both the engineers and their stakeholders.

Spending less time on operational work could free the engineers up to work on something that would be more fun (for sure!) and more valuable (um, hopefully?).

If that other work is (probabilistically) likely to lead to greater profits in the future, Bertha will happily ascribe real value to replacing operational work with "something else".

However, that's not the whole story.

That operational work, thankless though it may be, is very likely creating *some* form of value.

Bertha cares about that value, too.

It would be a mistake to assume the operational work is just waste -- even though it may *feel* like waste to both the stakeholders and the engineers.

*** Forms of Visibility

There are two different forms of visibility you'll want to aim for.

First, you want to simply make it clear *how much time* the engineers are spending on operational work.

That in and of itself can sometimes motivate a real investment to speed up or fully eliminate some operational tasks the engineers are currently doing.

But also, you often want to also build visibility into the *value being created by the operational work*.

That is particularly important if the operational work is difficult to fully eliminate, and you want to move it *off the team*, and find a home for it somewhere else in the organization.

E.g. say your engineers spend some time every sprint helping set up tricky data import configurations for new customers. It's just not possible to automate all that away, because it requires carefully reviewing test data files from customers, testing out the imports and diagnosing failures, etc.

Imagine you were go to the Important People at your company and say, "Can we create a dedicated Data Operations team so the engineers can spend less time on new customer onboarding?"

There is a real danger that Important People will hear that as a form of *complaining*.

Everyone's job has certain unpleasant and/or boring parts, many Important People are very good at ignoring complaints that they hear as: "Part of my job isn't fun, can I stop doing that part?"

There's certainly nothing particularly *urgent* in the above.

You might be able to make a more effective case by saying something like:

"It currently takes three weeks to onboard new customers, and delays in the back and forth to get data imports set up are the main driver. That work is currently being handled by the engineers, but a) they are expensive, and b) it often takes a few days for an engineer to find time to review a question from customers, which adds a lot of delays and frustrates customers. We'd like to talk about finding a better home for that work, so we can both improve onboarding times and reduce costs. Our early estimate is that 70% of the work can be done by the more technical members of the help desk, if we can carve out time for them, and the engineers can build some basic tooling."

That's speaking to potential benefits -- both visibly better customer experiences, but also lower costs *for the operation itself*.

There's a decent chance you can loop in your product team to help build this kind of case, because they would love to have more of "their" engineers time devoted to "their" work.

**** Small

Talk to your team to develop an inventory of the different kinds of operational work they spend time on.

Ask your team to roughly estimate how much time they spend on work in each category, per week/month/quarter.

For each category of operational work, build an initial sketch of the value being created. You will likely need to talk to stakeholders outside of your normal set to do this. Value can both be creating good things (happier customers) and preventing bad things (avoiding losing data, etc).

**** Medium

Tag and categorize operational work in your ticketing system (and possibly ask engineers to, when they work on "ops" tickets, log the time on the tickets), so that you can produce summary views of time spent.

Build visibility into the value being created by the operational work -- find some way to create a view into whatever business process is being enabled, or risk is being reduced.

**** Large

Build visibility into "good performance" of the operation -- not just the overall metric, but some substeps which offer ways to decompose the work.
** Reduce Interruptive Maintenance Work
Sure, in theory, there's a bug prioritization scheme in place, which is supposed to insulate your engineers from constant distractions.

But maybe your company has a sales team?

And people who work in sales, for reasons of both personal disposition and compensation structure, have this tendency to try to route around the rules, to get extra focus on the Very Important Problems of their own, Very Important customers.

So one of your long-tenured engineers, who suffers from the misfortune of being both experienced and also, y'know, *nice*[fn:: Hello Tom Hare! Hello Lisa McCusker], ends up getting a stream of emails and slacks from half the sales and/or success teams.

And a lot of what she gets asked about feel like feature requests in disguise?

But she also don't want to leave customers in the lurch?

Ugh.

*** The Economic Value

As with other forms of "distraction", Bertha will see a couple of different kinds of potential value:

First, if the engineers could spend less overall time fixing bugs, maybe they could spend that time working on something more valuable.

Second, even if they spent the same amount of overall time actually fixing bugs, there could be real benefits if they could make that work more *predictable*.

As in, in the current model, their focus is being continually blown up by these urgent, time-sensitive questions. Engineering work rewards periods of sustained focus, so Bertha would estimate future profits as increasing, if the team was able to create longer periods of sustained focus.

Finally, there's a more subtle potential for value, that can open the door to some interesting tactics for cleaning up this pattern:

The engineers are spending some time dealing with, let's call them emergent customer problems.

The choice of *which* such problems to focus on is actually an opportunity for value -- and shouldn't be left up to the vagaries of which sales lead is the most persistent or used to go out drinking with one of your engineers.

If you can come up with a *better way to choose what engineers work on*, Bertha might see that as improving your future profits, as well.

The reason this can be a real win is that it can allow you to *get the VP of Sales* to crack the whip on her team, to stop them from bothering your engineers all the time.

As in, if that VP of Sales understands that there's a first-class process in place, that allows *someone* on (or near) her team to work with the engineers to prioritize key fixes, she may well be ready to strongly enforce better pattens of behavior.

And she's guaranteed to be better at managing sales people than most engineers ever will be.[fn:: I once asked Marion Kennedy Amos, then Ellevation's VP of Sales (now the CEO), about the challenges of interviewing sales people, and she rolled her eyes and said "It's the worst"]

*** Forms of Visibility
**** Small
Ask your engineers to estimate how much time they spend on reactive bug fixes, especially ones that come outside of normal channels.

Ask follow up questions about how they *decide* which bugs to work on (i.e. make sure they don't skip to the part where they were actually coding, which may have been a small fraction of the time they lost to distraction).

Maybe shadow one of them for part of a day, to see just how often requests come in.

Have a quick meeting with your engineers, to identify any patterns in the bugs they fix -- e.g. is there a slew of bugs around login issues? Or maybe customer data imports?

**** Medium
Bootstrap a regular (e.g. weekly) maintenance triage session, to collaboratively prioritize key bugs. This is a fantastic pattern, introduced to me by Andy Rosequist, check the Maintenance Triage case stury for more.

**** Large
If there's an area with continual bugs, but a lot of value, make a case for setting up a durable team to own, e.g. authentication.
** Enable Parallel Development Across Multiple Teams
** Everything Everywhere All In the Same Goddamn Place At Once
*** Scrap/Experiment w/ story
aka, The Value Of Enabling Multiple Teams To Work In Parallel

At Ellevation, in early 2021, the product team had identified an opportunity they were eager to pursue.

# a major strategic investment they wished to make

# A new way to solve one of our core customer problems

Unfortunately, doing so would require overhauling multiple core product features.

It was going to be a big enough effort that we expected to have multiple teams working on it for a long time (spoiler: they ended up working on it for a very, *very* long time. But it ultimately proved very, very *very* valuable)

At the start of the work, we knew we wanted one team to expand the set of *data fields* we stored for school districts -- adding dozens and dozens of new field definitions, threading those through the search indexing subsystem, updating the sprawling queries and dashboards built on that data.

We wanted another team to build a new suite of tools for creating and sharing forms and reports built on top of those new fields.

Unfortunately, at the start of the work, the code to do those "two parts" was snarled up together -- and some of it lived in the hoariest parts of the legacy product.

Practically every user story we could come up with required both teams to adjust "their" sytems -- and we kept on getting tripped up by trying to split that work up.

Trivial-seeming decisions about the front-end UI for creating new forms would turn out to be blocked by esoteric bits of search indexing logic in the backend.

But, since the work was spread across multiple teams, it would sometimes take us *weeks* to discover those restrictions.

Sidebar That I Literally Can Not Resist Writing: this this *this* is the thing that people just don't want to understand about the costs of dependencies between team -- if those teams are not operating in total lockstep, then "small" discoveries and "small" adjustments that would, within one team, take a day or two can easily take a month or more.

And, guess what, developing software is ONE GODDAMN DISCOVERY AND ADJUSTMENT AFTER ANOTHER.

Or as Kellan Elliot-McCrea says with less swearing in [[https://kellanem.com/notes/on-team-size][On Sizing Your Engineering Organizations]]:

/Coordination swamps all other costs in the development of software./

Given this context, there was *massive* potential value in a technical investments to *enable parallel development across multiple teams*.

Bertha, our economically rational investor, would be thrilled if Ellevation found a way to enable those two teams to move quickly and independently, each making their own discoveries and adjustments as they went. She would increase her estimate of future profits -- since we had a credible hypothesis about the increase in future profits if we could overhaul these core features.


We knew it was going to take real work

But we wouldn't find that out for weeks, so development just kept stalling out.

# Given this, massive value for enabling parallel development

# But, how can we make that visible?

# Lucky, tech savvy product team. Even so.

# A long, long period of struggle

# Maybe: build up an imagined version of this?

*** The Economic Value
*** Forms of Visibility
**** Small
**** Medium
**** Large
** Reduce Frequency & Duration of Outages
*** The Economic Value
*** Forms of Visibility
**** Small
**** Medium
**** Large
** Reduce Risk of Losing Data
*** The Economic Value
Imagine that a team pauses feature work for a week and spends that time testing their ability to restore from backups.

Their main stakeholders are very frustrated -- this is the Worst Possible Time, the features that the team are working on are So Very Important.

As the team does this work, they discover something terrifying -- their backups are in an out-of-date format, and they can't restore from them. The team quickly fixes the format, takes and successfully restores a backup, and breathes a huge, somewhat shaky sigh of relief.

Was that week waste?

No, absolutely not.

The engineers created a *ton of value* for the company.

Bertha would say that they have meaningfully reduced the risk of angering and then losing customers -- and she would price that into her estimate of future profits.

If you're thinking, "But wait, if her estimate is all about what is known, and no one knew about this problem beforehand, why is Bertha marking the company as more valuable after fixing it?"

The answer is actually pretty simple: if the team *hasn't* been regularly exercising their restores, Bertha will price the company as if there's a pretty good chance that they *can't* sucessfully restore.

Risks don't go away if we attempt to ignore them -- and an economically rational investor will know that.

This is why doing that kind of risk reduction work increases company value -- even if you don't find any massive problems to fix.



# XXX Move all this to use ownership to align benefits with costs

However, even if their product team understands all of this (which is not always the case), it's hard for them to be excited about it... when they are being beaten up daily by executives about the sluggish pace of delivery.

# a) that value is not *visible* to their stakeholders, and, b) if it is visible, it may be perceived as "not theirs".

# -- but often that value does not accrue to *their stakeholders*, nor is necessarily visible to their stakeholders.

The product team may perceive themselves as accountable for creating a *specific kind* of value -- that derived from new features -- and thus see the operational work as in conflict with what they've been charged to do. Even if it's good for the company.

A short-hand: the value being created by operational work may not accure to the team's main stakeholders.

This leads to the anti-pattern of the stakeholder saying "Well, that's just engineering work"... and then trying to bargain that work down into the smallest amount of time possible. *Which may not be the right tradeoff for the business.* (and certainly isn't fun for engineering, who are put in the position of having to either be perceived as slow, or take the risk of being blamed for future failures they "should have seen coming").

# I call this engineering having to "internalize" the tradeoff --

*** Forms of Visibility
**** Small
**** Medium
**** Large
** Reduce Risk of a Security Breach
*** The Economic Value
*** Forms of Visibility
**** Small
**** Medium
**** Large
** Ensure Many Customers Can Use System At Once
Aka, Load & Scale
*** The Economic Value
*** Forms of Visibility
**** Small
**** Medium
**** Large
** Ensure Big Customers Can Use System In Big Ways
*** The Economic Value
*** Forms of Visibility
**** Small
**** Medium
**** Large
** Reduce Cost Of Serving Customers
(But, See: Drunk, Lamppost)
*** The Economic Value
*** Forms of Visibility
**** Small
**** Medium
**** Large

* Scraps
Maybe:

"A Catalog of Forms of Value/Visibility"
"A Tour of Forms of Value + Visibilty"

Map Concerns to Value to Visibility
Concerns -> Value -> Visibility: A Tour

A Catalog of Concerns/Value/Visibility
A Catalog of Forms of Concerns/Value/Visibility

** Structure for each

Value - why Bertha cares.

Visibility:
 - Cheap
 - Fuller
 - Fullest

Incremental Options? Nah, those are the increments.
