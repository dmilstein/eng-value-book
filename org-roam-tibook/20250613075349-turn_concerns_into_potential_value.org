:PROPERTIES:
:ID:       2EC03879-2A23-4546-BCB8-E9A464665A03
:END:
#+title: Turn Concerns Into Potential Value
#+filetags: :Chapter:
* Turn Concerns Into Potential Value
Now, armed with a fuller understanding of value, we're ready to look at various kinds issues engineers tend to be concerned about.

We'll look for ways to turn those from vague worries into potentially valuable investment opportunities.

We'll ask: What Would Bertha (our economically rational investor) Say?

For each, we'll also share a few ideas on how you might make the potential value *visible* to stakeholders.

Here are the four concerns we're going to dig into:

 - "This Code Is a Nightmare From The Black Depths of Hell"

 - "Deploying To Production Saps My Will To Live"

 - "I Can't Find a Moment to Think"

 - "The Database Is On the Verge of Death And No One Cares"

** "This Code Is a Nightmare From The Black Depths of Hell"

Bad code isn't something Bertha really cares much about, in and of itself.

She's seen plenty of companies grow their profits despite a codebase that would make Cthulu cry[fn:: I'm 99% certain this is Edmund's line, hi Edmund!], and she's *also* seen plenty of startups sink beneath the waves, despite the most DRY'd up clean code you can imagine.

# XXX Check Speeding Up Your Eng Org -- I *am* stealing that joke from Edmund, right?

However, when the engineers hate the code with the heat of a thousand suns, there is /sometimes/ a potentially valuable investment opportunity hovering nearby -- something Bertha *would* care about.

For example, an opportunity Bertha would listen to pretty carefully is one that would:

*** Potential Value: Enable *Specific* Product Improvements

Say the product team asks for some feature that is, unfortunately, borderline inmpossible to build, given the way the code is set up.

An example I've seen many times: the product team wants to build some hot new feature that, unfortunately, has the trivial prerequisite of restructuring the core data model for the business.

If Bertha hears that the engineering team has found a safe way to incrementally restructure that core data model, and can now add the new feature, she will increase her probabilistic estimate of future profits[fn:: she'll increase that estimate a lot more if there's evidence customers actually *want* the feature -- so maybe figure that out first?], and thus the company's value will *increase*.

On the other hand, if Bertha hears that the engineering team has restructured the core data model, to make it "better" and "more flexible"... but did so on their own, and have not unlocked any specific product improvements... Bertha is gonna be *pissed*. Her estimate of future profits is going to go *down* as a result. An engineering team doing that kind of work has destroyed value for the company.

Value is not created by adding some kind of theoretical or abstract form of flexibility.

But, how might we make this kind of potential value more *visible*?

Well, first, we need to help people really understand the current limitations.

As an example, at an EdTech company, there might be painful limits around how the system models the assignment of lessons to students.

Assignments have a whole state machine-like lifecycle, plus lots of logic around who is allowed to make assignments to who, plus privacy laws impacting some of those bits, plus all of that has exciting time-varying issues as both students and teachers move in and out of classes during the school year.

As is often the case for such fundamental challenges, there are both code and data challenges. The limitations are driven *both* by how assignments are modeled in the system, and also by the quality of the "rostering" data ingested from the schools.

The engineering team, who have lived and breathed the core lesson assignment model for years, might try to convey the challenges in some requested new feature by saying:

/"This is going to be very hard, because we don't have reliable mappings from teachers to the *combination* of students and classes in the database"./

If you're exceptionally lucky, you might have a PM who is fluent enough in SQL to visualize the restrictions that imposes.

But, even in that case, odds are good that the PM won't be making tradeoff decisions on their own -- so you'll be *very* well-served by making those restrictions comprehensible to a broader audience.

So, what are other options for creating visibility?

I'll name two.

First, you can try leaning on *User Stories*[fn:: I *adore* user stories, especially in the formulation from User Stories Applied, by <XXX whathisname>].

Instead of talking about the details of the DB tables as above, you could write a careful memo explaining that:

/The current data model does *not* support: "As a teacher, I can batch assign to all the students in my class in one step, in order to support the lesson I taught that day"./

/With the current data model teachers would have to make assignments one at a time./

That user story form of visibility is generally much more effective than an abstract statement. The human mind is deeply wired to understand *stories*, that formulation is a little miniature story.

The best way to play this game is to build a *set* of such user stories, covering different facets of what the team believes users need.

Such a list allows you to:

 - Priority sort work in collaboration with stakeholders

   You can ask "Which user story should we build first?", and "Which ones are worth making a significant technical investment to unlock?"

 - Demonstrate incremental progress

   "We've enabled 3 of the 10 key user stories" is a fantastic form of visible, incremental progress.

   It's so much better than some made-up progress metric, like "Our replatforming is 30% complete". Sooooo much better.

 - Pivot to other work if/when you discover you've met the important uses cases

   I'm going out on a crazy limb here and suggest that, although, when the user story list was first developed, every single one of those 10 key stories was *absolutely critical* ("How can you even ask?!?"), now that you've built exactly 4 of them, your  stakeholder might change their mind, and realize that those 4 are a perfectly reasonable increment to ship to customers.[fn:: This is part of why I recommend pushing very hard for establishing a simple priority sort -- I find that more effective than aggressively front-loading an argument about the *specific* scope of an initial launch.] Thanks to the magic of Hindsight Bias, about five minutes after making this decision, your stakeholder will believe they always knew that they just needed those four stories.

Usually, developing such a set of user stories also has the salutary effect of forcing the engineers and product team to *talk to each other*.

So that's the first idea.

The second tactic, which can in concert with the user story approach, is to build a crude but usable prototype on top of the *current data model* (or, possibly, on top of "the simplest possible extension to that data model").

Such a prototype:

 - Allows stakeholders to *experience* the restrictions, instead of imagining them

 - Gives the engineers an opportunity to learn precisely where the limits of the current data model and data set lie

 - Creates something you can incrementally keep improving (and showing!) as flexibility is added under the hood

 - Can be shown to customers, to, among other things, understand which of the user stories they *truly* need

To be carefully clear: if you're trying to create visibility into data model risks, your best bet here is the kind of prototype that offers a visually crude but "real" version of the most important workflows. Like, near-wireframe versions of pages, but hooked up to an actual database.[fn:: At Ellevation, we called such a protoype "An end-to-end shambling mess of the whole system"]

The core capability is that someone can step through various steps of that workflow, in order to understand what is / is not possible. (Tactical tip: your engineers might consider building script to prep time-varying *data* in various specific stages, so that you can demo user stories like "As a teacher, I can reassign a lesson that a student has already completed, and, after they complete it a second time review both responses").

These kind of visually crude, data-centric protoypes, are distinct from prototypes that allow you to explore a new user experience, but aren't hooked up to any actual code.

Such experience prototypes can be *super* useful if you're trying to learn about user needs.

But if what you're trying to do is make visible the *restrictions* in your code and data, such prototypes can easily promise a version of the product that is forbiddingly hard to build.

Having created visibility with either or both of the above approaches, the engineers might be able to then gradually negotiate their way up the ladder of commitment, to maybe carefully refactor some part of the core data model, or instrument the code around it with much more thorough tests, or even break some subdomain off to a separate service.

And they'll be able to show incremental progress, and offer meaningful decisions, at every step.

** "Deploying To Production Saps My Will To Live"

Maybe the engineers are frustrated because there's an incredible amount of friction involved in getting their changes live -- unreliable builds, manual steps, flaky tests, weird credential issues, tons of post-deploy babystting, a high frequency of reverts, etc.

This kind of problem is actually *easy* to get Bertha interested in. You can frame the positive investment as:

*** Potential Value: Enable The Team To Ship Smaller Changes More Often

Bertha understands that your company's future profits are, ultimately, strongly influenced by how quickly your engineering and product teams can go through repeated cycles where they build, then ship, and then *learn*.

Being, frankly, *more* rational than the median software company CEO, she understands that it is only through such learning loops that teams can hone in on software that is both *valuable to customers* and *feasible to build* (the intersection set of those two being essentially impossible to predict in advance).

Luckily, there's strong support for Bertha's belief in the economic value of fast, frequent, safe deploys, thanks to the truly marvelous book Accelerate.

<XXX and XXX> conducted *actually valid research* (in software engineering! for real! I know, right?!) and demonstrated a link between long-term company value and the speed, frequency and safety which which engineering teams ship code.

What's more, they even define a set of 4 key metrics that you can make the center of your visibility efforts around deployment:

 - Change Frequency

 - Deploy Lead Time

 - Revert Frequency

 - Mean Time to Restore

You can start with rough or approximate versions of those early on, and then gradually improve your visibility over time.

This is what the Ellevation team did, in gradually moving from the manually updated spreadsheet to the full dashboard.

In the Casebook of Technical Investments, we'll go deep on improving deploy, in the section: "Ship Smaller Changes More Often".

** "I Can't Find a Moment to Think"

Wouldn't it be great if your engineers had time to, say, *do software engineering*?

But instead, every day they face what feels like some kind of coordinated assult on their focused work time, thanks to:

 - A stream of bugs and feature requests from customers (somehow every one of them at the HIGHEST PRIORITY)

 - Urgent follow ups from sales/success/support about those bug and feature requests (all arguing for the importance of SOME SPECIFIC BUG)

 - Weird bits of operational work only engineering can do, and needs to get done RIGHT NOW (that manual account set-up step for some Important New Customer, or a data pull that BI needs by end of day, to prep for presenting to Senior Leadership *tomorrow*)

Plus, these interruptive requests tend to fall most heavily on your strongest, most valuable engineers. And that's especially true if those engineers suffer from the  misfortune of being nice.

(I have vivid memories of standing by Tom Hare's desk at Wayfair, watching just a parade of people from the operations teams "wander by", each asking for Tom's to help fix some weird edge case. Tom was such a good engineer! And so nice!).

To use the power of value in your favor, you're might try a mix of:

*** Potential Value: Create Engineering Capacity *And* Improve Operational Outcomes

There are two distinct ways that Bertha understands the potential for value here, and thus two distinct forms of visibility.

First, Bertha suspects there might well be value for the company if the engineers could spend *less time* on all this interruptive work.

In this belief, she is likely heartily joined by both the engineers *and* their immediate stakeholders.

Spending less time on reactive work could free the engineers up to work on things that would be more valuable (hopefully) and more fun (definitely).

# more fun for them and more in keeping with the product team's immediate goals.

If that "other" work were likely to lead to greater profits in the future, Bertha will happily ascribe real value to replacing the reactive work with that "something else".

Visibility on this "engineering capacity" front is fairly straightforward: you want to simply make it clear *how much time* the engineers are spending on operational work (with some multiplier for interruptions, since they blow up focus).

Just viewing the capacity consumed by reactive work can sometimes motivate a real investment to speed up or fully eliminate interruptive tasks the engineers are currently responsible for.

You can build visibility into the "capacity spent on reactive work" by some combo of:

 - Surveying engineers on a regular basis as to how much time they're spending

 - Tagging and tracking tickets

 - Shadowing an engineer for a day or two

 - Setting up a formal triage process to bring reactive work out into the open

All of that can help create enough visibility to make a case for investment, in particular if there's a way to *reduce* the reactive work.

However, that's not the whole story.

The reactive work, thankless though it may be, is very likely creating *some* form of value for the business.

Bad news: *Bertha cares about that value, too.*

If fixing bugs, or restoring the site from outages, or correcting data issues in production keep customers renewing, then Bertha will not be happy if your team simply stops doing that work.

The trick here is to spend a bit of time understanding the *positive* value of what your team perceives as reactive work.

If you can really dig in on that side, you might be able to find creative ways to restructure how much work gets to your team, or make a real investment to eliminate a whole class of issues at a deeper level, or even, propose moving the work *off your team* altogether and finding a home for it somewhere else in the organization.

Those kind of major investments or shifts can be economically rational, but those aren't easy pitches to make, unless you can show the *positive* value to the business, *beyond* just saving time for the engineers.

E.g. say your engineers spend time every sprint helping set up data import configurations for new customers.

Even if they were to invest in better tooling, they can't automate it all away, because setting up each new customer requires carefully reviewing sample data files, testing out imports and diagnosing failures, helping the customers fix subtle issues on *their* end, etc.

Imagine you were go to an Important Person at your company and say, "We'd like create a dedicated Data Operations team"

And the Important Person looks august, and says, "Okay, why?"

And you say, "So my engineers can spend less time on new customer onboarding."

Here's a problem: there is a risk that Important People will hear that as a form of *complaining*.

Everyone's job has certain unpleasant and/or boring parts. Most Important People have developed the skill of ignoring complaints that they hear as: "Part of my job isn't fun, can I stop doing that part?"

You really don't want them to hear this suggestion in that light.

You might be able to make a more effective case by saying something like:

/"It currently takes three weeks to onboard new customers. Delays in the back and forth to setup data imports are the main driver./

/That work is currently being handled by the engineers, but:/
  /a) Engineers are expensive, and/
  /b) it often takes a few days for an engineer to find time to review a question from customers, which adds a lot of delays and frustrates customers./

/We'd like to talk about finding a better home for that work, so we can both improve onboarding times and reduce costs./

/Our early estimate is that 70% of the work can be done by the more technical members of the help desk, if we can carve out time for them, and the engineers can build some basic tooling."/

That's speaking to potential benefits -- both a better customer experience, but also lower costs and better outcomes *for the operation itself*.

There's a decent chance you can (and should) loop in your product team to help build this kind of case. It's usually not too hard to get their help, because they would love to have more of "their" engineers time devoted to "their" work.

There are other variations on this game plan you can run, be it setting up a regular collaborative triage process, or breaking off a separate platform team that owns a particularly troublesome bit of functionality (e.g. authentication and authorization is a classic), etc. We'll touch on a couple in the Case Book of Tech Investments later.

** "The Database Is On the Verge of Death And No One Cares"

The whole company is focused on the next big feature launch, but that one grizzled engineer keeps pounding their fist on the table, trying to convince everyone the database is about to fall over[fn:: I like to imagine them crying out "Databasus delenda est". And maybe wearing a toga.].

But... that engineer seems to always be worrying about the database?

And no one really knows what would make things better short of a massive and truly terrifying replatforming.[fn:: If you've recently hired a senior engineer who, without having talked to anyone in product or the business, is now busily convincing the rest of your team that a few weeks of high CPU load means you have literally no choice but to move to {NoSQL, Distributed Systems, Microservices}... you're going to want to *quickly* regain control over the "How we're going to ensure our system scales" narrative. Otherwise, things could get *very* out of hand, *very* fast. And also, maybe take a hard look at your hiring processes?]

Unfortunately, you don't actually know how bad things are with the DB.

There have been a few scary spikes in the middle of the day, and there was that time the DB got totally wedged due to what turned out to be locking issues.[fn:: it's not production if you're not occasionally killing spids, amirite?]

But each time, the team was able to find some way to get it going again, and the pains weren't that bad for customers.

In fact, a *different* senior engineer, one who has done some work as a DBA, believes that there's a lot more headroom in the current set up, if you could all just slow down for a minute to find it.

But then a team adds a feature that run a dozen expensive queries every time a customer blinks.

That team is being heaped with praise because the new feature is so sexy, and they're rushing to add something else which will wreak further havoc on your carefully crafted database indexing schemes.

What's an engineering leader to do?

*** The Economic Landscape

The work we've done to build up our model of Bertha and her ability to reason about *probabilistic* future events really helps us here.

Bertha, being rational, knows that sometimes, companies find themselves stuck with a technical architecture that impedes their ability to grow -- and a single shared database hitting the limits of vertical scaling can /sometimes/ create that kind of problem.[fn:: though maybe not as often as some enginers seem to think]

Bertha would ask around the company to learn more.

She'd find out the engineering team does not, currently, have any real idea how soon the database might achieve a state of full overload and grind to a halt.

She'd also find that the engineers haven't developed any options for incrementally improving things.

She'd be at least a bit worried about some of the early signs of DB stress -- the random brownouts during the day, the obscure locking issue.

Given all of the above, how would Bertha come up with an estimate of future profits?

In particular, how would she think about the impact of possible database problems on future profits?

A rational investor like Bertha will make an estimate by averaging over all "similar" companies that she's seen, that possessed the combination of early warning signs of danger with a *lack of knowledge* of how to handle that danger.

She'll know that plenty of those companies got lucky, and found that with a few tweaks to their indexes plus moving some analytics queries to a read replica, they were fine for the next few years (as that one DBA-turned-engineer suggests).

But other companies ran straight into a brick wall, and new feature development slowed to a crawl for a year or more -- which seriously depresses the long-term profit stream (as the *other* engineer keeps warning about).

Given that it's unknown which world you're living in, Bertha will estimate the potential impact of database issues as a *weighted mix* of those two outcomes.

And the bad outcome, even if not particularly probable, is *very* bad indeed if it does occur. So the *risk* (likelihood x impact) genuinely depresses overall company value.

*** Making Risks Visible

The potential value for the business is to *reduce that risk*.

To do that, you'll need some way to make the current state of risk visible -- both so you can advocate for investment, but also so you can verify after investing that you actually made things better.

An excellent way to determine risks associated with capacity is to deliberately oversaturate your system in production and see at what point it collapses.

However, that tends to be a pretty significant investment, so you'll want to get there by climbing a few rungs of the ladder of commitment.

One of the best ways I know to *start* is to develop a practice of *running excellent post-mortems* (see [[id:3DE23585-34F0-4C88-A16B-4558ACC45C99][Make Your Post-Mortems an Act of Visibility]]).

In our story above, this would mean slowing down and taking the time to really learn from both the during-the-day spikes and the transient locking issues.

And then, as some of your high priority, post-mortem-driven improvements, invest in improving visibility, with such efforts as:

 - Instrumenting any key infrastructure that isn't currently well-monitored

 - Leveling up on within-the DB monitoring

 - Going through the exercise of developing good SLO's (see [[id:0A54C1F2-B531-4CF9-9337-8FC336B0AB15][Leverage the Dark Art of "Metrics" In Your Favor]])

 - Running load tests outside of production, and seeing how the SLO's respond

 - Saturating your systems *in* production, to determine bottlenecks and limits

 - Building a picture of which parts of the app could potentially might be sectioned off to a separate database, if you did want to go down that road.

At each step on that ladder, you'll learn things that will allow you to choose what work to do next -- and can share what you learn with your stakeholders, along with concrete options for next steps.
* Scraps/Notes

Now.

Someone reading this is vigorously nodding their head, and thinking /"See, this is why my proposal to fully rewrite all that super nasty code is totally right! Let's goooo!"/

*NOTHING COULD BE FURTHER FROM THE (ECONOMIC) TRUTH.*

Yes, Bertha would be quite happy to see features enabled and delivery speed increased.

However, Bertha has been around for a minute.

If you tell her she's going to get those new features and that faster pace of delivery just the moment the team finishes a big ground-up rewrite or replatforming, she's gonna raise her eyebrows and write something very nasty indeed on her little clipboard.

See our later chapter: "The Giant Rewrite: Only Undertake If You Wish To Later Be Fired Midway Through a Long & Painful Death March".

We'll talk there about tactics that will allow you to safely and incrementally make major changes to your systems.

But, for now, we'll just say: start by making the potential value *more visible* to your stakeholders.

Here a few useful, very lightweight first steps:

If your team is *totally unfamiliar* with the terrifying code, create a spreadsheet of "engineers who are able to develop, test and safely deploy a change to System X".

If your team can, like, check out and build the code, but don't know how to make any meaningful changes, create a spreadsheet of "engineers who know how to work in System X".

Those may sound a bit silly, but *showing* your product team a list of the exactly one engineer who can currently even check out the legacy app is a genuine form of visibility.

You can base your decisions and goals for an upcoming sprint on that shared visibility, you can later update it and show progress over time, etc.


Once you've got that initial visibility, you can set milestones that improve the thing you're showing. And, on the path to those milestones, you can and should incrementally improve the code. But that's not the value you're selling to your stakeholders.



# Key first question: are you actually working in this code, like right now? Or is it just you did a drive by and were horrified by what you found?
