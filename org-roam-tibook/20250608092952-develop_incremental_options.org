:PROPERTIES:
:ID:       03D1870C-E583-4D5C-9589-5E0799793D48
:END:
#+title: Offer Decisions With Options & Off-Ramps
#+filetags: :Chapter:

* Offer Decisions With Options & Off-Ramps
** Intro

# Build Milestones Around Decisions
# Offer A Next Decision Point
# Offer a Timeboxed Next Decision Point
# Maybe retitle "Set Milestones to Enable Decisions"

Let's review where things ended, in our last chapter, for the engineering leader we featured there.

She worked with her engineers to dig into various concerns.

As she did so, she consulted in her mind with Bertha, her economically rational investor (slash imaginary friend), to understand how addressing each of those concerns could potentially increase a probablistic estimate of future profits -- and therefore create value for the business.

With Bertha's help, she narrowed down the list of opportunities to a single leading contender: improving site performance (which the engineers had initially described as "the database seems unhappy").

She took time to practice the skills of tactical empathy, and then deployed those skills on building rapport with her key stakeholder.

Then, we she met with that stakeholder to pitch an investment in creating visibility into site performance, she spoke to both her stakeholder's fears (/"worst case, many of those pages could potentially seem broken."/ ) and their hopes (/"guarantee an excellent experience for the first Enterprise customers who commit to Forms 2.0."/)

She offered some initial visibility that she and her team had built "on the side" as a means to understand why investment is indicated now and not later (/"Enterprise customers who use the old, legacy Forms 1.0 product, all have *much* bigger data sets than we've seen for the new Form 2.0 in production so far"/)[fn:: This is a very useful form of visibility -- the use patterns of customers in different segments should absolutely inform investment.]

She focused her initial pitch for investment on building further visibility. (/"We'd like to propose that we commit time to building a clearer picture of our capacity limits"/)

# XXX Mix in the basic DB server CPU monitoring? If so, mix it back into previous chapter.

To her surprise and delight... her stakeholder was convinced.

But then, before the enginering leader could feel good for even a minute, the stakeholder asked: /"How long will this project take?"/

And then promptly blew right past the proposed focus on visibility, and instead demanded a time estimate for achieving the ultimate outcome:

/"How long will it take to ensure good performance for enterprise users?"/

What can our engineering leader friend say?

She has *literally no idea* how long it would take to improve performance for enterprise users -- she doesn't actually even know yet if there's a performance issue for enterprise users yet! That's why she's proposing an investment in building visibility!

But her stakeholder is staring expectantly at her.

What should she do?

** Some Supposedly Fun Ways To Estimate That I'll Never Try Again

Yep, I've done all of these and have the battle scars and failed projects to show for it.

*** Guess and Pad

Often your engineering team will have a hunch about what they need to do.

Except they won't call it a hunch.

They'll say:

/"We know what the problem has to be. We just need some time to fix it. We can get it done in a week, easy."/

Engineers (who I love! Because I am one!), will say this with perfect confidence...

...even if they have absolutely *zero* understanding of what is causing a problem.

Honestly, I think it's just part of being an engineer -- we *know* that one part of the code was written in a dumb way, it's been bugging us /forever/. Now there's an issue /near/ that code, it /must/ be caused by it.

We can already visualize how we want to clean up the code, and how much better things will be once we've done so.

If your team announces they know how to fix a problem...

...but they have *not* first built visibility...

...and/or have *not* done some fairly deep exploratory work...

...I strongly recommend that you just *nod and smile*.

/"Oh, yes,"/ you say, /"that sounds *extremely* likely. I can't wait to dig in!"/

But under no circumstances should you turn around and use this to scope a project with your stakeholder.

You might think to yourself: "I'm no fool. I'll *pad* that estimate. That way, even if the engineers were a little optimistic, we'll still get it done".

# Mama didn't raise no foolish engineering manager

You might say to your stakeholder "The team knows what to do, we just need three weeks."

And pat yourself on the back for the 3x padding, in going from one week to three.

Ohmygod, please don't do this.

Look back at our running example, which is typical of so many potential technical investments: there's a *risk* of bad performance for enterprise customers, but you don't even yet know what the performance for enterprise customers actually *is*.

Let's say your team tells you their certain they know what the problem is.

They've long been unhappy about how much data gets shipped to the browser.  They are *convinced* Enterprise customers are going to take a hit because they have much larger data sets.

It's time to finally implement pagination!

But the team has *not* measured overall performance for anyone, they haven't profiled requests in production, they have no load tests, etc.

What might the team find in those three weeks of work, when they go to add pagination to only send smaller chunks of data in response to each request... which they "know" will make things much better?

Well, if you're *extraordinarily* lucky, they'll be able to build sufficient visibility into actual enterprise performance, *then* apply the fix they "knew" was the problem, then verify that it worked, then share the results with your stakeholder.

But that, um, almost never happens?

Instead, you'll essentially always get hit by some combination of:

 - *It's hard to build visibility*

   E.g. user-perceived load time is driven both by server-side response time and client-side render time... and it turns out to be deeply non-trivial to link those two up.

   Or the team adds detailed monitoring to production, but customers only do the "heavy" actions once in a while, so there's no visibility yet.

   Or the team tries to reproduce issues outside of production, but they need to generate significant concurrent load and that turns out to be a real engineering challenge of its own.

 - *The problem isn't what the team thought it was*

   It turns out that the database is struggling to generate responses for Enterprise customers at all, so the pagination idea makes things *worse*, not better (because the system now hits the database every time the user advances a page, instead of once up front).

   Or, it's something that literally no one was thinking about -- e.g. the team discover there's a series of weird hops through various gateway servers, and one of those gets transiently overloaded and then slows everything down for a period. And it's been hitting *all* customers, but only the Enterprise customers have enough clout for the team to hear about it.

 - *The problem is very hard to fully solve*

   The team discovers that some engineer early in the company's history re-invented the Entity Attribute Value pattern, and half your customers are storing arbitrary data in implicit per-customer schemas, which are literally impossible to sanely index, and there's no way to change that without fundamentally rethinking what the product promises to your customers. Good times!

If almost any of those Bad Things happen (and you're just about guaranteed that at least one will), you'll find yourself, when your three weeks are up, in a very tough spot.

Your stakeholder is now expecting the "engineering issue" to be resolved, and to "get back" the team's full capacity to focus on "business needs".

Not only do you have nothing to show them, but you may have discovered that you urgently want to spend even *more* time on addressing the issues you've uncovered.

That is a crappy, crappy place to be.

Okay, if Guessing & Padding is a bad idea, because you're papering over genuine unknowns, maybe you should instead...

*** Give a Brief Primer on Company Value & Information Theory

Hahahahaha. No.

Sigh. I so wish this worked.

If you pull this off, please let me know, and I will buy you all the beers to learn more.

*** Refuse Outright

You could simply tell the stakeholder:

/We have literally no idea how long this will take./

I mean, this is... *true*, but it's not exactly *helpful*.

Your stakeholder isn't just asking for an estimate to be a jerk, they're asking because the new information you've shared, as part of your pitch for a tech investment, has *created news problem for them*.

And, ideally, you want to help them solve those problems.

** Understand The Challenges Facing Your Stakeholder

# When a stakeholder learns for the first time about a potential technical investment, they suddenly acquire some new, tricky problems.

# Thanks to the information you've shared with them, your stakeholder has some new problems.

When a stakeholder considers committing to a technical investment, they suddenly acquire two new decisions to make, and one new fear to manage:

 - *Decision 1: how can they make time to /start/ this work?*

   E.g. if the team is going to investigate performance issues in this next sprint, how many planned stories or epics is the stalkeholder going to have to deprioritize?


 - *Decision 2: what should they tell Other People about the impact on Other Goals?*

   If it's going to take more than a sprint or two to improve Enterprise performance, the team is going to have to drop *something* significant to make time.

   e.g. maybe there's that complex new data view that the Enterprise customers have been clamoring for.

   Your stakeholder has been expecting to make real progress on that, over the next few months.

   They now have to decide if that's at risk -- and if *is*, they need to go and socialize that fact across your company.

   If the technical investment ends up taking real time, your stakeholder is going to have disappoint *someone*.


 - *Fear: if the work expands in scope, they will lose all control and won't be able to achieve their own goals*.

   One of a stakeholder's biggest fears is that they'll end up stuck in some endless engineering-driven project, with *no way to stop*.

   Any stakeholder who has worked with engineering has had at least one really unpleasant experience of estimates blowing up beyond all expectation, and finding themselves just mired for months and months, unable to resume forward motion.

   Having that happen for a technical investment feels extra terrifying -- because the stakeholder may not understand any options for shrinking scope as they go.

They're asking for an estimate to make those decisions and to manage that fear -- *even if that's not how they're consciously thinking about it*.

As in, if they had a good estimate stretching out into the future, they could *both* set expectations with Other People, *and* also hold the engineering team accountable to wrapping the investment up in a reasonable time frame.

Unfortunately, as per the previous section, for the vast majority of technical investments, you won't, at this point, be able to give your stakeholder a sufficiently accurate estimate to allow them to solve these (very real!) problems.

But, because we can understand those underlying issues, we can find a way to help the stakeholder, *without committing to a false or damaging estimate*.

Before we walk through how to do so, I want to talk for a moment about how your stakeholder manages "medium-term" goals -- because those medium-term goals are what they're updating, in making Decision 2 ("Who do they need to tell about this shift?").

If you have an even vaguely rational stakeholder, they won't think of their medium-term goals as completely *certain*[fn:: If your stakeholder is *not* at all flexible, and is running your work purely using the rigid tools of 'project management', then, first, siiiiigh. Second, I strongly suspect that, for your company to have any shot at winning, someone will need to bootstrap a product management function. Doing so is beyond the scope of this book -- check out Melissa Perri's truly excellent Escaping the Build Trap for ideas.]. Instead, they'll have some mental model of:

 - The order in which they're going to get to various goals

 - Key risks that could delay various goals

 - Which other people need to be told about changes to which goals, and when

A core part of your stakeholder's job is using this ever-evolving medium-term picture to *collaborate* with people across the company -- be that conducting user testing, planning rollouts, preparing sales materials, or the like.

All of those are *genuinely important* business actions -- and all have genuine lead-time challenges (meaning, the company needs to start preparing for them well in advance -- so having no idea when engineering will finish work injects all kinds of expensive delays).

With our eye on those collaborations, we can find creative ways to help our stakeholder to make their key decisions and manage their fear.

Let's see how.

# They're asking for an estimate that stretches out past the next few weeks to as part of preparing both of these decisions.

** Timebox to a Shared Decision With Options & Off-Ramps

Ultimately, you want to give your stakeholder *visibility* and *control*, so they can make good decisions, *with* you.

The central trick is:

*Design your increments and your milestones around the next decision to make*.

That way, you can offer your stakeholder exactly what they need -- a way to both /understand/ and /control/ this investment, as it unfolds.

Let's illustrate this with our running story, from the last chapter.

As a reminder, the engineering leader wrapped up the initial part of her pitch by saying:

/We'd like to propose that we commit time to building a clearer picture of our capacity limits, and, once we've done that, ensuring that we have sufficient capacity to guarantee an excellent experience for the first Enterprise customers who commit to Forms 2.0./

To help support the stakeholder in making Decision 1 -- "What do we need to do to get started?" -- the engineering leader then says:

/We're proposing that Andrea spends the next three weeks developing and implementing a first draft of Service Level Indicators -- which will show us: "Are customers on Forms 2.0 *using it successfully*?". And if they're *not* -- if they are getting hit by performance issues -- we can know *before* the help desk or success team comes to us./

This does two things.

First, it precisely defines the near-term scope -- not just three weeks, but three weeks of Andrea's time, specifically.

Second, it paints a clear picture of the *benefit* of this first increment: being able to know about customer issues before complaints wend their way through the support machinery.

The engineering leader continues:

/Building SLI's has some real tradeoff costs. We had planned for Andrea to take point on adding new features to the Search Indexing. We think the potential performance issues are a bigger risk. And, if we understand it right, not all the ENT customers need those new Search features, so we might be able to delay the transition for customers who do need them. We believe the risk of bad performance cuts across all of the ENT customers./

By coming to the table with options for near-term tradeoffs, the engineering leader is, again, helping the stakeholder face a genuine challenge -- while still creating space for the stakeholder to disagree or even pusback ("we think", "if we understand it right", "we believe").

Now the engineering shifts to talking about the "next decision":

/The key milestone Andrea would be working towards, which she can hit within 3 weeks, would be to ready to sit down with you and me, and review both the definitions of an initial set of the SLI's *and* how those SLI's are performing in production./

# The goal of Andrea's work is that the stakeholder will be able to make a next good decision, at a specific date, with specific new infomration. They will have both visibility and control.

/We'd then be able to decide, together, if that performance seems acceptable. If so, we can return to our original plans and just keep an eye on performance as transitions ramp up. If performance already seems problematic, or if we're just uncertain, the team could start some proactive load testing, or if we've found any bottlenecks, deal with those./

/But we don't have to make that decision yet -- we'll have more info in just a few weeks./

This little sketch offers three key things:

 - A Decision Point

   In three weeks, there will be a meeting to review what Andrea has learned and make a shared decision about what to do next.

 - An Off-Ramp

   At that decision point, the stakeholder will have an opportunity to cleanly paused or even wind down the investmetn.

 - Options

   The engineering leader is sharing her current understanding of potential next steps: 1) proactive load testing, 2) remediating bottlenecks.

Such potential follow ups allow a stakeholder to update an evolving, probabilistic picture of the medium-term.

The stakeholder might ask questions to flesh out their understanding (e.g. "What might be involved in load testing?"). I have generally found those to be very productive conversations -- so much so that I encourage engineering leaders to prompt for those questions.

Knowing when that next decision point is coming allows the stakeholder to make concrete decisions, right now, about who to communicate with immediately, who to wait until after they hit that decision point, etc.

Let's now flip it around and see if from the engineering side.

We've defined a clean milestone, with a hard deadline of a meeting in three weeks, with an outcome of:

*Support a decision about "what do we do next?"*

An engineer working towards such a "decision outcome" has a great deal of flexibility to adjust scope, especially if you take the time to discuss with whoever is doing the work:

/What information will the engineering leader and stakeholder need to make this decision?/

That is a *great* thing for them to more fully understand.

E.g. say Andrea discovers that adding the SLI's is more work than expected. If she understands the decisions being made, she can shrink her scope to the 1-2 very most important SLI's and bring those to the meeting with the engineering leader and the stakeholder.

The engineering leader can then have *exactly* the meeting that they promised: here is some initial visibility, let's now decide if it's sufficient, and what next steps we want to take.

** Decision/Options/Off-Ramps: Examples
Let's dig into a few scenarios, to illustrate this approach further.
*** Scenario 1: Russian Roulette Deploys

The deploy pipeline randomly fails for no clear reason, and when the team does successfully deploy, they frequently end up emergency reverting in exciting ways.

There is a simply *huge* range of possible problems that could be causing this situation.

It could be anything from some trivially misconfigured CI/CD parameters, which you can fix in a few days, all the way to fundamental architectural choices that are causing genuine ongoing conflicts between multiple teams, which could take several years of work to restructure your codebase to fully eliminate.

Given that huge range of uncertainty, the "next decisions" to make will generally be moving through three progressively stronger forms of visibility:

 - How frequently are reverts occurring?

 - What is the largest driver of reverts?

 - What are the options to address the issue?

At each step, there's a straightforward offramp: pause active work on stabilizing deploys, but *keep the visibility in place*.

Also at each step, the engineering leader should be able to forecast the next couple options to either continue to build visibility, or, if actual issues have been identified, to start to wear those down.

To bring it to life, we'll imagine an engineering leader who has moved partway through that sequence, and is now advocating for further work:

/As we've been talking about, we have a major problem with revert frequency./

/Over the last month, engineers had to rollback just short of 20% of their deploys because of causing issues on the site. That's huge drag on velocity *plus* an unpleasant customer experience./

/We strongly recommend spending some time, now, to see if we can improve that./

/I've talked to the team, and they think there are a couple of buckets those reverts fall into, based on the post-deploy problems that crop up./

/One bucket is "bugs in the navigation bar". The navigation masthead has weird knowledge of all the separate systems, in ways that has been really hacked together over the years. Luckily, the team has done some work on the masthead in the last year, if we have to dig in here, we should have some reasonable options./

/Another bucket, unfortunately, seems to be issues in the ancient legacy reports, which no one knows how to safely change. If that turns out to be a major driver of problems, it could be that we're going to have to bite the bullet and update some of that code./

/In any event, starting today, our proposal is to do two things, over the next two weeks. First, have the engineers spend a bit of extra time categorizing each revert, as it happens, into one of our buckets -- and, as part of that, discuss them during standups every morning. Second, we want to do prioritize a timeboxed bit of exploratory work into both the masthead and the legacy reports, so that we can talk out options with you, at the next sprint planning. We're ready to break out some tickets for that, if that sounds good."/

Before we move on, I'll note that this story illustrates why building visibility first is so powerful.

If you and the stakeholder decide to pause the search for improvements, you'll be able to keep an eye on ongoing deploy stability. If it never improves (or god forbid gets worse!), you're well-positioned to pick the investment back up later.

This is in dramatic contrast to the "Build Visibility Later / Never" plan, which generally offers the much less attractive offramp of: "People have been randomly changing things, nothing seems better yet? If we stop now, when we start again we'll probably retry half the things we've already blindly tried, so can we please not stop? We're sure we're about to fix it."

*** Scenario 2: Your Founder's Favorite Customers' Favorite Legacy Code

Your product has a couple of gnarly old features that only your earliest customers still use -- naturally, they're written in their own Very Special tech stack, that you're not using anywhere else.

But your CEO *personally* acquired those customers in the early days of the business.

And he is *oddly reluctant* to retire those hoary old product features and run the risk of potentially churn those Very Special early customers.

Even if there are only three of them left.

Meanwhile, your product team visibly seethes at the idea of taking months to move those old, barely-used-by-anyone features to the current tech stack.[fn:: I mean, *obviously*, this is actually a conflict between the CEO and the Product team. But at a wild guess from here in the footnotes, at *your* company they've both somehow succeeded in convincing themselves that this is an engineering issue. At a guess.]

Your engineers have been growing more worried and frustrated.

Then, you realize there is a way to make the potential for value much more visible.

Your company strategy is to move upmarket, and start selling to enterprises.

Early sales conversation have made it clear that those enterprises are going to demand attestations of security -- third party audits, penetration tests, architecture reviews.

That nasty old legacy part of your product is just a festival of security issues -- out of date libraries, wide open permissions for operators, that horrible password reset page that can be compromised by running View Source, long-abandoned JS frameworks, you name it.

So now you can build a series of decision points, options and off ramps, along a path to gradually and visibly improving security.

By doing so, you which will force into the open the long-term cost of keeping around this semi-abandoned body of code.

You can both make prioritization decisions *and* generate commitment by referencing the specific demands of the enterprise customers your sales team is spending more and more time with.

And thus, with just some modest luck, you can aim for your *VP of Sales* being the one to persuade your CEO that now is maybe the to thank those early customers for their service and let them go.

And they are the VP of Sales! They're good at persuading people! Plus they have to hit their quota, which I find to be a marvelously persuasive fom of argument.

* Scraps
Your stakeholders will almost definitely see them in that light, certainly at first.

You or your team may also do so -- especially if you've been forced to operate in a scarcity mindset around engineering-driven work. E.g. if you're able to bargain your way into three weeks of "engineering" work in any year, you'll be forced to think "What 'project' will fit into those three weeks"



Tech Investments should absolutely be broken up into defined steps, and each of those steps should almost always should have a clean end date (and therefore be forced to shrink in scope, as that date approaches).

Aka, you and your team should live and breathe timeboxing, when you go to execute on your investments.


Investments are, ideally, "done" when it no longer make sense to continue to invest.

And even then they're not really "done", so much as other things become, for that moment, more valuable to invest in.


Why?

Not just because you don't know how much work is involved, but, more fundamentally, because you don't know when you'll reach a point where the potential value of further tech investment is less than the value of other investments (aka the opportunity cost).

Not only is that hard to even estimate up front, it will *change over time*.



** Old Intro

Things are going well.

You've worked with your engineers to turn concerns into potential value.

Bertha, your economically rational investor/imaginary friend, has helped you identify forms of value based on probablistic estimates of future profits.

You've narrowed down your list of opportunities to the one you think has the greatest potential value for your business.

You've found a creative way to build some initial visibility into that potential value.

You've taken the time to practice tactical empathy, and then deployed your newly practiced skills on building rapport with your key stakeholder.

It's now the Big Day.

You're ready to make your case for investment.

You speak to both your stakeholder's fears and their hopes.

You situate the investment in line with their long-term goals.

You offer the initial visibility that you've built on the side as a means to understand why investment is indicated now and not later.

To your surprise and delight... your stakeholder is convinced.

# They're ready to make the difficult decision to temporarily put aside some of their other priorities.

# Temporarily.

Then, they ask: "So, how long will this take?"

And stare expectantly at you.

And, boom, you're right back in one of the most fun parts of being an engineering leader.


** Old Intro To "Estimates Are Hard"
Obviously, estimates are always tricky.

But they're often *extra* tricky for technical investments.

When digging into complex and uncertain parts of your systems (of both the technical and social varieties), it can be difficult when you start to even *understand your options*.

Which makes it nearly impossible to commit to a time estimate to achieve some cleanly visible outcome.

# Satoe Sakuma said this well, "It's like you're going into a cave, and the first step is just bringing in some light. But then, when they ask you how long it will take"

Once again, let's put ourselves in our stakeholder's shoes.

Let's say we have a stakeholder who is not yet in a habit of regularly co-prioiritizing technical investments with engineering.

Even if that stakeholder fully embraces an iterative approach to software development (which is a best case, not always achieved in reality)...

...there's still a very good chance that, as they're considering a technical investment you've proposed, they're trying to limit the impact of this "unpleasant temporary distraction" on their current goals.

They're reviewing the sprawling list of things things they've been asked to do.

They're reviewing the painfully smaller list of things they believe are possible -- and getting ready to eject a few things from that list.

# They're actively rejiggering their mental map of the next month or two.

They're thinking, "Which people am I going to disappoint in order to solve this 'engineering problem'?"[fn:: It's not an engineering problem! It's an opportunity for investment. You'll get there eventually]

They're likely preparing to bargain you down from whatever your initial "request" for time turns out to be.[fn:: You're not making a request! You're exposing an opportunity for investment. Again, you'll get there eventually]

# Remember their job is to disappoint everyone around them.

So you have to say *something* to them -- you can't just say "I don't know, it'll take as long as it takes".



** Old Scenario 1: Unreliable Deploys

The deploy pipeline randomly fails for no clear reason, and when the team does successfully deploy, they end up reverting far too often.

You have some developed some initial visibility showing that engineers are starting to deploy less frequently as a result.

That, plus a some heavy leaning on Accelerate has your stakeholder ready to talk.

They say, "How long will this take to fix?"

How can you respond?

If you knew *why* the pipeline was failing... it wouldn't be failing.

Ditto for the post-deploy failures and reverts.

You could take a *guess*, based on the team's current hunches about what's causing the unreliability, and say something like "We think we can likely improve things in about three weeks of time, for two engineers."

What could those two engineers find when they dig in?

If you're lucky, maybe they find some misconfigured CI/CD params. You're just a couple of arcane JSON or YAML config tweaks away from more reliable deploys.

If you're *not* so lucky, they might discover that your entire build pipeline is, for deep-in-the-guts reasons, non-deterministically selecting versions to build, test and deploy. To get to a more reliable process, you're going to have to restructure that pipeline at a fairly deep level.

If you're *super, super not lucky*, this might be the moment you realize that fundamental architectural choices made long ago are forcing multiple teams to all frequently change the same hotly contested parts of your codebase, and that's causing *genuine conflicts*. The repeated deploy failures are actually the CI/CD process *doing its job*. You don't have to update your deploy process... you just have to update the most fundamental abstractions in your code. Easy peasy.

In the latter two cases, you're going to reach the end of your three week period, and not only is your stakeholder going to expect everyone to return to fully focusing on the original feature work, but, *you won't be able to show them any visible improvements*.

Instead of this building trust and making your next investment easier to advocate for, you'll feel like you've dug yourself into a hole.
** Tech Investments Aren't Exactly Projects and Don't Exactly End

It's extremely tempting to think about tech investments through the lens of "projects".

We've spec'd out a project, and we're going to do X, Y and Z, and be done by such-and-such a date.

There's something useful in this, but you have to be very careful about how you define the "goal" of the project.

To see why, let's return to our friend Bertha the economically rational investor.

Say you've convinced a stakeholder to "let" your team work on the problem of sluggish site performance. That stakeholder has asked you how long the work will take.

Now, you want to create as much value for your business as possible.

So you ask Bertha, the arbiter of value:

/Given what you know, how long *should* my team work on improving site performance? When should we tell our stakeholder that the work will be over? What will maximize company value?/

Bertha would squint at you, and then say:

/If you want to maximize value for the company, your team should work on improving site performance until precisely the moment that the net benefit of further site performance improvements is less than the net benefit of other work you could be doing, instead./

Say you've just finished a project to deal with sluggish site performance.

You SLI's have achieved an acceptable range, given current load.

Everyone celebrates the "Improve Performance" project being over. Maybe there's a party.

But then the next day, your site gets a huge influx of new users.

These new users adore the base feature set, have very high expectations of responsiveness, and could care less about all the clever new extensions product has dreamed up.

Given the above, it's likely economically optimal for your team to keep working on site performance, and not pivot back to expanding the feature set.

But if you let yourself get drawn too tightly into the project formulation, no one will even be thinking about further potential site performance investments

In fact, if you're extra unlucky, stakeholders who "gave you time" to "fix" the performance are going to be mad, because the site suddenly seems really sluggish again (see: huge increase in usage). What, are they supposed to let the team spend another month on these engineering issues?!? When are they going to get back to business needs?!

Instead of thinking about tech investments primarily as projects, I think you're better served by thinking of them as a series of *decision points*.

You do some chunk of work, make some improvements, build slightly clearer visibility. Then, based on what you've discovered, you decide: should we keep going down this road?

# The companies that make better decisions, more often, are the companies that win.

You want to get your stakeholder into a regular cadence of shared decision-making.

# As part of that, you may need to retrain yourself to think about tech investments not as one-off projects, but as a steady series of opportunities to make choices together.

# This can be particularly hard if you engineering team has developed a scarcity mindset around engineering-driven work. E.g. if you're only ever able to bargain your way into three weeks of "engineering" work in any year, it can feel like the idea of planning for a future shared decision is a fool's move.

/"Fine, Dan, whatever, that *sounds* great"/ I can imagine you thinking, /"but how on earth am I supposed to get my stakeholder to buy into that?"/

Your stakeholder is standing in front of you.

They're waiting for you to tell them how long your first proposed investment is going to take.

They are clearly *not* looking forward to "repeated discussions about potential tech investments", in the future.

What do you say to them?

If you've read this far, you'll know that I've helpfully tested out the strategy of "Explain the abstract theory of the value of decisions" to them, and seen it fail 100% of the time, and am ready to instead share what I *have* seen work.
** Marketing
Imagine we flip this around, to some part of the business where leaders are used to thinking about "positive" investments.

For most B2B businesses, few things are more important than acquiring new, high-quality leads -- potential customers their sales team can talk to.

# If you're helping run a B2B business, odds are good that you care very much about bringing high quality leads into the top of your sales funnel.

Most B2B businesses therefore have a marketing team.

That team spends various amounts of money, to run various campaigns, across various platforms, to acquire leads.

They know how many dollars they spend, on average, to acquire a high-quality lead.

They've developed a plan, which they're currently executing, spending money every month against various platforms.

But then, one day, a new platform shows up, that the company has never advertised on before.

The marketing team runs an initial campaign, spending $1,000.

They promptly get back more high quality leads per dollar spent than on any other platform!

Amazing.

Should they now stop? Because that initial project is "over"? And they have a "plan", they need to get back to?

Of course not.

They should *change the plan*, based on the new information.

If, by making an initial investment, they've discovered that there is even more value to be found, they should *increase* their investment -- not curtail it.

Many tech investments function just this way -- there's a potential source of value, once you dig into it, you may very well find *more* value than you realized, and more than you were expecting to make, from your existing roadmap.

Sometimes that's visibly positive value: "It'll only take another week to apply the new indexing scheme to the rest of our tables, and then the entire site should see better peformance".

Sometimes that's risk-avoidance value: "Our initial security review made clear that things are much worse than we realized -- we think it's more valuable for the company to pause work on the feature roadmap and get to a lower risk state, immediately."

But if your "engineering project" is "over", no one is going to be looking for further investment opportunities.

Because, fundamentally, they're thinking about it is an "unpleasant" project they've been forced to do, not an investment that makes their company more valuable.

You're going to gradually persuade people into working that way.

** Moar Scenarios...

You propose enabling parallel development across multiple teams by inserting an interface layer in the middle of some convoluted mess of legacy code. Product is ready to consider saying yes, but asks "How long will that take?", before they commit.

You propose creating tooling to allow the help-desk to fix a slew of data issues that are currently requiring your team to spend hours a week executing SQL updates by hand. You guessed it -- your stakeholder would be happy to say yes, if they knew how long it would take.

Your backup regimen hasn't been reviewed in a while, you've raised sufficiently economic fear for your stakeholder to agree to some work to verify safer backups -- how long will that take?
