:PROPERTIES:
:ID:       E0ADBF07-90B8-4C37-81C0-96A428020F5E
:END:
#+title: Substack
As part of my [[id:17305FA7-A43F-40C9-9309-0EF3577C70D0][Author Platform]], I've gone and set up a Substack.

* Tooling / Links

Substack Dashboard: https://buildingandlearning.substack.com/publish/home

* Substack Buttong HTML
<iframe src="https://buildingandlearning.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>

* Ideas for posting cadence
3x / week.

Pick out 2 things I've written, and 1 reference to something I like.

Schedule those for, like, Mon/Wed/Fri.

Do it... when? Either EOW, when I'm done writing?

Do it in the afternoon, maybe on Mondays or some such.

For now, reference or all of them on LinkedIn?

** Email to EWJ re posting cadence
Subject: Rubber Ducking Substack Posting Cadence
E-

I want to write out some thoughts about posting cadence plus patterns for Substack, so I can see if I can clarify my own thinking (and of course I super value your take on the below).

So, to start, what is the value of, the goals for posting to Substack:

 - Develop a pool of beta readers

 - Build a seed audience for when the book launches

 - Build a long-term platform

 - Create motivation and connection (by e.g. hearing that what I'm writing is useful)

I think that, if I can make the substack itself recommendable, it helps on all those fronts.

And, even in starting to work on it, I'm discovering something which is kind of blindingly obvious in retrospect, which is:

Because I'm already spending hours and hours every day *writing a book*...

...I have *tons* of content available to post.

And thematically related content, etc.

And I'm not gonna, like, run out, any time soon.

So then the question kind of becomes: how often should I post? Should I worry about annoying people?

I have 3 posts scheduled for this week -- each about 500 words, each, I think, pretty fun and tight (and each having, like, one insight that I think people might say "Oooh, I want to tell someone this").

I took me very little time to get those set up (most of the time was just figuring out how to deal with formatting and scheduling on substack). Cutting and pasting out of all this writing I'm doing is not hard.

So, one option is to post every (week)day. And celebrate that fact.

I could do something like:

 - Mon/Wed/Fri are ~500 word excerpts from the book

 - Tue is Tuesday Thank You Notes, where I spend a couple hundred words celebrating some book or blog post or paper I've found influential in my thinking. I've got a list, this would be fun and easy to write, and create some variety.

 - Fri is Questions for the Community -- something where I'm asking people to send in stories or questions or the like, on some theme (and later sharing back what I hear).

I mean, having written that out, why... wouldn't I do it?

I think there's decent evidence my writing isn't annoying, and it's email, they can just ignore it if they want.

It sounds like a thing that people might well start recommending, esp if it's at all playful and/or fun. Plus if I can get a Friday Mailbag going, I think I would find that super motivating (plus, frankly, great early customer development for later Highly Paid Consulting gigs, if I want to go down that road)

I can likely get the work down to ~1-1.5 hours a week, to prep 5 days worth of posts, out of the stream of writing I'm alrady doing.

Could just build a hbabit around that for, like, Wednesday afternoons, to prep next week's posts.

And any fears that "people won't need to buy the book if it's all out there on a blog" are just batshit crazy and dumb. If the blog gets enough traction that I have *any* worries on that front, I'm selling a metric ton of books, *because* of the traction, not despite it. Just need to like beat myself up over that fear or something.

Thoughts?
D
* About

*Building & Learning*

aka

Some Adventures At the Intersection of Engineering, Product & Human Nature Whilst Engaged in the Pursuit of Value

aka

Some Things I've Learned Both From & With All The Excellent People With Whom I Have Worked Over These Years

aka

Build -> Learn -> Build -> Learn

aka

The Name of the Song is Haddock's Eyes, and The Tune's My Own Invention

(No, *you're* obsessed with Lewis Carrol, shut up)

Hi, my name is Dan.

For the last 30 years, I've worked in various combinations of engineering and product -- I love both discplines, and value both super highly.

I've worked as a principal engineer building and operating complex systems; I've led product at startups desperately trying to find traction; I've managed engineering teams ranging in size from 2 to 500.

Right now, I'm working on a book:

"Tech Investments, Not Tech Debt: How To Make Time For Engineering Work That Matters".

In this herein Substack, I'll be sharing ideas from it and thoughts the writing of it triggers and the like.

(and just possibly some random Lewis Carrol-inspired absurdity once in a while, I make no promises otherwise)

Speaking of said book, if you're potentially interested in being a beta reader at some stage of development, holler at me.


* Posts
** Defining Tech Investments

I believe that the metaphor of "Technical Debt" started it's life as a very useful prompt for economic thinking...

...but has now mostly drifted into a not-very-useful shorthand for *bad code*.

For reasons that apparently require a book to fully explain, I don't think engineering leaders or teams should spend much time talking about "bad code".

Instead, I recommend spending time identifying and advocating for *"Technical Investments"*, which I define as:

Work that the engineers believe is *valuable to their business*...

...but that *no one is asking for*.

The Technical Investment approach, when applied well, leads to very-useful-indeed conversations around:

 - Potential business value

 - How to make that value visible to key decision makers

 - How to safely and incrementally realize that value

Of course, bringing stakeholders along on that journey is somewhat profoundly non-trivial, so I'll be spending real time in the book on how to build trust and rapport with stakeholders, as an enabler for making major technical investments.

** Tech Investments - Build Visibility Into Value

Instead of technical debt, engineering leaders can ask their teams *and* stakeholders to talk about *technical investments*, which I'll define as:

/Work the engineers believe is *valuable for the business*, but that *no one is asking for*./

That puts the focus on the genuine problem: a *mismatch in understanding* between the engineers and their stakeholders, about what is *potentially valuable* for the business.

At heart, the vast majority of both engineers and stakeholders want to create value for the business.

They just have different information and beliefs about how best to do so.

Many engineers try to resolve this gap by *explaining* the potential value: "You see, when code has bad 'coupling', a change in one place can impact many other places, which is a drag on development. This is why we should spend a week refactoring."

Although there's a good instinct in this -- bringing the stakeholders into a shared understanding with the engineers about what is valuable -- it has one crucial flaw:

It requires the stakeholders to take the entire statement of value on faith.

There is nothing they can *see*, that shows them things are "bad", before the investment is made.

And there will be nothing they can *see*, after, that shows them things have gotten "better".

Given that lack of visibility, it's hardly surprising that stakeholders, confronted with such a choice, often feel like they are giving something up and getting nothing in return.

One of the core theses of the book is that engineering leaders have a wide variety of options to *build visibility* into potential value.

It is *massively cheaper* to build such visibility than it is to make the full investment.

Once there is visibility, the engineers and their stakeholders can look at it, together, and operate from a shared understanding of the reality of the business.

If the engineering team can then offer disciplined, incremental steps to gradually (and visibly) improve things (including improving the depth and reach of the visibility), theu can build real trust with stakeholders over time.

That then allows them to "climb the ladder" from small initial investments to, sometimes, very major, transformative investments.

The best way to do that is not as a one-off project an engineering leader puts all their authority on the line for (ugh, I've done that so many times, and never seen great results), but instead, a series of repeated *tech investment cycles*, each of which generates visibility and options.

All in partnership, not opposition, with stakeholders.
** Tech Investments: Favor Repeated Cycles Over One-Off Projects

If you're stuck in an oppositional relationship with stakeholders who don't seem to care about anything except their feature list, it may feel like your best bet is to carve off a big block of time so the team can just go and definitively fix their problems, without interruptions.

I have tried the "Bargain for one giant chunk of time" approach, and, unfortunately, it has been something of a consistent disaster.

Technical investments are *far* more effective done as a series of repeated small steps, instead of a single giant one-off project.

There are at least two reasons for this.

First, in the big bang mode, the stakeholders don't tend to see the work as "valuable".

Instead they see it as a "painful delay", and as such, feel "owed" immediately faster progress on their features.

Which is not always the immediate payoff for a technical investment -- even an extremely valuable one.

# XXX Add: especially if the big bang investment has no associated visibility?
# XXX Tease apart: don't start here vs it's okay to build to this
# As in the real problem is if you use the one-time nature to avoid fully educating the stakeholder and ensuring they can see the results of the investment.

But the big bang approach is not actually good for the engineers, either.

Real value is often created at the intersection of the technical and human/social systems (see Allspaw on Socio-Technical) -- and those are essentially impossible to adjust in big, fixed steps.

E.g. two significant forms of value are:

 1) reducing the time to get code to production

 2) reducing the time to restore from outages

# XXX increasing the load a system can handle? Increasing capacity to match current demand?

Both are *extremely* valuable for a business (more on both in [[id:E7DB3CD4-9B7B-425B-BF07-E2607DDD6670][Forms of Value/Visibility]]).

But neither is effectively addressed as a single big bang investment -- you have to steadily improve things, see where new bottlenecks or problems occur, and then pick the next thing to focus on. That kind of effort take real calendar time -- you have to see a set of "improved" deploys, or see how the team is able to handle the next set of stresses to the system, before you can understand your next step.

# Footnote?
(if an engineer tries to convince you that all the stability problems in the site will be addressed by rewriting the entire thing in Rust, you should +fire+ firmly persuade that engineer to think otherwise).

# Maybe: do a single one in detail, then list a slew of others which also need steady digging and learning

Thus, what you want is to get into a *cycle of technical investments* -- where you are repeatedly identifying small potential improvements, advocating for those, and then executing on them.

Going through this cycle *with* your stakeholders will gradually build trust and rapport over time.

# (and a shared understanding)

That increased trust, rapport and understanding will allow you to "lever up" to larger and larger investments.

You should, of course, still *execute* the work in incremental steps (because that is how all software should be built) but you can use these repeated cycles to gradually climb the [[id:722C702D-A6C2-4A51-AB62-515CE8144AA2][Ladder of Commitment]] for technical investments:

 - On the Side

 - A Single Ticket

 - A Within-Team Project

 - A Cross-Team Initiative

 - A Durable Team
** The Golden Cesspool

Your product team has an ambitious plan to build something cool.

Good news: customers are genuinely eager to use this cool thing!

Bad news: building it will require your team to dig into that horrible part of the legacy codebase that was written by contractors many years ago, has no tests that you can trust worth a damn, and is based on a data model that is a malevolent joke against your current reality.

I will make a bold prediction: this specific flavor of technical debt is never going to go out of style.

The inimitable Edmund Jorgensen (who I quote, um, kind of a lot in the book), first framed this most clearly to me, and named this pattern:

[[https://www.tomheon.com/2017/03/24/the-golden-cesspool/][The Golden Cesspool]]

/"Proposing the rule of the golden cesspool: the closer code is to the heart of a businessâ€™s domain, the worse the code will be."/

In my experience, Edmund is totally right.

Almost all companies seem to have some genuinely hideous mass of code sitting at the beating heart of their business.

Over the years, tons of complex business logic has been shoved into that cesspool.

The most critical processes of the business are tied to data updates in the cesspool.

All sorts of state gets updated in all sorts of deeply non-obvious ways.

Your engineering team likely already thinks about this morass as a prime example of tech debt, and are itching to rewrite it.

They may, in fact, resist an attempt to methodically build visibility and then incrementally improve things.

Instead, they'll make the faux-economic argument that it'd be better to just commit to a ground-up rewrite of that core system.

They'll claim that it will be both faster and cheaper to do so "from scratch" rather than through a slow, incremental shift.

Once that rewrite is fully finished, the things the product team are asking for will be super easy to build!

What could go wrong?

Please see our later chapter: *The Giant Rewrite: Only Undertake If You Wish To Later Be Fired Midway Through a Long & Painful Death March*, which has some tips on how one *can* gradually rewrite such systems.

But as a brief teaser: the core trick here is to convert this from a technical investment to a *product* investment.

The product team *already thinks* there's value here -- they just don't realize there's more of a *cost* than usual.

Making those risks visible and gradually wearing them down will therefore create value.
** Building Visibility For Data Model Investments
/One in a continuing series about (link) Technical Investments, excerpting ideas from Link) the upcoming book/

/In (link) The Golden Cesspool, we talked about how most companies have some particularly nasty chunk of legacy code sitting at the heart of their systems -- and we recommended finding a way to frame work on cesspool as a *product* investment, not a technical investment./

/However, in (link) Build Visibility Into Value, we strongly recommended building visibility as the first step in any major technical investment./

/But how can you build visibility into a bad data model?/

That product team has asked for some feature that is, unfortunately, borderline inmpossible to build, given the way the code and data are currently set up.

A classic example: they've spec'd out some hot new feature that, unfortunately, has the trivial prerequisite of needing to first restructure the core data model for the entire product.

If technical investments are "things that the engineers believe are valuable to the business", how could work on that fundamental data model create value for the business?

If the engineering team can find a safe way to incrementally restructure that core data model, such that they are then able to implement the hot new feature, they will make their overall company *more valuable* in so doing (because the company can look forward to an increase in profits in the future, thanks to this new feature). Their work would create value.

If, on the other hand, the engineering team restructures the core data model to make it "more flexible", but do so on their own, and don't carefully focus on unlocking specific product improvements as they go... odds are quite good that they've made their overall company *less valuable*). Their work will have destroyed value.

Value is not created by adding some kind of theoretical or abstract form of flexibility, but rather by steadily evolving in partnership with discovery around true user needs.

But, how might we make this kind of potential value more *visible*?

First, we need to help stakeholders understand the current limitations.

As an example, at an EdTech company, there might be painful limits around how the system models the assignment of lessons to students.

Classroom assignments have a whole state machine-like lifecycle, plus lots of logic around who is allowed to make assignments to who, plus privacy laws impacting some of those bits, plus all of that has exciting time-varying issues as both students and teachers move in and out of classes during the school year, and then take and retake assignments, etc.

As is often the case for such fundamental challenges, there are both code and data challenges.

Assignment limitations are driven *both* by how assignments are modeled in the system, and also by the quality of the "rostering" data ingested from the schools, that links students, teachers and classes.

The engineering team, who have lived and breathed the core lesson assignment model for years, might try to convey the challenges in some requested new feature by saying:

/"This is going to be very hard, because we don't have reliable mappings from teachers to the *combination* of students and classes in the database"./

If you're exceptionally lucky, you might have a PM who is fluent enough in SQL to visualize the restrictions that imposes.

But, even in that case, odds are good that the PM won't be making tradeoff decisions on their own -- so you'll be *very* well-served by making those restrictions comprehensible to a broader audience.

So, what are other options for creating visibility?

I'll name two.

First, you can try leaning on *User Stories*[fn:: I *adore* user stories, especially in the formulation from User Stories Applied, by <XXX whathisname>].

Instead of talking about the details of the DB tables as above, you could write a careful memo explaining that:

/The current data model does *not* support: "As a teacher, I can batch assign to all the students in my class in one step, in order to support the lesson I taught that day"./

/Instead, with the current data model teachers would have to make assignments one at a time./

That user story form of visibility is generally much more effective than an abstract statement. The human mind is deeply wired to understand *stories*, that formulation is a little miniature story.

The best way to play this game is to build a *set* of such user stories, covering different facets of what the team believes users need.

Such a list allows you to:

 - *Priority sort work in collaboration with stakeholders*

   You can ask "Which user story should we build first?", and "Which ones are worth making a significant technical investment to unlock?"

 - *Demonstrate incremental progress*

   "We've enabled 3 of the 10 key user stories" is a fantastic form of visible, incremental progress.

   It's so much better than some made-up progress metric, like "Our replatforming is 30% complete". Sooooo much better.

 - *Pivot to other work if/when you discover you've met the important uses cases*

   I'm going out on a crazy limb here and suggest that, although, when the user story list was first developed, every single one of those 10 key stories was *absolutely critical* ("How can you even ask?!?"), now that you've built exactly 4 of them, your  stakeholder might change their mind, and realize that those 4 are a perfectly reasonable increment to ship to customers.[fn:: This is part of why I recommend pushing very hard for establishing a simple priority sort -- I find that more effective than aggressively front-loading an argument about the *specific* scope of an initial launch.]

   Thanks to the magic of Hindsight Bias, about five minutes after making this decision, your stakeholder will believe they always knew that they just needed those four stories.

Usually, developing such a set of user stories also has the salutary effect of forcing the engineers and product team to *talk to each other*.

So that's the first idea.

The second tactic, which can work in concert with the user story approach, is to build a crude but usable prototype on top of the *current data model* (or, possibly, on top of "the simplest possible extension to that data model", one step ahead of where you are now).

Such a prototype:

 - Allows stakeholders to *experience* restrictions, instead of imagining them

 - Gives the engineers an opportunity to learn precisely where the limits of the current data model and data set lie

 - Creates something you can incrementally keep improving (and showing!) as flexibility is added under the hood

 - Can be shown to customers, to, among other things, understand which of the user stories they *truly* need

To be carefully clear: if you're trying to create visibility into data model risks, your best bet here is the kind of prototype that offers a visually crude but "real" version of the most important workflows. Like, near-wireframe versions of pages, but hooked up to an actual database.[fn:: At Ellevation, we called such a protoype "An end-to-end shambling mess of the whole system"]

The core capability is that someone can step through various steps of that workflow, in order to understand what is / is not possible.

These kind of visually crude, data-centric protoypes, are distinct from prototypes that allow you to explore a new user experience, but aren't hooked up to any actual code.

Such user experience prototypes can be *super* useful if you're trying to learn about user needs.

But if what you're trying to do is make visible the *restrictions* in your code and data, such prototypes can easily promise a version of the product that is forbiddingly hard to build.

(Tactical tip: for the crude workflow prototypes, your engineers might consider building scripts to prep time-varying *data* in various specific stages, so that you can demo user stories like "As a teacher, I can reassign a lesson that a student has already completed, and, after they complete it a second time, review both responses").

Having created visibility with either or both of the above approaches, the engineers might be able to then gradually negotiate their way up the ladder of commitment, to maybe carefully refactor some part of the core data model, or instrument the code around it with much more thorough tests, or even break some subdomain off to a separate service.

And they'll be able to show incremental progress, and offer meaningful decisions, at every step.
