
* My Prompts

** Generate The Spec
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here’s the idea:

I am writing a non-fiction book in a set of emacs org-mode files. I want to be able to, as I write and save my writing be able to view both a) wordcounts for the overall book, and also for each chapter and section, and also b) a rendered version of the text of the book. I'd like to view those in HTML pages which, ideally, auto-update so that I don't have to reload them.

** Improve TOC parsing
The current tool to parse the TOC file only handles *file* links. Please write out options for having it also handle org-roam links -- which have a GUID which can only be found *inside* the org-roam file that is linked to.

Assume the tool will not run persistently, but will instead be kicked off from scratch each time, collect word counts for a TOC with between 10 and 20 chapters, and then exit. Also assume there will be 50-100 files in the org-roam directory. How could that change the above recommendations?
* Prompt Templates From Harper
** Step 1. Idea Honing
Use a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):

*** Start
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here’s the idea:

<IDEA>
*** End
Now that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
** Step 2. Planning

Take the spec and pass it to a proper reasoning model (o1*, o3*, r1):

*** Start (TDD)
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
*** End
It should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as *prompt_plan.md* in the repo.

*"Can you make a `todo.md` that I can use as a checklist? Be thorough."*

You can save it as todo.md in the repo.

Your codegen tool should be able to check off the todo.md while processing. This is good for keeping state across sessions.

** Step 3. Execution (with aider)

 - set up the repo (boilerplate, uv init, cargo init, etc)

 - start aider

 - paste prompt into aider

 - watch aider dance ♪┏(・o･)┛♪

 - aider will run tests, or you can run app to verify

 - if it works, move on to next prompt

 - if it doesn’t work, Q&A with aider to fix

 - rinse repeat ✩₊˚.⋆☾⋆⁺₊✧
